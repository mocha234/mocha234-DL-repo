{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chicken-nylon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-diary",
   "metadata": {},
   "source": [
    "# StudentPerformance_with_HParamter_GA_Tuning\n",
    "\n",
    "Building a predictions modle with Deep Learning Approach with Tensorflow/Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-statement",
   "metadata": {},
   "source": [
    "### Other Notebooks(in this learnign \"series\"):\n",
    "\n",
    "1. [Genetic Algorithm with Python](https://github.com/mocha234/mocha234-DL-repo/blob/main/GeneticAlgorithm/GA_with_Python.ipynb) --> Understanding Genetic Algorithm with Python(without libraries)\n",
    "2. [Predicting Student Performance(Empirically)](https://github.com/mocha234/mocha234-DL-repo/blob/main/GeneticAlgorithm/StudentPerformance_with_NN.ipynb) --> Empirically tune hyper-parameters\n",
    "3. [Predicting Student Performance(SKLearn's GridSearchCV)](ww) --> Tune hyper-parameters with Sci-Kit Learn's GridSearchCV\n",
    "4. [Predicting Student Performance(Genetic Algorithm with PyGAD)](https://github.com/mocha234/mocha234-DL-repo/blob/main/GeneticAlgorithm/StudentPerformance_PyGAD.ipynb) --> Tune hyper-parameters with GA using PyGAD\n",
    "5. [Predicting Student Performance(Genetic Algorithm with Trained Model + PyGAD)](https://github.com/mocha234/mocha234-DL-repo/blob/main/GeneticAlgorithm/StudentPerformance_Tensorflow_PyGAD.ipynb) --> Tune GA hyper-parameters using PyGAD of a trained Model\n",
    "6. [Some Findings, Comparison, Summary](https://github.com/mocha234/mocha234-DL-repo/blob/main/GeneticAlgorithm/GA_summary.ipynb) --> Summary of this learning \"series\"\n",
    "\n",
    "\n",
    "***This Notebook*** 7. [Using GA to find the Best Hyperparameters](https://github.com/mocha234/mocha234-DL-repo/blob/main/GeneticAlgorithm/StudentPerformance_with_HParamter_GA_Tuning.ipynb) --> Using GA to find the Best Hyperparameters, encoding desire hyperparameter into gene in string of chromosome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-shield",
   "metadata": {},
   "source": [
    "### Index\n",
    "\n",
    "1. Dataset\n",
    "2. Packages Needed\n",
    "3. Data Preprocessing\n",
    "4. Building Deep Learning Model with Tensorflow/Keras\n",
    "5. Finding the best Hyperparameters with GA\n",
    "5. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-manufacturer",
   "metadata": {},
   "source": [
    "# 1. Dataset\n",
    "\n",
    "Source: https://archive.ics.uci.edu/ml/datasets/Student+Performance\n",
    "\n",
    "References: \n",
    "- https://www.kaggle.com/terrifictitan12/student-performance-81-accuracy\n",
    "- https://janakiev.com/blog/keras-iris/\n",
    "- https://datascienceplus.com/keras-regression-based-neural-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-provider",
   "metadata": {},
   "source": [
    "#### Description\n",
    "\n",
    "This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. \n",
    "\n",
    "Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). \n",
    "\n",
    "#### Note: In this notebook, I used the Dataset with Portuguese Language\n",
    "\n",
    "In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks. \n",
    "\n",
    "Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. \n",
    "\n",
    "This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd-period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-small",
   "metadata": {},
   "source": [
    "### Attribute Information:\n",
    "\n",
    "### Attributes for both student-mat.csv (Math course) and student-por.csv (Portuguese language course) datasets:\n",
    "\n",
    "* 1 school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)* \n",
    "* 2 sex - student's sex (binary: 'F' - female or 'M' - male)\n",
    "* 3 age - student's age (numeric: from 15 to 22)\n",
    "* 4 address - student's home address type (binary: 'U' - urban or 'R' - rural)\n",
    "* 5 famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)\n",
    "* 6 Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)\n",
    "* 7 Medu - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education)\n",
    "* 8 Fedu - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education)\n",
    "* 9 Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "* 10 Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "* 11 reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\n",
    "* 12 guardian - student's guardian (nominal: 'mother', 'father' or 'other')\n",
    "* 13 traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    "* 14 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    "* 15 failures - number of past class failures (numeric: n if 1<=n<3, else 4)\n",
    "* 16 schoolsup - extra educational support (binary: yes or no)\n",
    "* 17 famsup - family educational support (binary: yes or no)\n",
    "* 18 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    "* 19 activities - extra-curricular activities (binary: yes or no)\n",
    "* 20 nursery - attended nursery school (binary: yes or no)\n",
    "* 21 higher - wants to take higher education (binary: yes or no)\n",
    "* 22 internet - Internet access at home (binary: yes or no)\n",
    "* 23 romantic - with a romantic relationship (binary: yes or no)\n",
    "* 24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "* 25 freetime - free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "* 26 goout - going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "* 27 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "* 28 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "* 29 health - current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "* 30 absences - number of school absences (numeric: from 0 to 93)\n",
    "\n",
    "#### these grades are related with the course subject, Math or Portuguese:\n",
    "* 31 G1 - first period grade (numeric: from 0 to 20)\n",
    "* 31 G2 - second period grade (numeric: from 0 to 20)\n",
    "* 32 G3 - final grade (numeric: from 0 to 20, output target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-better",
   "metadata": {},
   "source": [
    "# 2. Packages Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "integrated-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import convert_to_tensor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(precision=15)\n",
    "plt.rcParams[\"figure.figsize\"] = (17, 6) # (w, h)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-player",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "continued-opposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>home</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>home</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>R</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>teacher</td>\n",
       "      <td>services</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>R</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
       "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
       "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
       "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
       "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
       "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
       "644     MS   F   19       R     GT3       T     2     3  services     other   \n",
       "645     MS   F   18       U     LE3       T     3     1   teacher  services   \n",
       "646     MS   F   18       U     GT3       T     1     1     other     other   \n",
       "647     MS   M   17       U     LE3       T     3     1  services  services   \n",
       "648     MS   M   18       R     LE3       T     3     2  services     other   \n",
       "\n",
       "     reason guardian  traveltime  studytime  failures schoolsup famsup paid  \\\n",
       "0    course   mother           2          2         0       yes     no   no   \n",
       "1    course   father           1          2         0        no    yes   no   \n",
       "2     other   mother           1          2         0       yes     no   no   \n",
       "3      home   mother           1          3         0        no    yes   no   \n",
       "4      home   father           1          2         0        no    yes   no   \n",
       "..      ...      ...         ...        ...       ...       ...    ...  ...   \n",
       "644  course   mother           1          3         1        no     no   no   \n",
       "645  course   mother           1          2         0        no    yes   no   \n",
       "646  course   mother           2          2         0        no     no   no   \n",
       "647  course   mother           2          1         0        no     no   no   \n",
       "648  course   mother           3          1         0        no     no   no   \n",
       "\n",
       "    activities nursery higher internet romantic  famrel  freetime  goout  \\\n",
       "0           no     yes    yes       no       no       4         3      4   \n",
       "1           no      no    yes      yes       no       5         3      3   \n",
       "2           no     yes    yes      yes       no       4         3      2   \n",
       "3          yes     yes    yes      yes      yes       3         2      2   \n",
       "4           no     yes    yes       no       no       4         3      2   \n",
       "..         ...     ...    ...      ...      ...     ...       ...    ...   \n",
       "644        yes      no    yes      yes       no       5         4      2   \n",
       "645         no     yes    yes      yes       no       4         3      4   \n",
       "646        yes     yes    yes       no       no       1         1      1   \n",
       "647         no      no    yes      yes       no       2         4      5   \n",
       "648         no      no    yes      yes       no       4         4      1   \n",
       "\n",
       "     Dalc  Walc  health  absences  G1  G2  G3  \n",
       "0       1     1       3         4   0  11  11  \n",
       "1       1     1       3         2   9  11  11  \n",
       "2       2     3       3         6  12  13  12  \n",
       "3       1     1       5         0  14  14  14  \n",
       "4       1     2       5         0  11  13  13  \n",
       "..    ...   ...     ...       ...  ..  ..  ..  \n",
       "644     1     2       5         4  10  11  10  \n",
       "645     1     1       1         4  15  15  16  \n",
       "646     1     1       5         6  11  12   9  \n",
       "647     3     4       2         6  10  10  10  \n",
       "648     3     4       5         4  10  11  11  \n",
       "\n",
       "[649 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"student-por.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "military-sending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.744222</td>\n",
       "      <td>2.514638</td>\n",
       "      <td>2.306626</td>\n",
       "      <td>1.568567</td>\n",
       "      <td>1.930663</td>\n",
       "      <td>0.221880</td>\n",
       "      <td>3.930663</td>\n",
       "      <td>3.180277</td>\n",
       "      <td>3.184900</td>\n",
       "      <td>1.502311</td>\n",
       "      <td>2.280431</td>\n",
       "      <td>3.536210</td>\n",
       "      <td>3.659476</td>\n",
       "      <td>11.399076</td>\n",
       "      <td>11.570108</td>\n",
       "      <td>11.906009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.218138</td>\n",
       "      <td>1.134552</td>\n",
       "      <td>1.099931</td>\n",
       "      <td>0.748660</td>\n",
       "      <td>0.829510</td>\n",
       "      <td>0.593235</td>\n",
       "      <td>0.955717</td>\n",
       "      <td>1.051093</td>\n",
       "      <td>1.175766</td>\n",
       "      <td>0.924834</td>\n",
       "      <td>1.284380</td>\n",
       "      <td>1.446259</td>\n",
       "      <td>4.640759</td>\n",
       "      <td>2.745265</td>\n",
       "      <td>2.913639</td>\n",
       "      <td>3.230656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age        Medu        Fedu  traveltime   studytime    failures  \\\n",
       "count  649.000000  649.000000  649.000000  649.000000  649.000000  649.000000   \n",
       "mean    16.744222    2.514638    2.306626    1.568567    1.930663    0.221880   \n",
       "std      1.218138    1.134552    1.099931    0.748660    0.829510    0.593235   \n",
       "min     15.000000    0.000000    0.000000    1.000000    1.000000    0.000000   \n",
       "25%     16.000000    2.000000    1.000000    1.000000    1.000000    0.000000   \n",
       "50%     17.000000    2.000000    2.000000    1.000000    2.000000    0.000000   \n",
       "75%     18.000000    4.000000    3.000000    2.000000    2.000000    0.000000   \n",
       "max     22.000000    4.000000    4.000000    4.000000    4.000000    3.000000   \n",
       "\n",
       "           famrel    freetime       goout        Dalc        Walc      health  \\\n",
       "count  649.000000  649.000000  649.000000  649.000000  649.000000  649.000000   \n",
       "mean     3.930663    3.180277    3.184900    1.502311    2.280431    3.536210   \n",
       "std      0.955717    1.051093    1.175766    0.924834    1.284380    1.446259   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      4.000000    3.000000    2.000000    1.000000    1.000000    2.000000   \n",
       "50%      4.000000    3.000000    3.000000    1.000000    2.000000    4.000000   \n",
       "75%      5.000000    4.000000    4.000000    2.000000    3.000000    5.000000   \n",
       "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
       "\n",
       "         absences          G1          G2          G3  \n",
       "count  649.000000  649.000000  649.000000  649.000000  \n",
       "mean     3.659476   11.399076   11.570108   11.906009  \n",
       "std      4.640759    2.745265    2.913639    3.230656  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000   10.000000   10.000000   10.000000  \n",
       "50%      2.000000   11.000000   11.000000   12.000000  \n",
       "75%      6.000000   13.000000   13.000000   14.000000  \n",
       "max     32.000000   19.000000   19.000000   19.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gentle-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "infectious-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isnull().sum() \n",
    "# Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "entitled-security",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2']\n",
      "\n",
      "Number of Features: 32\n"
     ]
    }
   ],
   "source": [
    "features_list = list(df.columns)[:-1]\n",
    "print(\"Features: {x}\".format(x = features_list))\n",
    "print(\"\\nNumber of Features: {x}\".format(x = len(features_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brutal-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()\n",
    "# # Check datatype of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "brilliant-english",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>home</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>home</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>R</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>teacher</td>\n",
       "      <td>services</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>R</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
       "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
       "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
       "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
       "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
       "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
       "644     MS   F   19       R     GT3       T     2     3  services     other   \n",
       "645     MS   F   18       U     LE3       T     3     1   teacher  services   \n",
       "646     MS   F   18       U     GT3       T     1     1     other     other   \n",
       "647     MS   M   17       U     LE3       T     3     1  services  services   \n",
       "648     MS   M   18       R     LE3       T     3     2  services     other   \n",
       "\n",
       "     reason guardian  traveltime  studytime  failures schoolsup famsup paid  \\\n",
       "0    course   mother           2          2         0       yes     no   no   \n",
       "1    course   father           1          2         0        no    yes   no   \n",
       "2     other   mother           1          2         0       yes     no   no   \n",
       "3      home   mother           1          3         0        no    yes   no   \n",
       "4      home   father           1          2         0        no    yes   no   \n",
       "..      ...      ...         ...        ...       ...       ...    ...  ...   \n",
       "644  course   mother           1          3         1        no     no   no   \n",
       "645  course   mother           1          2         0        no    yes   no   \n",
       "646  course   mother           2          2         0        no     no   no   \n",
       "647  course   mother           2          1         0        no     no   no   \n",
       "648  course   mother           3          1         0        no     no   no   \n",
       "\n",
       "    activities nursery higher internet romantic  famrel  freetime  goout  \\\n",
       "0           no     yes    yes       no       no       4         3      4   \n",
       "1           no      no    yes      yes       no       5         3      3   \n",
       "2           no     yes    yes      yes       no       4         3      2   \n",
       "3          yes     yes    yes      yes      yes       3         2      2   \n",
       "4           no     yes    yes       no       no       4         3      2   \n",
       "..         ...     ...    ...      ...      ...     ...       ...    ...   \n",
       "644        yes      no    yes      yes       no       5         4      2   \n",
       "645         no     yes    yes      yes       no       4         3      4   \n",
       "646        yes     yes    yes       no       no       1         1      1   \n",
       "647         no      no    yes      yes       no       2         4      5   \n",
       "648         no      no    yes      yes       no       4         4      1   \n",
       "\n",
       "     Dalc  Walc  health  absences  G1  G2  \n",
       "0       1     1       3         4   0  11  \n",
       "1       1     1       3         2   9  11  \n",
       "2       2     3       3         6  12  13  \n",
       "3       1     1       5         0  14  14  \n",
       "4       1     2       5         0  11  13  \n",
       "..    ...   ...     ...       ...  ..  ..  \n",
       "644     1     2       5         4  10  11  \n",
       "645     1     1       1         4  15  15  \n",
       "646     1     1       5         6  11  12  \n",
       "647     3     4       2         6  10  10  \n",
       "648     3     4       5         4  10  11  \n",
       "\n",
       "[649 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.drop([\"G3\"], axis = 1)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "small-vienna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     G3\n",
       "0    11\n",
       "1    11\n",
       "2    12\n",
       "3    14\n",
       "4    13\n",
       "..   ..\n",
       "644  10\n",
       "645  16\n",
       "646   9\n",
       "647  10\n",
       "648  11\n",
       "\n",
       "[649 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df.drop(features_list, axis = 1)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "opponent-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_school = {'GP' : 0, 'MS' : 1}\n",
    "mapping_sex = {'F' : 0, 'M' : 1}\n",
    "mapping_address = {'U' : 0, 'R' : 1}\n",
    "mapping_famsize = {'GT3' : 0, 'LE3' : 1}\n",
    "mapping_pstatus = {'A' : 0, 'T' : 1}\n",
    "mapping_mjob = {'at_home' : 0, 'health' : 1, 'other' : 2, 'services' : 3, 'teacher' : 4}\n",
    "mapping_fjob = {'at_home' : 0, 'health' : 1, 'other' : 2, 'services' : 3, 'teacher' : 4}\n",
    "mapping_reason = {'course' : 0, 'other' : 1, 'home' : 2, 'reputation' : 3}\n",
    "mapping_guardian = {'mother' : 0, 'father' : 1, 'other': 2}\n",
    "mapping_schoolsup = {'no' : 0, 'yes' : 1}\n",
    "mapping_famsup = {'no' : 0, 'yes' : 1}\n",
    "mapping_romantic = {'no' : 0, 'yes' : 1}\n",
    "mapping_paid = {'no' : 0, 'yes' : 1}\n",
    "mapping_activities = {'no' : 0, 'yes' : 1}\n",
    "mapping_nursery = {'no' : 0, 'yes' : 1}\n",
    "mapping_higher = {'no' : 0, 'yes' : 1}\n",
    "mapping_internet = {'no' : 0, 'yes' : 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "strong-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['school'] = features['school'].map(mapping_school)\n",
    "df['sex'] = features['sex'].map(mapping_sex)\n",
    "df['address'] = features['address'].map(mapping_address)\n",
    "df['famsize'] = features['famsize'].map(mapping_famsize)\n",
    "df['Pstatus'] = features['Pstatus'].map(mapping_pstatus)\n",
    "df['Mjob'] = features['Mjob'].map(mapping_mjob)\n",
    "df['Fjob'] = features['Fjob'].map(mapping_fjob)\n",
    "df['reason'] = features['reason'].map(mapping_reason)\n",
    "df['guardian'] = features['guardian'].map(mapping_guardian).astype('Int64')\n",
    "df['famsup'] = features['famsup'].map(mapping_famsup)\n",
    "df['schoolsup'] = features['schoolsup'].map(mapping_schoolsup)\n",
    "df['romantic'] = features['romantic'].map(mapping_romantic)\n",
    "df['paid'] = features['paid'].map(mapping_paid)\n",
    "df['activities'] = features['activities'].map(mapping_activities)\n",
    "df['nursery'] = features['nursery'].map(mapping_nursery)\n",
    "df['higher'] = features['higher'].map(mapping_higher)\n",
    "df['internet'] = features['internet'].map(mapping_internet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "conditional-italic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>home</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>home</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>R</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>teacher</td>\n",
       "      <td>services</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>R</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
       "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
       "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
       "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
       "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
       "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
       "644     MS   F   19       R     GT3       T     2     3  services     other   \n",
       "645     MS   F   18       U     LE3       T     3     1   teacher  services   \n",
       "646     MS   F   18       U     GT3       T     1     1     other     other   \n",
       "647     MS   M   17       U     LE3       T     3     1  services  services   \n",
       "648     MS   M   18       R     LE3       T     3     2  services     other   \n",
       "\n",
       "     reason guardian  traveltime  studytime  failures schoolsup famsup paid  \\\n",
       "0    course   mother           2          2         0       yes     no   no   \n",
       "1    course   father           1          2         0        no    yes   no   \n",
       "2     other   mother           1          2         0       yes     no   no   \n",
       "3      home   mother           1          3         0        no    yes   no   \n",
       "4      home   father           1          2         0        no    yes   no   \n",
       "..      ...      ...         ...        ...       ...       ...    ...  ...   \n",
       "644  course   mother           1          3         1        no     no   no   \n",
       "645  course   mother           1          2         0        no    yes   no   \n",
       "646  course   mother           2          2         0        no     no   no   \n",
       "647  course   mother           2          1         0        no     no   no   \n",
       "648  course   mother           3          1         0        no     no   no   \n",
       "\n",
       "    activities nursery higher internet romantic  famrel  freetime  goout  \\\n",
       "0           no     yes    yes       no       no       4         3      4   \n",
       "1           no      no    yes      yes       no       5         3      3   \n",
       "2           no     yes    yes      yes       no       4         3      2   \n",
       "3          yes     yes    yes      yes      yes       3         2      2   \n",
       "4           no     yes    yes       no       no       4         3      2   \n",
       "..         ...     ...    ...      ...      ...     ...       ...    ...   \n",
       "644        yes      no    yes      yes       no       5         4      2   \n",
       "645         no     yes    yes      yes       no       4         3      4   \n",
       "646        yes     yes    yes       no       no       1         1      1   \n",
       "647         no      no    yes      yes       no       2         4      5   \n",
       "648         no      no    yes      yes       no       4         4      1   \n",
       "\n",
       "     Dalc  Walc  health  absences  G1  G2  \n",
       "0       1     1       3         4   0  11  \n",
       "1       1     1       3         2   9  11  \n",
       "2       2     3       3         6  12  13  \n",
       "3       1     1       5         0  14  14  \n",
       "4       1     2       5         0  11  13  \n",
       "..    ...   ...     ...       ...  ..  ..  \n",
       "644     1     2       5         4  10  11  \n",
       "645     1     1       1         4  15  15  \n",
       "646     1     1       5         6  11  12  \n",
       "647     3     4       2         6  10  10  \n",
       "648     3     4       5         4  10  11  \n",
       "\n",
       "[649 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "literary-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "failing-qualification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='school', data=features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vocational-translator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features.hist(bins=20, figsize=(20,15));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-mississippi",
   "metadata": {},
   "source": [
    "#### Outliers\n",
    "\n",
    "As I go through the data, I found there are students who achieve 0 in their G3 depsite having more than half during their G1 & G2 examinations. \n",
    "The outliers might affect model's performance, hence I decided to drop those outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "educational-burning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=target[\"G3\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-snake",
   "metadata": {},
   "source": [
    "#### Drop Outliers data if certain requirement satisfied.\n",
    "\n",
    "G3 with score of 2.5 and less considered as Outliers. To understand this data, I will list down these outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "copyrighted-wellington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     school  sex  age  address  famsize  Pstatus  Medu  Fedu  Mjob  Fjob  \\\n",
       "163       0    1   18        0        1        1     1     1     2     2   \n",
       "172       0    1   16        0        0        1     3     3     2     3   \n",
       "440       1    1   16        0        0        1     1     1     0     3   \n",
       "519       1    1   16        1        0        1     2     1     2     3   \n",
       "563       1    1   17        0        0        1     2     2     2     2   \n",
       "567       1    1   18        1        0        1     3     2     3     2   \n",
       "583       1    0   18        1        0        1     2     2     2     2   \n",
       "586       1    0   17        0        0        1     4     2     4     3   \n",
       "597       1    0   18        1        0        1     2     2     0     2   \n",
       "603       1    0   18        1        1        0     4     2     4     2   \n",
       "605       1    0   19        0        0        1     1     1     0     3   \n",
       "610       1    0   19        1        0        0     1     1     0     0   \n",
       "626       1    0   18        1        0        1     4     4     2     4   \n",
       "637       1    1   18        1        0        1     2     1     2     2   \n",
       "639       1    1   19        1        0        1     1     1     2     3   \n",
       "640       1    1   18        1        0        1     4     2     2     2   \n",
       "\n",
       "     reason  guardian  traveltime  studytime  failures  schoolsup  famsup  \\\n",
       "163       0         0           1          1         2          0       0   \n",
       "172       0         1           1          2         1          0       1   \n",
       "440       2         0           2          2         0          0       1   \n",
       "519       3         0           2          2         0          0       0   \n",
       "563       0         0           1          1         1          0       0   \n",
       "567       0         0           1          1         1          0       0   \n",
       "583       1         0           2          1         1          0       0   \n",
       "586       2         0           1          2         0          1       1   \n",
       "597       0         0           3          2         1          0       0   \n",
       "603       3         0           1          2         0          0       0   \n",
       "605       1         1           2          1         1          0       0   \n",
       "610       0         2           2          2         3          0       1   \n",
       "626       1         1           3          2         0          0       1   \n",
       "637       1         0           2          1         0          0       0   \n",
       "639       1         0           2          1         1          0       0   \n",
       "640       2         1           2          1         1          0       0   \n",
       "\n",
       "     paid  activities  nursery  higher  internet  romantic  famrel  freetime  \\\n",
       "163     0           0        1       0         1         1       2         3   \n",
       "172     0           0        1       1         1         1       4         5   \n",
       "440     0           1        1       1         0         1       5         4   \n",
       "519     0           1        1       1         1         0       5         2   \n",
       "563     0           1        1       1         0         1       1         2   \n",
       "567     0           0        1       0         1         0       2         3   \n",
       "583     0           0        1       0         1         1       5         5   \n",
       "586     0           1        1       1         1         0       5         5   \n",
       "597     0           1        1       1         0         1       4         3   \n",
       "603     0           1        1       1         1         1       5         3   \n",
       "605     0           0        1       0         0         0       5         5   \n",
       "610     0           1        1       0         0         1       3         5   \n",
       "626     0           0        0       1         1         1       3         2   \n",
       "637     0           1        0       1         1         1       4         4   \n",
       "639     0           0        1       1         0         0       4         3   \n",
       "640     1           0        1       1         0         0       5         4   \n",
       "\n",
       "     goout  Dalc  Walc  health  absences  G1  G2  G3  \n",
       "163      5     2     5       4         0  11   9   0  \n",
       "172      5     4     4       5         0  10  10   1  \n",
       "440      5     4     5       3         0   7   0   0  \n",
       "519      1     1     1       2         0   8   7   0  \n",
       "563      1     2     3       5         0   7   0   0  \n",
       "567      1     2     2       5         0   4   0   0  \n",
       "583      5     1     1       3         0   8   6   0  \n",
       "586      5     1     3       5         0   8   8   0  \n",
       "597      3     1     1       4         0   9   0   0  \n",
       "603      1     1     1       5         0   5   0   0  \n",
       "605      5     2     3       2         0   5   0   0  \n",
       "610      4     1     4       1         0   8   0   0  \n",
       "626      2     4     2       5         0   7   5   0  \n",
       "637      3     1     3       5         0   7   7   0  \n",
       "639      2     1     3       5         0   5   8   0  \n",
       "640      3     4     3       3         0   7   7   0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outliers = df[df[\"G3\"]<2.5]\n",
    "df_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-george",
   "metadata": {},
   "source": [
    "#### Dropping rows if:\n",
    "\n",
    "G3 considered as outliers when G1 or G2 above average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "driven-active",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     school  sex  age  address  famsize  Pstatus  Medu  Fedu  Mjob  Fjob  \\\n",
       "0         0    0   18        0        0        0     4     4     0     4   \n",
       "1         0    0   17        0        0        1     1     1     0     2   \n",
       "2         0    0   15        0        1        1     1     1     0     2   \n",
       "3         0    0   15        0        0        1     4     2     1     3   \n",
       "4         0    0   16        0        0        1     3     3     2     2   \n",
       "..      ...  ...  ...      ...      ...      ...   ...   ...   ...   ...   \n",
       "644       1    0   19        1        0        1     2     3     3     2   \n",
       "645       1    0   18        0        1        1     3     1     4     3   \n",
       "646       1    0   18        0        0        1     1     1     2     2   \n",
       "647       1    1   17        0        1        1     3     1     3     3   \n",
       "648       1    1   18        1        1        1     3     2     3     2   \n",
       "\n",
       "     reason  guardian  traveltime  studytime  failures  schoolsup  famsup  \\\n",
       "0         0         0           2          2         0          1       0   \n",
       "1         0         1           1          2         0          0       1   \n",
       "2         1         0           1          2         0          1       0   \n",
       "3         2         0           1          3         0          0       1   \n",
       "4         2         1           1          2         0          0       1   \n",
       "..      ...       ...         ...        ...       ...        ...     ...   \n",
       "644       0         0           1          3         1          0       0   \n",
       "645       0         0           1          2         0          0       1   \n",
       "646       0         0           2          2         0          0       0   \n",
       "647       0         0           2          1         0          0       0   \n",
       "648       0         0           3          1         0          0       0   \n",
       "\n",
       "     paid  activities  nursery  higher  internet  romantic  famrel  freetime  \\\n",
       "0       0           0        1       1         0         0       4         3   \n",
       "1       0           0        0       1         1         0       5         3   \n",
       "2       0           0        1       1         1         0       4         3   \n",
       "3       0           1        1       1         1         1       3         2   \n",
       "4       0           0        1       1         0         0       4         3   \n",
       "..    ...         ...      ...     ...       ...       ...     ...       ...   \n",
       "644     0           1        0       1         1         0       5         4   \n",
       "645     0           0        1       1         1         0       4         3   \n",
       "646     0           1        1       1         0         0       1         1   \n",
       "647     0           0        0       1         1         0       2         4   \n",
       "648     0           0        0       1         1         0       4         4   \n",
       "\n",
       "     goout  Dalc  Walc  health  absences  G1  G2  G3  \n",
       "0        4     1     1       3         4   0  11  11  \n",
       "1        3     1     1       3         2   9  11  11  \n",
       "2        2     2     3       3         6  12  13  12  \n",
       "3        2     1     1       5         0  14  14  14  \n",
       "4        2     1     2       5         0  11  13  13  \n",
       "..     ...   ...   ...     ...       ...  ..  ..  ..  \n",
       "644      2     1     2       5         4  10  11  10  \n",
       "645      4     1     1       1         4  15  15  16  \n",
       "646      1     1     1       5         6  11  12   9  \n",
       "647      5     3     4       2         6  10  10  10  \n",
       "648      1     3     4       5         4  10  11  11  \n",
       "\n",
       "[633 rows x 33 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_idx = df[df[\"G3\"] < 2.5].index\n",
    "len(outlier_idx) \n",
    "df = df.drop(outlier_idx)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-multiple",
   "metadata": {},
   "source": [
    "### Reassign features and target dataframe after dropping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "yellow-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.drop(features_list, axis = 1)\n",
    "features = df.drop([\"G3\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-anaheim",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-engineer",
   "metadata": {},
   "source": [
    "#### Split Training and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sought-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "raised-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler(feature_range = (0,1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "y_train_scaled = scaler.fit_transform(y_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "y_test_scaled = scaler.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "characteristic-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unscaled = scaler.inverse_transform(X_train_scaled).astype('float64') \n",
    "y_train_unscaled = scaler.inverse_transform(y_train_scaled).astype('float64') \n",
    "X_test_unscaled = scaler.inverse_transform(X_test_scaled).astype('float64') \n",
    "y_test_unscaled = scaler.inverse_transform(y_test_scaled).astype('float64') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "valuable-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_np = X_test.values.astype(int)\n",
    "y_test_np = y_test.values.astype(int)\n",
    "X_test_np = convert_to_tensor(X_test_np)\n",
    "y_test_np = convert_to_tensor(y_test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-scotland",
   "metadata": {},
   "source": [
    "# 4. Building Deep Learning Model with Tensorflow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "talented-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_LR = 0.1\n",
    "theLearningRate = init_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "arabic-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(theLearningRate = theLearningRate):\n",
    "\n",
    "    model = Sequential([\n",
    "    Dense(32, input_dim=32, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "    ])\n",
    "    optimizer = Adam(lr = theLearningRate)\n",
    "    model.compile(\n",
    "        loss='mse', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['mse','mae']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-interaction",
   "metadata": {},
   "source": [
    "# GA Starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-dynamics",
   "metadata": {},
   "source": [
    "# 5. Finding the best Hyperparameters with GA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-function",
   "metadata": {},
   "source": [
    "### Hyperparameters Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "animal-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams_optimizerFunc = {\n",
    "#     1 : \"SGD\",\n",
    "#     2 : \"RMSprop\",\n",
    "#     3 : \"Adagrad\",\n",
    "#     4 : \"Adam\"\n",
    "# }\n",
    "# For now use ADAM\n",
    "\n",
    "hyperparams_batchSize = {\n",
    "    0 : 6,\n",
    "    1 : 12,\n",
    "    2 : 24,\n",
    "    3 : 36,\n",
    "    4 : 48\n",
    "}\n",
    "\n",
    "\n",
    "# hyperparams_learningRate = {\n",
    "#     0 : 0.1,\n",
    "#     1 : 0.5,\n",
    "#     2 : 0.01,\n",
    "#     3 : 0.05,\n",
    "# }\n",
    "\n",
    "hyperparams_noEpochs = {\n",
    "    0 : 100,\n",
    "    1 : 200,\n",
    "    2 : 400,\n",
    "    3 : 500,\n",
    "    4 : 600,\n",
    "    5 : 700,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "infinite-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_upper_limit = 0.1\n",
    "LR_lower_limit = 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-wilson",
   "metadata": {},
   "source": [
    "### Configure GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "affecting-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromosomes_per_population = 4 \n",
    "genes_per_chromosome = 3 \n",
    "pop_size = (chromosomes_per_population, genes_per_chromosome)\n",
    "n_gen = 50\n",
    "new_population = np.random.randint(0,4,pop_size) # 0-4 --> 0,1,2,3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-trustee",
   "metadata": {},
   "source": [
    "### Define Initial Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "natural-consent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 3],\n",
       "       [1, 1, 2],\n",
       "       [3, 0, 1],\n",
       "       [1, 1, 0]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-component",
   "metadata": {},
   "source": [
    "## Enconding\n",
    "\n",
    "Index : 2, 1, 0\n",
    "\n",
    "Genes : Batch Size, Learning Rate, No of Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-experiment",
   "metadata": {},
   "source": [
    "# Defining Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-defensive",
   "metadata": {},
   "source": [
    "### Breeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "sharing-heather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 4)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(chromosomes_per_population) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "active-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "def breeding(chromosomes_per_population):\n",
    "    print(\"\\n<---Breeding--->\")\n",
    "    fitness_val_in_pop = []\n",
    "    print(\"Chromosome per population :\", chromosomes_per_population)\n",
    "    \n",
    "\n",
    "    for i in range(chromosomes_per_population) :\n",
    "        print(\"Chromosome :\", i)\n",
    "        \n",
    "        the_NoEpochs = hyperparams_noEpochs[new_population[i][0]]\n",
    "        the_LR = np.random.uniform(LR_lower_limit, LR_upper_limit)\n",
    "        the_BatchSize = hyperparams_batchSize[new_population[i][2]]\n",
    "\n",
    "        print(\"Learning Rate: \",the_LR)\n",
    "        print(\"Batch Size:\",the_BatchSize)\n",
    "        print(\"Number of Epochs :\",the_NoEpochs)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        model = create_model(\n",
    "            theLearningRate = the_LR\n",
    "        )\n",
    "        model.optimizer.get_config()\n",
    "        print(model.optimizer.get_config())\n",
    "\n",
    "        history = model.fit(\n",
    "            X_test_scaled, \n",
    "            y_test_scaled, \n",
    "            epochs=the_NoEpochs, \n",
    "            batch_size= the_BatchSize,  \n",
    "            verbose=0, validation_split=0.2) \n",
    "        print(\"\\n\")\n",
    "        loss, mean_sq_e, mean_abs_e = model.evaluate(X_test_np, y_test_np)\n",
    "        f_val = 1/mean_sq_e + 0.00001\n",
    "        fitness_val_in_pop.append(f_val)\n",
    "        print(\"Fitness Value: \",f_val)\n",
    "#         print(fitness_val_in_pop)\n",
    "        max_fVal = np.max(fitness_val_in_pop)\n",
    "        print(\"Max Fitness Value of the Population :\",max_fVal)\n",
    "        print(fitness_val_in_pop)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    return (max_fVal, fitness_val_in_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-planet",
   "metadata": {},
   "source": [
    "### Selection\n",
    "\n",
    "Selecting the best parents to mate and breed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "sunset-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_by_fVal(fitness_val_in_pop):\n",
    "    print(\"\\n<---Sorting--->\")\n",
    "    fitness_val_in_pop_sorted_index = np.argsort(-fitness_val_in_pop)\n",
    "    top1and2 = new_population[fitness_val_in_pop_sorted_index[0:2]]\n",
    "    top3and4 = new_population[fitness_val_in_pop_sorted_index[2:4]]\n",
    "\n",
    "    \n",
    "    sorted_population = np.concatenate((top1and2, top3and4))\n",
    "    fittest_chromose_in_pop = new_population[fitness_val_in_pop_sorted_index[0]]\n",
    "    print(sorted_population)\n",
    "    return (fittest_chromose_in_pop, sorted_population)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-howard",
   "metadata": {},
   "source": [
    "### Crossover\n",
    "\n",
    "For now, only got 3 genes, crossover/swap index 0 between the parents.\n",
    "Instead of swapping just one, swap the other two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ranking-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(sorted_population):\n",
    "    print(\"\\n<---Crossover--->\")\n",
    "    tmp = np.array(sorted_population[:])\n",
    "    tmp2 = np.zeros(np.shape(sorted_population))\n",
    "\n",
    "    for i in range(len(sorted_population)):\n",
    "        if (i % 2) == 0:  \n",
    "            tmp[i][1:3] = sorted_population[i+1][1:3]\n",
    "        else:  \n",
    "            tmp[i][1:3] = sorted_population[i-1][1:3]\n",
    "            \n",
    "    new_population = tmp\n",
    "    return new_population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-automation",
   "metadata": {},
   "source": [
    "### Fittest chromosome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-noise",
   "metadata": {},
   "source": [
    "### Combining the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "center-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ga_run(new_population):\n",
    "    fVal_gen = []\n",
    "    max_fVal = 0.00\n",
    "    idx_max_fVal = 0\n",
    "    \n",
    "    for i in range(n_gen):\n",
    "        print(\"Generation: \",i)\n",
    "        print(\"Population of Chromosomes:\")\n",
    "        print(new_population)\n",
    "        \n",
    "        pop_max_fVal, fitness_val_in_pop = breeding(chromosomes_per_population)\n",
    "        fVal_gen.append(pop_max_fVal)\n",
    "        \n",
    "        fittest_chromosome, sorted_population = sorting_by_fVal(np.array(fitness_val_in_pop))\n",
    "        \n",
    "        new_population = crossover(sorted_population)\n",
    "        print(\"After Crossover\")\n",
    "        print(new_population)\n",
    "        \n",
    "        if max_fVal < pop_max_fVal:\n",
    "            max_fVal = pop_max_fVal\n",
    "            idx_max_fVal = i\n",
    "            fittest_chromosome = fittest_chromosome\n",
    "            print(\"Chromosome Updated\")\n",
    "            print(\"Current fittest Chromosome :\")\n",
    "            print(fittest_chromosome)\n",
    "            \n",
    "        else:\n",
    "            print(\"Previous Generation Chromosome is better:\")\n",
    "            print(\"Current fittest Chromosome :\")\n",
    "            print(fittest_chromosome)\n",
    "            \n",
    "        print(\"\\n\")\n",
    "            \n",
    "    return (fVal_gen, max_fVal, idx_max_fVal, fittest_chromosome)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-brown",
   "metadata": {},
   "source": [
    "# Executing Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "through-heather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation:  0\n",
      "Population of Chromosomes:\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.028997721663698985\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.028997721663698985, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 16.8025 - mse: 16.8025 - mae: 3.9735\n",
      "Fitness Value:  0.059524872872164056\n",
      "Max Fitness Value of the Population : 0.059524872872164056\n",
      "[0.059524872872164056]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.03509528732339026\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03509528732339026, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 149.4539 - mse: 149.4539 - mae: 11.9476\n",
      "Fitness Value:  0.006701027003627505\n",
      "Max Fitness Value of the Population : 0.059524872872164056\n",
      "[0.059524872872164056, 0.006701027003627505]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.09491525640971527\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09491525640971527, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.059524872872164056\n",
      "[0.059524872872164056, 0.006701027003627505, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.01962672107825954\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.01962672107825954, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 898us/step - loss: 10.8580 - mse: 10.8580 - mae: 3.1339\n",
      "Fitness Value:  0.09210841458164\n",
      "Max Fitness Value of the Population : 0.09210841458164\n",
      "[0.059524872872164056, 0.006701027003627505, 0.006221586329733097, 0.09210841458164]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 1 0]\n",
      " [1 3 3]\n",
      " [1 1 2]\n",
      " [3 0 1]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 3 3]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [3 1 2]]\n",
      "Chromosome Updated\n",
      "Current fittest Chromosome :\n",
      "[1 1 0]\n",
      "\n",
      "\n",
      "Generation:  1\n",
      "Population of Chromosomes:\n",
      "[[1 3 3]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [3 1 2]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.01819181034713788\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.01819181034713788, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 9.9330 - mse: 9.9330 - mae: 2.9662\n",
      "Fitness Value:  0.100684677876382\n",
      "Max Fitness Value of the Population : 0.100684677876382\n",
      "[0.100684677876382]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.07191381546380217\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.07191381546380217, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 8.5089 - mse: 8.5089 - mae: 2.7631\n",
      "Fitness Value:  0.11753412712577442\n",
      "Max Fitness Value of the Population : 0.11753412712577442\n",
      "[0.100684677876382, 0.11753412712577442]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.02115487554357526\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.02115487554357526, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.11753412712577442\n",
      "[0.100684677876382, 0.11753412712577442, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.07674103023042604\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.07674103023042604, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.11753412712577442\n",
      "[0.100684677876382, 0.11753412712577442, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Chromosome Updated\n",
      "Current fittest Chromosome :\n",
      "[1 1 2]\n",
      "\n",
      "\n",
      "Generation:  2\n",
      "Population of Chromosomes:\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.06505415681411814\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06505415681411814, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 7.4253 - mse: 7.4253 - mae: 2.5486\n",
      "Fitness Value:  0.13468470837525426\n",
      "Max Fitness Value of the Population : 0.13468470837525426\n",
      "[0.13468470837525426]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.06498144850576246\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06498144850576246, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.13468470837525426\n",
      "[0.13468470837525426, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.010904707953636208\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.010904707953636208, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.13468470837525426\n",
      "[0.13468470837525426, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.03802159566066939\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03802159566066939, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.13468470837525426\n",
      "[0.13468470837525426, 0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Chromosome Updated\n",
      "Current fittest Chromosome :\n",
      "[1 3 3]\n",
      "\n",
      "\n",
      "Generation:  3\n",
      "Population of Chromosomes:\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.05815585037681585\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.05815585037681585, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.09152778039119329\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09152778039119329, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.0451780361034117\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.0451780361034117, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.09590427799781673\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09590427799781673, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 3 3]\n",
      "\n",
      "\n",
      "Generation:  4\n",
      "Population of Chromosomes:\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.08071828351845048\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.08071828351845048, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.0390425879068946\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.0390425879068946, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.09208505206570726\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09208505206570726, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 980us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.04161229848979915\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.04161229848979915, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.8617 - mse: 4.8617 - mae: 2.0080\n",
      "Fitness Value:  0.20569999086182764\n",
      "Max Fitness Value of the Population : 0.20569999086182764\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097, 0.20569999086182764]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 1 0]\n",
      " [1 3 3]\n",
      " [1 1 2]\n",
      " [3 0 1]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 3 3]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [3 1 2]]\n",
      "Chromosome Updated\n",
      "Current fittest Chromosome :\n",
      "[1 1 0]\n",
      "\n",
      "\n",
      "Generation:  5\n",
      "Population of Chromosomes:\n",
      "[[1 3 3]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [3 1 2]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.008538835100969642\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.008538835100969642, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.0074 - mse: 4.0074 - mae: 1.6938\n",
      "Fitness Value:  0.2495456201450724\n",
      "Max Fitness Value of the Population : 0.2495456201450724\n",
      "[0.2495456201450724]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.09498497448636357\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09498497448636357, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.3191 - mse: 3.3191 - mae: 1.5796\n",
      "Fitness Value:  0.3012945327034161\n",
      "Max Fitness Value of the Population : 0.3012945327034161\n",
      "[0.2495456201450724, 0.3012945327034161]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.036466752672184945\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.036466752672184945, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 7.0976 - mse: 7.0976 - mae: 2.4487\n",
      "Fitness Value:  0.14090260180012357\n",
      "Max Fitness Value of the Population : 0.3012945327034161\n",
      "[0.2495456201450724, 0.3012945327034161, 0.14090260180012357]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.06658912676493013\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06658912676493013, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9613 - mse: 160.9613 - mae: 12.4196\n",
      "Fitness Value:  0.006222671571064778\n",
      "Max Fitness Value of the Population : 0.3012945327034161\n",
      "[0.2495456201450724, 0.3012945327034161, 0.14090260180012357, 0.006222671571064778]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Chromosome Updated\n",
      "Current fittest Chromosome :\n",
      "[1 1 2]\n",
      "\n",
      "\n",
      "Generation:  6\n",
      "Population of Chromosomes:\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.006469555291113836\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.006469555291113836, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 978us/step - loss: 19.1456 - mse: 19.1456 - mae: 4.2144\n",
      "Fitness Value:  0.05224122494539904\n",
      "Max Fitness Value of the Population : 0.05224122494539904\n",
      "[0.05224122494539904]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.05662640928569777\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.05662640928569777, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.05224122494539904\n",
      "[0.05224122494539904, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.03599866631228119\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03599866631228119, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 845us/step - loss: 2.5221 - mse: 2.5221 - mae: 1.3325\n",
      "Fitness Value:  0.39650360197026213\n",
      "Max Fitness Value of the Population : 0.39650360197026213\n",
      "[0.05224122494539904, 0.006221586329733097, 0.39650360197026213]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.04404667091814726\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.04404667091814726, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.39650360197026213\n",
      "[0.05224122494539904, 0.006221586329733097, 0.39650360197026213, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 3 3]\n",
      " [1 1 2]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "Chromosome Updated\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  7\n",
      "Population of Chromosomes:\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.09409997157217535\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09409997157217535, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.058206046336009024\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.058206046336009024, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 10.1701 - mse: 10.1701 - mae: 3.0459\n",
      "Fitness Value:  0.09833730971785999\n",
      "Max Fitness Value of the Population : 0.09833730971785999\n",
      "[0.006221586329733097, 0.09833730971785999]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.01679399581708845\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.01679399581708845, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "6/6 [==============================] - 0s 998us/step - loss: 2.4075 - mse: 2.4075 - mae: 1.3026\n",
      "Fitness Value:  0.41537427450756315\n",
      "Max Fitness Value of the Population : 0.41537427450756315\n",
      "[0.006221586329733097, 0.09833730971785999, 0.41537427450756315]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.007449657124673792\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.007449657124673792, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 14.6633 - mse: 14.6633 - mae: 3.6606\n",
      "Fitness Value:  0.06820735488885613\n",
      "Max Fitness Value of the Population : 0.41537427450756315\n",
      "[0.006221586329733097, 0.09833730971785999, 0.41537427450756315, 0.06820735488885613]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 1 2]\n",
      " [1 1 0]\n",
      " [1 3 3]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 1 2]\n",
      " [1 0 1]\n",
      " [1 3 3]\n",
      " [1 1 0]]\n",
      "Chromosome Updated\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  8\n",
      "Population of Chromosomes:\n",
      "[[3 1 2]\n",
      " [1 0 1]\n",
      " [1 3 3]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.03882695237021995\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03882695237021995, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.014086701051615861\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.014086701051615861, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 938us/step - loss: 8.7616 - mse: 8.7616 - mae: 2.7233\n",
      "Fitness Value:  0.11414378950160618\n",
      "Max Fitness Value of the Population : 0.11414378950160618\n",
      "[0.006221586329733097, 0.11414378950160618]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.046778774604539566\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.046778774604539566, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.11414378950160618\n",
      "[0.006221586329733097, 0.11414378950160618, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.026525887605066533\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.026525887605066533, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 996us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.11414378950160618\n",
      "[0.006221586329733097, 0.11414378950160618, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 1 2]\n",
      "\n",
      "\n",
      "Generation:  9\n",
      "Population of Chromosomes:\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.08030551374844255\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.08030551374844255, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.04636525452091266\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.04636525452091266, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 975us/step - loss: 21.0505 - mse: 21.0505 - mae: 4.4356\n",
      "Fitness Value:  0.04751475624736274\n",
      "Max Fitness Value of the Population : 0.04751475624736274\n",
      "[0.006221586329733097, 0.04751475624736274]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.020828648271653743\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.020828648271653743, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 866us/step - loss: 5.2762 - mse: 5.2762 - mae: 2.0513\n",
      "Fitness Value:  0.18953909996198848\n",
      "Max Fitness Value of the Population : 0.18953909996198848\n",
      "[0.006221586329733097, 0.04751475624736274, 0.18953909996198848]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.059364664103697534\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.059364664103697534, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 906us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.18953909996198848\n",
      "[0.006221586329733097, 0.04751475624736274, 0.18953909996198848, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 1 2]\n",
      " [1 3 3]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 1 2]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 3 3]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  10\n",
      "Population of Chromosomes:\n",
      "[[3 1 2]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 3 3]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.048746377234192985\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.048746377234192985, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.08593805530615878\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.08593805530615878, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 960us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.011001058083299573\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.011001058083299573, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 15.2874 - mse: 15.2874 - mae: 3.7269\n",
      "Fitness Value:  0.06542350911583628\n",
      "Max Fitness Value of the Population : 0.06542350911583628\n",
      "[0.006221586329733097, 0.006221586329733097, 0.06542350911583628]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.011172457219807412\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.011172457219807412, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 9.5147 - mse: 9.5147 - mae: 2.9206\n",
      "Fitness Value:  0.105110497760374\n",
      "Max Fitness Value of the Population : 0.105110497760374\n",
      "[0.006221586329733097, 0.006221586329733097, 0.06542350911583628, 0.105110497760374]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 1 0]\n",
      " [3 0 1]\n",
      " [1 3 3]\n",
      " [1 1 2]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 0 1]\n",
      " [3 1 0]\n",
      " [1 1 2]\n",
      " [1 3 3]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 1 0]\n",
      "\n",
      "\n",
      "Generation:  11\n",
      "Population of Chromosomes:\n",
      "[[1 0 1]\n",
      " [3 1 0]\n",
      " [1 1 2]\n",
      " [1 3 3]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.006415375927895111\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.006415375927895111, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 27.6927 - mse: 27.6927 - mae: 5.0852\n",
      "Fitness Value:  0.03612057043885093\n",
      "Max Fitness Value of the Population : 0.03612057043885093\n",
      "[0.03612057043885093]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.07717676277239639\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.07717676277239639, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.03612057043885093\n",
      "[0.03612057043885093, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.08510914316465792\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.08510914316465792, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.03612057043885093\n",
      "[0.03612057043885093, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.08893399748397857\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.08893399748397857, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.03612057043885093\n",
      "[0.03612057043885093, 0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 3 3]\n",
      "\n",
      "\n",
      "Generation:  12\n",
      "Population of Chromosomes:\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.09259481389939471\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09259481389939471, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.02276162968143383\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.02276162968143383, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 24.4245 - mse: 24.4245 - mae: 4.7294\n",
      "Fitness Value:  0.040952455518084636\n",
      "Max Fitness Value of the Population : 0.040952455518084636\n",
      "[0.006221586329733097, 0.040952455518084636]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.05836961652730021\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.05836961652730021, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.040952455518084636\n",
      "[0.006221586329733097, 0.040952455518084636, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.0583262706150582\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.0583262706150582, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.040952455518084636\n",
      "[0.006221586329733097, 0.040952455518084636, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 1 2]\n",
      "\n",
      "\n",
      "Generation:  13\n",
      "Population of Chromosomes:\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.03237053436165909\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03237053436165909, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 15.0972 - mse: 15.0972 - mae: 3.7125\n",
      "Fitness Value:  0.06624723706954601\n",
      "Max Fitness Value of the Population : 0.06624723706954601\n",
      "[0.06624723706954601]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.03605076287536871\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03605076287536871, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.06624723706954601\n",
      "[0.06624723706954601, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.06275570659387246\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06275570659387246, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.0271 - mse: 5.0271 - mae: 1.9303\n",
      "Fitness Value:  0.19893325533615405\n",
      "Max Fitness Value of the Population : 0.19893325533615405\n",
      "[0.06624723706954601, 0.006221586329733097, 0.19893325533615405]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.06530823342784871\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06530823342784871, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 826us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.19893325533615405\n",
      "[0.06624723706954601, 0.006221586329733097, 0.19893325533615405, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 3 3]\n",
      " [1 1 2]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  14\n",
      "Population of Chromosomes:\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.008813380358801007\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.008813380358801007, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 13.6251 - mse: 13.6251 - mae: 3.4583\n",
      "Fitness Value:  0.07340397142147204\n",
      "Max Fitness Value of the Population : 0.07340397142147204\n",
      "[0.07340397142147204]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.06204500218531444\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06204500218531444, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.8981 - mse: 160.8981 - mae: 12.4177\n",
      "Fitness Value:  0.0062251119513920886\n",
      "Max Fitness Value of the Population : 0.07340397142147204\n",
      "[0.07340397142147204, 0.0062251119513920886]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.018493693015806324\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.018493693015806324, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 8.2815 - mse: 8.2815 - mae: 2.7077\n",
      "Fitness Value:  0.12076069822470761\n",
      "Max Fitness Value of the Population : 0.12076069822470761\n",
      "[0.07340397142147204, 0.0062251119513920886, 0.12076069822470761]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.035539096918277634\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.035539096918277634, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 15.1314 - mse: 15.1314 - mae: 3.7670\n",
      "Fitness Value:  0.06609791671446165\n",
      "Max Fitness Value of the Population : 0.12076069822470761\n",
      "[0.07340397142147204, 0.0062251119513920886, 0.12076069822470761, 0.06609791671446165]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 3 3]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 2]\n",
      " [1 1 0]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  15\n",
      "Population of Chromosomes:\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 2]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.06290298920349618\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06290298920349618, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.09174923536111833\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09174923536111833, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.08894345350210403\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.08894345350210403, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.02872387570102783\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.02872387570102783, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 975us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 3 3]\n",
      "\n",
      "\n",
      "Generation:  16\n",
      "Population of Chromosomes:\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.097666829020746\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.097666829020746, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.0829040946949708\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.0829040946949708, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 998us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.022369629652667675\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.022369629652667675, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.3220 - mse: 4.3220 - mae: 1.8524\n",
      "Fitness Value:  0.2313824477783787\n",
      "Max Fitness Value of the Population : 0.2313824477783787\n",
      "[0.006221586329733097, 0.006221586329733097, 0.2313824477783787]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.08102471267840813\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.08102471267840813, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.2313824477783787\n",
      "[0.006221586329733097, 0.006221586329733097, 0.2313824477783787, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 3 3]\n",
      " [1 1 2]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  17\n",
      "Population of Chromosomes:\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.030936920886204027\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.030936920886204027, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 968us/step - loss: 9.3837 - mse: 9.3837 - mae: 2.9093\n",
      "Fitness Value:  0.106577540121778\n",
      "Max Fitness Value of the Population : 0.106577540121778\n",
      "[0.106577540121778]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.06364031980065432\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06364031980065432, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 15.9330 - mse: 15.9330 - mae: 3.8333\n",
      "Fitness Value:  0.0627727870284079\n",
      "Max Fitness Value of the Population : 0.106577540121778\n",
      "[0.106577540121778, 0.0627727870284079]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.04964633322427164\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.04964633322427164, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.7184 - mse: 3.7184 - mae: 1.7125\n",
      "Fitness Value:  0.26894163271089855\n",
      "Max Fitness Value of the Population : 0.26894163271089855\n",
      "[0.106577540121778, 0.0627727870284079, 0.26894163271089855]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.06974318110686231\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06974318110686231, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 950us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.26894163271089855\n",
      "[0.106577540121778, 0.0627727870284079, 0.26894163271089855, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 3 3]\n",
      " [1 1 2]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  18\n",
      "Population of Chromosomes:\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.05084718260177947\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.05084718260177947, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.06972306040221278\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06972306040221278, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.8597 - mse: 5.8597 - mae: 2.2282\n",
      "Fitness Value:  0.17066706998410167\n",
      "Max Fitness Value of the Population : 0.17066706998410167\n",
      "[0.006221586329733097, 0.17066706998410167]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.030674021696290826\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.030674021696290826, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.4317 - mse: 5.4317 - mae: 2.0590\n",
      "Fitness Value:  0.18411462635351428\n",
      "Max Fitness Value of the Population : 0.18411462635351428\n",
      "[0.006221586329733097, 0.17066706998410167, 0.18411462635351428]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.046734306213109186\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.046734306213109186, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 944us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.18411462635351428\n",
      "[0.006221586329733097, 0.17066706998410167, 0.18411462635351428, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 1 2]\n",
      " [1 3 3]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 1 2]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 3 3]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  19\n",
      "Population of Chromosomes:\n",
      "[[3 1 2]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 3 3]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.08347501491796026\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.08347501491796026, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.06208169963431888\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06208169963431888, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.6979 - mse: 5.6979 - mae: 2.1821\n",
      "Fitness Value:  0.17551427460436364\n",
      "Max Fitness Value of the Population : 0.17551427460436364\n",
      "[0.006221586329733097, 0.17551427460436364]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.052046015401310965\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.052046015401310965, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 918us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.17551427460436364\n",
      "[0.006221586329733097, 0.17551427460436364, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.05461767144887218\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.05461767144887218, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 9.4367 - mse: 9.4367 - mae: 2.9197\n",
      "Fitness Value:  0.10597938843571211\n",
      "Max Fitness Value of the Population : 0.17551427460436364\n",
      "[0.006221586329733097, 0.17551427460436364, 0.006221586329733097, 0.10597938843571211]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 1 2]\n",
      " [1 1 0]\n",
      " [1 3 3]\n",
      " [3 0 1]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 1 0]\n",
      " [1 1 2]\n",
      " [1 0 1]\n",
      " [3 3 3]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 1 2]\n",
      "\n",
      "\n",
      "Generation:  20\n",
      "Population of Chromosomes:\n",
      "[[1 1 0]\n",
      " [1 1 2]\n",
      " [1 0 1]\n",
      " [3 3 3]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.088859728238686\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.088859728238686, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.7555 - mse: 160.7555 - mae: 12.4080\n",
      "Fitness Value:  0.0062306272415178264\n",
      "Max Fitness Value of the Population : 0.0062306272415178264\n",
      "[0.0062306272415178264]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.03742219007805814\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03742219007805814, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 13.8792 - mse: 13.8792 - mae: 3.5978\n",
      "Fitness Value:  0.0720600346241116\n",
      "Max Fitness Value of the Population : 0.0720600346241116\n",
      "[0.0062306272415178264, 0.0720600346241116]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.058155770362342325\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.058155770362342325, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.0720600346241116\n",
      "[0.0062306272415178264, 0.0720600346241116, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.044640911393367684\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.044640911393367684, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.7385 - mse: 3.7385 - mae: 1.7145\n",
      "Fitness Value:  0.2674984356625653\n",
      "Max Fitness Value of the Population : 0.2674984356625653\n",
      "[0.0062306272415178264, 0.0720600346241116, 0.006221586329733097, 0.2674984356625653]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 1 0]\n",
      " [1 1 2]\n",
      " [1 3 3]\n",
      " [3 0 1]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 1 2]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [3 3 3]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 1 0]\n",
      "\n",
      "\n",
      "Generation:  21\n",
      "Population of Chromosomes:\n",
      "[[1 1 2]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [3 3 3]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.03871821445011924\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03871821445011924, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.07858514483320236\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.07858514483320236, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.0857602895119389\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.0857602895119389, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 19.7401 - mse: 19.7401 - mae: 4.2817\n",
      "Fitness Value:  0.05066832203970552\n",
      "Max Fitness Value of the Population : 0.05066832203970552\n",
      "[0.006221586329733097, 0.006221586329733097, 0.05066832203970552]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.07915695628855043\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.07915695628855043, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.05066832203970552\n",
      "[0.006221586329733097, 0.006221586329733097, 0.05066832203970552, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 3 3]\n",
      " [1 1 2]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  22\n",
      "Population of Chromosomes:\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.08244386626396251\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.08244386626396251, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.08278126632882979\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.08278126632882979, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.03466495265219221\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03466495265219221, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.06629452204224247\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06629452204224247, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 3 3]\n",
      "\n",
      "\n",
      "Generation:  23\n",
      "Population of Chromosomes:\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.06426335503924405\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06426335503924405, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 9.1945 - mse: 9.1945 - mae: 2.8651\n",
      "Fitness Value:  0.10877041304179841\n",
      "Max Fitness Value of the Population : 0.10877041304179841\n",
      "[0.10877041304179841]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.021744803464031945\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.021744803464031945, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.10877041304179841\n",
      "[0.10877041304179841, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.021002256363129974\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.021002256363129974, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.10877041304179841\n",
      "[0.10877041304179841, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.054688301302724486\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.054688301302724486, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.10877041304179841\n",
      "[0.10877041304179841, 0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 3 3]\n",
      "\n",
      "\n",
      "Generation:  24\n",
      "Population of Chromosomes:\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.0942397470046156\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.0942397470046156, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.05530344551782873\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.05530344551782873, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.059011494045608584\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.059011494045608584, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.8780 - mse: 0.8780 - mae: 0.6938\n",
      "Fitness Value:  1.1389666986824538\n",
      "Max Fitness Value of the Population : 1.1389666986824538\n",
      "[0.006221586329733097, 0.006221586329733097, 1.1389666986824538]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.037821830540085054\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.037821830540085054, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.4981 - mse: 4.4981 - mae: 1.8885\n",
      "Fitness Value:  0.2223248967747065\n",
      "Max Fitness Value of the Population : 1.1389666986824538\n",
      "[0.006221586329733097, 0.006221586329733097, 1.1389666986824538, 0.2223248967747065]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 1 0]\n",
      " [1 3 3]\n",
      " [1 1 2]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 1 0]\n",
      " [1 0 1]\n",
      " [1 1 2]\n",
      " [1 3 3]]\n",
      "Chromosome Updated\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  25\n",
      "Population of Chromosomes:\n",
      "[[3 1 0]\n",
      " [1 0 1]\n",
      " [1 1 2]\n",
      " [1 3 3]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.039875987679781524\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.039875987679781524, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.0532439522189581\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.0532439522189581, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.007607425045342563\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.007607425045342563, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 17.3785 - mse: 17.3785 - mae: 4.0354\n",
      "Fitness Value:  0.05755220773091713\n",
      "Max Fitness Value of the Population : 0.05755220773091713\n",
      "[0.006221586329733097, 0.006221586329733097, 0.05755220773091713]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.0593898584638854\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.0593898584638854, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.05755220773091713\n",
      "[0.006221586329733097, 0.006221586329733097, 0.05755220773091713, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 3 3]\n",
      " [1 1 2]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  26\n",
      "Population of Chromosomes:\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.097014386520596\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.097014386520596, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.07534857194333515\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.07534857194333515, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.08253219336941314\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.08253219336941314, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 990us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.032311579712886\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.032311579712886, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9774 - mse: 160.9774 - mae: 12.4205\n",
      "Fitness Value:  0.006222052059680667\n",
      "Max Fitness Value of the Population : 0.006222052059680667\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097, 0.006222052059680667]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 1 0]\n",
      " [1 3 3]\n",
      " [1 1 2]\n",
      " [3 0 1]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 3 3]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [3 1 2]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 1 0]\n",
      "\n",
      "\n",
      "Generation:  27\n",
      "Population of Chromosomes:\n",
      "[[1 3 3]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [3 1 2]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.016175041774489102\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.016175041774489102, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 12.9908 - mse: 12.9908 - mae: 3.4304\n",
      "Fitness Value:  0.07698737873326074\n",
      "Max Fitness Value of the Population : 0.07698737873326074\n",
      "[0.07698737873326074]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.04829054862884863\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.04829054862884863, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.2968 - mse: 5.2968 - mae: 2.1050\n",
      "Fitness Value:  0.188803585696443\n",
      "Max Fitness Value of the Population : 0.188803585696443\n",
      "[0.07698737873326074, 0.188803585696443]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.07394487810623952\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.07394487810623952, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 912us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.188803585696443\n",
      "[0.07698737873326074, 0.188803585696443, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.09530234979333371\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09530234979333371, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.188803585696443\n",
      "[0.07698737873326074, 0.188803585696443, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 1 2]\n",
      "\n",
      "\n",
      "Generation:  28\n",
      "Population of Chromosomes:\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.09316966710494513\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09316966710494513, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 59.7318 - mse: 59.7318 - mae: 7.2918\n",
      "Fitness Value:  0.01675150863891836\n",
      "Max Fitness Value of the Population : 0.01675150863891836\n",
      "[0.01675150863891836]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.04338562201935987\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.04338562201935987, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 924us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.01675150863891836\n",
      "[0.01675150863891836, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.013270040795913315\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.013270040795913315, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 6.1531 - mse: 6.1531 - mae: 2.2976\n",
      "Fitness Value:  0.162528836133293\n",
      "Max Fitness Value of the Population : 0.162528836133293\n",
      "[0.01675150863891836, 0.006221586329733097, 0.162528836133293]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.0933149147796608\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.0933149147796608, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 150.0463 - mse: 150.0463 - mae: 11.9711\n",
      "Fitness Value:  0.006674608383071797\n",
      "Max Fitness Value of the Population : 0.162528836133293\n",
      "[0.01675150863891836, 0.006221586329733097, 0.162528836133293, 0.006674608383071797]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 3 3]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 2]\n",
      " [1 1 0]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  29\n",
      "Population of Chromosomes:\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 2]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.06489005103837693\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06489005103837693, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.03332296509398962\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03332296509398962, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.6984 - mse: 160.6984 - mae: 12.4056\n",
      "Fitness Value:  0.006232836335682216\n",
      "Max Fitness Value of the Population : 0.006232836335682216\n",
      "[0.006221586329733097, 0.006232836335682216]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.01299719005818447\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.01299719005818447, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 12.1067 - mse: 12.1067 - mae: 3.3220\n",
      "Fitness Value:  0.08260874225845538\n",
      "Max Fitness Value of the Population : 0.08260874225845538\n",
      "[0.006221586329733097, 0.006232836335682216, 0.08260874225845538]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.07856946603952306\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.07856946603952306, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.08260874225845538\n",
      "[0.006221586329733097, 0.006232836335682216, 0.08260874225845538, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 1 2]\n",
      " [1 3 3]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 1 2]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 3 3]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  30\n",
      "Population of Chromosomes:\n",
      "[[3 1 2]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 3 3]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.02890844339487971\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.02890844339487971, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.039528743971927446\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.039528743971927446, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.012168224077479736\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.012168224077479736, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 966us/step - loss: 6.2031 - mse: 6.2031 - mae: 2.2874\n",
      "Fitness Value:  0.16122012135544134\n",
      "Max Fitness Value of the Population : 0.16122012135544134\n",
      "[0.006221586329733097, 0.006221586329733097, 0.16122012135544134]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.017112159942576435\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.017112159942576435, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 12.2512 - mse: 12.2512 - mae: 3.3688\n",
      "Fitness Value:  0.08163437945447262\n",
      "Max Fitness Value of the Population : 0.16122012135544134\n",
      "[0.006221586329733097, 0.006221586329733097, 0.16122012135544134, 0.08163437945447262]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 1 0]\n",
      " [1 3 3]\n",
      " [1 1 2]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 1 0]\n",
      " [1 0 1]\n",
      " [1 1 2]\n",
      " [1 3 3]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  31\n",
      "Population of Chromosomes:\n",
      "[[3 1 0]\n",
      " [1 0 1]\n",
      " [1 1 2]\n",
      " [1 3 3]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.009828774569616176\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.009828774569616176, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 999us/step - loss: 21.0369 - mse: 21.0369 - mae: 4.4124\n",
      "Fitness Value:  0.047545577925905365\n",
      "Max Fitness Value of the Population : 0.047545577925905365\n",
      "[0.047545577925905365]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.07068244789206399\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.07068244789206399, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 19.1957 - mse: 19.1957 - mae: 4.2324\n",
      "Fitness Value:  0.052105094453459476\n",
      "Max Fitness Value of the Population : 0.052105094453459476\n",
      "[0.047545577925905365, 0.052105094453459476]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.09706402917308259\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09706402917308259, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 158.3238 - mse: 158.3238 - mae: 12.2852\n",
      "Fitness Value:  0.006326169503799619\n",
      "Max Fitness Value of the Population : 0.052105094453459476\n",
      "[0.047545577925905365, 0.052105094453459476, 0.006326169503799619]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.01641195136986046\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.01641195136986046, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 980us/step - loss: 2.2583 - mse: 2.2583 - mae: 1.0900\n",
      "Fitness Value:  0.4428157619275456\n",
      "Max Fitness Value of the Population : 0.4428157619275456\n",
      "[0.047545577925905365, 0.052105094453459476, 0.006326169503799619, 0.4428157619275456]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 1 0]\n",
      " [1 1 2]\n",
      " [1 3 3]\n",
      " [3 0 1]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 1 2]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [3 3 3]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 1 0]\n",
      "\n",
      "\n",
      "Generation:  32\n",
      "Population of Chromosomes:\n",
      "[[1 1 2]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [3 3 3]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.058698082047006404\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.058698082047006404, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 22.8216 - mse: 22.8216 - mae: 4.6231\n",
      "Fitness Value:  0.0438281665768637\n",
      "Max Fitness Value of the Population : 0.0438281665768637\n",
      "[0.0438281665768637]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.013756349628445224\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.013756349628445224, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 6.7873 - mse: 6.7873 - mae: 2.3517\n",
      "Fitness Value:  0.14734341974581383\n",
      "Max Fitness Value of the Population : 0.14734341974581383\n",
      "[0.0438281665768637, 0.14734341974581383]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.03991355554266376\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03991355554266376, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.14734341974581383\n",
      "[0.0438281665768637, 0.14734341974581383, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.03279041422657189\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03279041422657189, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 32.2609 - mse: 32.2609 - mae: 5.5194\n",
      "Fitness Value:  0.031007302351166385\n",
      "Max Fitness Value of the Population : 0.14734341974581383\n",
      "[0.0438281665768637, 0.14734341974581383, 0.006221586329733097, 0.031007302351166385]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [1 1 0]\n",
      " [3 0 1]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [1 0 1]\n",
      " [3 1 0]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 1 2]\n",
      "\n",
      "\n",
      "Generation:  33\n",
      "Population of Chromosomes:\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [1 0 1]\n",
      " [3 1 0]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.04928951389958885\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.04928951389958885, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.0626501197344442\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.0626501197344442, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 978us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.061790180979843234\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.061790180979843234, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.08315184174225743\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.08315184174225743, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 3 3]\n",
      "\n",
      "\n",
      "Generation:  34\n",
      "Population of Chromosomes:\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.03748322715983046\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03748322715983046, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.04708391899360117\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.04708391899360117, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 9.0216 - mse: 9.0216 - mae: 2.8073\n",
      "Fitness Value:  0.11085501543842342\n",
      "Max Fitness Value of the Population : 0.11085501543842342\n",
      "[0.006221586329733097, 0.11085501543842342]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.038671106082222205\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.038671106082222205, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.3241 - mse: 4.3241 - mae: 1.7372\n",
      "Fitness Value:  0.23127184276415175\n",
      "Max Fitness Value of the Population : 0.23127184276415175\n",
      "[0.006221586329733097, 0.11085501543842342, 0.23127184276415175]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.03534504577147613\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03534504577147613, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.8553 - mse: 4.8553 - mae: 2.0190\n",
      "Fitness Value:  0.20596944709838216\n",
      "Max Fitness Value of the Population : 0.23127184276415175\n",
      "[0.006221586329733097, 0.11085501543842342, 0.23127184276415175, 0.20596944709838216]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 1 0]\n",
      " [1 1 2]\n",
      " [1 3 3]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 1 0]\n",
      " [1 0 1]\n",
      " [1 3 3]\n",
      " [1 1 2]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  35\n",
      "Population of Chromosomes:\n",
      "[[3 1 0]\n",
      " [1 0 1]\n",
      " [1 3 3]\n",
      " [1 1 2]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.02113412133824648\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.02113412133824648, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.4751 - mse: 3.4751 - mae: 1.5892\n",
      "Fitness Value:  0.2877711642930607\n",
      "Max Fitness Value of the Population : 0.2877711642930607\n",
      "[0.2877711642930607]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.09679815085989216\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09679815085989216, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.2877711642930607\n",
      "[0.2877711642930607, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.011080184207690778\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.011080184207690778, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 6.6250 - mse: 6.6250 - mae: 2.3972\n",
      "Fitness Value:  0.15095229894874188\n",
      "Max Fitness Value of the Population : 0.2877711642930607\n",
      "[0.2877711642930607, 0.006221586329733097, 0.15095229894874188]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.06507385151113206\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06507385151113206, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.2877711642930607\n",
      "[0.2877711642930607, 0.006221586329733097, 0.15095229894874188, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 3 3]\n",
      " [3 0 1]\n",
      " [1 1 2]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 0 1]\n",
      " [3 3 3]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 3 3]\n",
      "\n",
      "\n",
      "Generation:  36\n",
      "Population of Chromosomes:\n",
      "[[1 0 1]\n",
      " [3 3 3]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.07890202971781024\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.07890202971781024, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.053967913846561036\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.053967913846561036, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.07725272525911582\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.07725272525911582, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.09206324531347856\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09206324531347856, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 3 3]\n",
      "\n",
      "\n",
      "Generation:  37\n",
      "Population of Chromosomes:\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.04281408945226595\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.04281408945226595, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 932us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.028771822559099318\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.028771822559099318, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.09104859091128363\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09104859091128363, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.08694105109398667\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.08694105109398667, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 3 3]\n",
      "\n",
      "\n",
      "Generation:  38\n",
      "Population of Chromosomes:\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.055032064397617576\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.055032064397617576, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.03540099223524165\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03540099223524165, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 984us/step - loss: 11.6054 - mse: 11.6054 - mae: 3.2221\n",
      "Fitness Value:  0.08617684752038661\n",
      "Max Fitness Value of the Population : 0.08617684752038661\n",
      "[0.006221586329733097, 0.08617684752038661]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.054299179030353924\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.054299179030353924, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 925us/step - loss: 1.9369 - mse: 1.9369 - mae: 1.1402\n",
      "Fitness Value:  0.5162942390486188\n",
      "Max Fitness Value of the Population : 0.5162942390486188\n",
      "[0.006221586329733097, 0.08617684752038661, 0.5162942390486188]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.0334203472482822\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.0334203472482822, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.5162942390486188\n",
      "[0.006221586329733097, 0.08617684752038661, 0.5162942390486188, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 1 2]\n",
      " [1 3 3]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 1 2]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 3 3]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  39\n",
      "Population of Chromosomes:\n",
      "[[3 1 2]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 3 3]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.03883622565638354\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03883622565638354, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 8.5770 - mse: 8.5770 - mae: 2.6848\n",
      "Fitness Value:  0.1166008871562069\n",
      "Max Fitness Value of the Population : 0.1166008871562069\n",
      "[0.1166008871562069]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.09173697039020429\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09173697039020429, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.1166008871562069\n",
      "[0.1166008871562069, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.03143672913030286\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03143672913030286, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 944us/step - loss: 10.4919 - mse: 10.4919 - mae: 3.0747\n",
      "Fitness Value:  0.09532205048763782\n",
      "Max Fitness Value of the Population : 0.1166008871562069\n",
      "[0.1166008871562069, 0.006221586329733097, 0.09532205048763782]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.04454348417303946\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.04454348417303946, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 17.5479 - mse: 17.5479 - mae: 4.0424\n",
      "Fitness Value:  0.056997033223885586\n",
      "Max Fitness Value of the Population : 0.1166008871562069\n",
      "[0.1166008871562069, 0.006221586329733097, 0.09532205048763782, 0.056997033223885586]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 3 3]\n",
      " [3 0 1]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 0 1]\n",
      " [3 3 3]\n",
      " [1 1 2]\n",
      " [1 1 0]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 3 3]\n",
      "\n",
      "\n",
      "Generation:  40\n",
      "Population of Chromosomes:\n",
      "[[1 0 1]\n",
      " [3 3 3]\n",
      " [1 1 2]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.09462912943588243\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09462912943588243, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9030 - mse: 160.9030 - mae: 12.4186\n",
      "Fitness Value:  0.006224926292582525\n",
      "Max Fitness Value of the Population : 0.006224926292582525\n",
      "[0.006224926292582525]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.05376632258416051\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.05376632258416051, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.8447 - mse: 3.8447 - mae: 1.7518\n",
      "Fitness Value:  0.2601115202991608\n",
      "Max Fitness Value of the Population : 0.2601115202991608\n",
      "[0.006224926292582525, 0.2601115202991608]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.048231306103311146\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.048231306103311146, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 930us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.2601115202991608\n",
      "[0.006224926292582525, 0.2601115202991608, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.07762782260189162\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.07762782260189162, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.2601115202991608\n",
      "[0.006224926292582525, 0.2601115202991608, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 1 2]\n",
      "\n",
      "\n",
      "Generation:  41\n",
      "Population of Chromosomes:\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.09139062942529458\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09139062942529458, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 985us/step - loss: 160.9827 - mse: 160.9827 - mae: 12.4207\n",
      "Fitness Value:  0.006221848919826808\n",
      "Max Fitness Value of the Population : 0.006221848919826808\n",
      "[0.006221848919826808]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.05890335925066031\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.05890335925066031, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 23.8890 - mse: 23.8890 - mae: 4.7342\n",
      "Fitness Value:  0.04187034071089157\n",
      "Max Fitness Value of the Population : 0.04187034071089157\n",
      "[0.006221848919826808, 0.04187034071089157]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.042949274902316426\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.042949274902316426, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.04187034071089157\n",
      "[0.006221848919826808, 0.04187034071089157, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.03263288652082637\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03263288652082637, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 7.3210 - mse: 7.3210 - mae: 2.5044\n",
      "Fitness Value:  0.1366025234268183\n",
      "Max Fitness Value of the Population : 0.1366025234268183\n",
      "[0.006221848919826808, 0.04187034071089157, 0.006221586329733097, 0.1366025234268183]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 1 0]\n",
      " [1 1 2]\n",
      " [1 3 3]\n",
      " [3 0 1]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 1 2]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [3 3 3]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 1 0]\n",
      "\n",
      "\n",
      "Generation:  42\n",
      "Population of Chromosomes:\n",
      "[[1 1 2]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [3 3 3]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.033613730979356396\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.033613730979356396, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.6359 - mse: 4.6359 - mae: 1.9477\n",
      "Fitness Value:  0.21571784433584748\n",
      "Max Fitness Value of the Population : 0.21571784433584748\n",
      "[0.21571784433584748]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.034184529858245695\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.034184529858245695, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 17.1255 - mse: 17.1255 - mae: 3.9588\n",
      "Fitness Value:  0.05840233956941709\n",
      "Max Fitness Value of the Population : 0.21571784433584748\n",
      "[0.21571784433584748, 0.05840233956941709]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.018745614431465867\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.018745614431465867, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 23.8755 - mse: 23.8755 - mae: 4.7389\n",
      "Fitness Value:  0.04189402038918919\n",
      "Max Fitness Value of the Population : 0.21571784433584748\n",
      "[0.21571784433584748, 0.05840233956941709, 0.04189402038918919]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.013510045781854444\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.013510045781854444, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.21571784433584748\n",
      "[0.21571784433584748, 0.05840233956941709, 0.04189402038918919, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 3 3]\n",
      "\n",
      "\n",
      "Generation:  43\n",
      "Population of Chromosomes:\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.03841303911066912\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03841303911066912, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 7.9785 - mse: 7.9785 - mae: 2.6661\n",
      "Fitness Value:  0.1253467995580719\n",
      "Max Fitness Value of the Population : 0.1253467995580719\n",
      "[0.1253467995580719]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.05326095729761207\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.05326095729761207, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 50.9056 - mse: 50.9056 - mae: 6.9404\n",
      "Fitness Value:  0.019654213899099642\n",
      "Max Fitness Value of the Population : 0.1253467995580719\n",
      "[0.1253467995580719, 0.019654213899099642]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.017121593389808516\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.017121593389808516, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 19.1133 - mse: 19.1133 - mae: 4.2424\n",
      "Fitness Value:  0.05232947844977919\n",
      "Max Fitness Value of the Population : 0.1253467995580719\n",
      "[0.1253467995580719, 0.019654213899099642, 0.05232947844977919]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.06266413514926931\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06266413514926931, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.1253467995580719\n",
      "[0.1253467995580719, 0.019654213899099642, 0.05232947844977919, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 3 3]\n",
      " [3 0 1]\n",
      " [1 1 2]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 0 1]\n",
      " [3 3 3]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 3 3]\n",
      "\n",
      "\n",
      "Generation:  44\n",
      "Population of Chromosomes:\n",
      "[[1 0 1]\n",
      " [3 3 3]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.04321370192058966\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.04321370192058966, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.018359336694782635\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.018359336694782635, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 6.2561 - mse: 6.2561 - mae: 2.2878\n",
      "Fitness Value:  0.15985526697179123\n",
      "Max Fitness Value of the Population : 0.15985526697179123\n",
      "[0.006221586329733097, 0.15985526697179123]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.06858390242208279\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06858390242208279, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.15985526697179123\n",
      "[0.006221586329733097, 0.15985526697179123, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.06007360914197261\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06007360914197261, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.15985526697179123\n",
      "[0.006221586329733097, 0.15985526697179123, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 1 2]\n",
      "\n",
      "\n",
      "Generation:  45\n",
      "Population of Chromosomes:\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.06235840304381887\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06235840304381887, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.029566050479968523\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.029566050479968523, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 14.5082 - mse: 14.5082 - mae: 3.6237\n",
      "Fitness Value:  0.06893639004460861\n",
      "Max Fitness Value of the Population : 0.06893639004460861\n",
      "[0.006221586329733097, 0.06893639004460861]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.06710492526733963\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.06710492526733963, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 7.5147 - mse: 7.5147 - mae: 2.5794\n",
      "Fitness Value:  0.13308204792936945\n",
      "Max Fitness Value of the Population : 0.13308204792936945\n",
      "[0.006221586329733097, 0.06893639004460861, 0.13308204792936945]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.08881092667524912\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.08881092667524912, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.13308204792936945\n",
      "[0.006221586329733097, 0.06893639004460861, 0.13308204792936945, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 1 2]\n",
      " [1 3 3]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 1 2]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 3 3]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  46\n",
      "Population of Chromosomes:\n",
      "[[3 1 2]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 3 3]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.05879973143817713\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.05879973143817713, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.09015221761580165\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09015221761580165, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.08725474524957157\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.08725474524957157, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.04951023771953319\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.04951023771953319, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 938us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 3 3]\n",
      " [1 1 2]\n",
      " [3 0 1]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 3 3]\n",
      "\n",
      "\n",
      "Generation:  47\n",
      "Population of Chromosomes:\n",
      "[[1 1 2]\n",
      " [1 3 3]\n",
      " [3 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.014818035099087547\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.014818035099087547, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 909us/step - loss: 8.9645 - mse: 8.9645 - mae: 2.7976\n",
      "Fitness Value:  0.1115605077600441\n",
      "Max Fitness Value of the Population : 0.1115605077600441\n",
      "[0.1115605077600441]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.09950737192183408\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09950737192183408, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 926us/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.1115605077600441\n",
      "[0.1115605077600441, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.020181452563601793\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.020181452563601793, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.5879 - mse: 4.5879 - mae: 1.8828\n",
      "Fitness Value:  0.21797536337607515\n",
      "Max Fitness Value of the Population : 0.21797536337607515\n",
      "[0.1115605077600441, 0.006221586329733097, 0.21797536337607515]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.07675445561692712\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.07675445561692712, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.21797536337607515\n",
      "[0.1115605077600441, 0.006221586329733097, 0.21797536337607515, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 3 3]\n",
      " [1 1 2]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n",
      "Generation:  48\n",
      "Population of Chromosomes:\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.00757951168474646\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.00757951168474646, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 15.6776 - mse: 15.6776 - mae: 3.8040\n",
      "Fitness Value:  0.06379512231195762\n",
      "Max Fitness Value of the Population : 0.06379512231195762\n",
      "[0.06379512231195762]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.03129872894979315\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.03129872894979315, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.5311 - mse: 5.5311 - mae: 2.0706\n",
      "Fitness Value:  0.1808051219028579\n",
      "Max Fitness Value of the Population : 0.1808051219028579\n",
      "[0.06379512231195762, 0.1808051219028579]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.08846886662907526\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.08846886662907526, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.1808051219028579\n",
      "[0.06379512231195762, 0.1808051219028579, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.026301663052275083\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.026301663052275083, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 9.7531 - mse: 9.7531 - mae: 2.9584\n",
      "Fitness Value:  0.10254185957605048\n",
      "Max Fitness Value of the Population : 0.1808051219028579\n",
      "[0.06379512231195762, 0.1808051219028579, 0.006221586329733097, 0.10254185957605048]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[1 1 2]\n",
      " [1 1 0]\n",
      " [1 3 3]\n",
      " [3 0 1]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[1 1 0]\n",
      " [1 1 2]\n",
      " [1 0 1]\n",
      " [3 3 3]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[1 1 2]\n",
      "\n",
      "\n",
      "Generation:  49\n",
      "Population of Chromosomes:\n",
      "[[1 1 0]\n",
      " [1 1 2]\n",
      " [1 0 1]\n",
      " [3 3 3]]\n",
      "\n",
      "<---Breeding--->\n",
      "Chromosome per population : 4\n",
      "Chromosome : 0\n",
      "Learning Rate:  0.04493090475755602\n",
      "Batch Size: 36\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.04493090475755602, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 1\n",
      "Learning Rate:  0.044107954973719034\n",
      "Batch Size: 24\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.044107954973719034, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006221586329733097\n",
      "[0.006221586329733097, 0.006221586329733097]\n",
      "\n",
      "\n",
      "Chromosome : 2\n",
      "Learning Rate:  0.09804860600120952\n",
      "Batch Size: 12\n",
      "Number of Epochs : 500\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.09804860600120952, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 148.3577 - mse: 148.3577 - mae: 11.9017\n",
      "Fitness Value:  0.006750468016975003\n",
      "Max Fitness Value of the Population : 0.006750468016975003\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006750468016975003]\n",
      "\n",
      "\n",
      "Chromosome : 3\n",
      "Learning Rate:  0.08209970250310397\n",
      "Batch Size: 6\n",
      "Number of Epochs : 200\n",
      "\n",
      "\n",
      "{'name': 'Adam', 'learning_rate': 0.08209970250310397, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 160.9895 - mse: 160.9895 - mae: 12.4211\n",
      "Fitness Value:  0.006221586329733097\n",
      "Max Fitness Value of the Population : 0.006750468016975003\n",
      "[0.006221586329733097, 0.006221586329733097, 0.006750468016975003, 0.006221586329733097]\n",
      "\n",
      "\n",
      "\n",
      "<---Sorting--->\n",
      "[[3 0 1]\n",
      " [1 3 3]\n",
      " [1 1 2]\n",
      " [1 1 0]]\n",
      "\n",
      "<---Crossover--->\n",
      "After Crossover\n",
      "[[3 3 3]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 2]]\n",
      "Previous Generation Chromosome is better:\n",
      "Current fittest Chromosome :\n",
      "[3 0 1]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fVal_gen, max_fVal, idx_max_fVal, fittest_chromosome = ga_run(new_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "interesting-persian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis= list(range(len(fVal_gen)))\n",
    "x_ticks = x_axis\n",
    "x_labels = x_axis\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(x_axis, fVal_gen)\n",
    "\n",
    "ax.xaxis.set_ticks(x_ticks)\n",
    "ax.xaxis.set_ticklabels(x_labels)\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Fitness Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "first-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fittest Generation: \", idx_max_fVal)\n",
    "print(\"Fittest Chromosome's Fitness Value: \", max_fVal)\n",
    "print(\"Fittest Chromosome: \", fittest_chromosome)\n",
    "\n",
    "print(\"\\nBest Hyperparameters found using Genetic Algorithm:\")\n",
    "print(\"Learning Rate :\\t Check the Learning Rate from the Generation index\")\n",
    "print(\"Batch Size :\\t\",hyperparams_batchSize[fittest_chromosome[2]])\n",
    "print(\"No of Epochs :\\t\",hyperparams_noEpochs[fittest_chromosome[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-reggae",
   "metadata": {},
   "source": [
    "## Building model based on the \"Best Chromosome\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-baseline",
   "metadata": {},
   "source": [
    "By using above Hyperparameters(best Hyperparameter foudn using GA), we build a model again and train it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-municipality",
   "metadata": {},
   "source": [
    "For now, check the learning rate thru the generation's index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "furnished-demographic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate :\t 0.1\n",
      "Batch Size :\t 12\n",
      "No of Epochs :\t 500\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_hyperparams = fittest_chromosome[:]\n",
    "best_LR = hyperparams_learningRate[best_hyperparams[1]]\n",
    "best_BatchSize = hyperparams_batchSize[best_hyperparams[2]]\n",
    "best_noOfEpochs = hyperparams_noEpochs[best_hyperparams[0]]\n",
    "\n",
    "print(\"Learning Rate :\\t\",best_LR)\n",
    "print(\"Batch Size :\\t\", best_BatchSize)\n",
    "print(\"No of Epochs :\\t\",best_noOfEpochs)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "allied-norway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Adam', 'learning_rate': 0.037821830540085054, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,281\n",
      "Trainable params: 5,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(\n",
    "#       theLearningRate = best_LR \n",
    "        theLearningRate = 0.037821830540085054\n",
    "        )\n",
    "\n",
    "print(model.optimizer.get_config())\n",
    "print(\"\\n\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "responsible-snake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7367 - mse: 0.7367 - mae: 0.5285 - val_loss: 0.2293 - val_mse: 0.2293 - val_mae: 0.4349\n",
      "Epoch 2/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0925 - mse: 0.0925 - mae: 0.2444 - val_loss: 0.0691 - val_mse: 0.0691 - val_mae: 0.2178\n",
      "Epoch 3/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0359 - mse: 0.0359 - mae: 0.1586 - val_loss: 0.0534 - val_mse: 0.0534 - val_mae: 0.1828\n",
      "Epoch 4/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - mae: 0.1297 - val_loss: 0.0287 - val_mse: 0.0287 - val_mae: 0.1246\n",
      "Epoch 5/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - mae: 0.1096 - val_loss: 0.0254 - val_mse: 0.0254 - val_mae: 0.1260\n",
      "Epoch 6/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - mae: 0.1146 - val_loss: 0.0180 - val_mse: 0.0180 - val_mae: 0.1055\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0889 - val_loss: 0.0169 - val_mse: 0.0169 - val_mae: 0.1032\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0835 - val_loss: 0.0193 - val_mse: 0.0193 - val_mae: 0.1095\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0864 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.1148\n",
      "Epoch 10/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0846 - val_loss: 0.0154 - val_mse: 0.0154 - val_mae: 0.0989\n",
      "Epoch 11/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0089 - mae: 0.0740 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.0991\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0689 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0892\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0577 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0875\n",
      "Epoch 14/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0598 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0802\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0553 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0768\n",
      "Epoch 16/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0576 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0861\n",
      "Epoch 17/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0683 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0768\n",
      "Epoch 18/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0586 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0763\n",
      "Epoch 19/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0606 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0839\n",
      "Epoch 20/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0504 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0805\n",
      "Epoch 21/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0537 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0797\n",
      "Epoch 22/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0572 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0828\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0584 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0734\n",
      "Epoch 24/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0596 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0758\n",
      "Epoch 25/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0535 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0725\n",
      "Epoch 26/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0490 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0696\n",
      "Epoch 27/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0489 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0744\n",
      "Epoch 28/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0494 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0762\n",
      "Epoch 29/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0479 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0708\n",
      "Epoch 30/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0485 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0705\n",
      "Epoch 31/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0550 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0719\n",
      "Epoch 32/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0546 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0790\n",
      "Epoch 33/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0567 - val_loss: 0.0077 - val_mse: 0.0077 - val_mae: 0.0692\n",
      "Epoch 34/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0484 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0752\n",
      "Epoch 35/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0521 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0684\n",
      "Epoch 36/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0583 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0896\n",
      "Epoch 37/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0552 - val_loss: 0.0076 - val_mse: 0.0076 - val_mae: 0.0688\n",
      "Epoch 38/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0520 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0782\n",
      "Epoch 39/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0488 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0717\n",
      "Epoch 40/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0477 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0769\n",
      "Epoch 41/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0450 - val_loss: 0.0088 - val_mse: 0.0088 - val_mae: 0.0749\n",
      "Epoch 42/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0485 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0825\n",
      "Epoch 43/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0475 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0763\n",
      "Epoch 44/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0408 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0809\n",
      "Epoch 45/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0519 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0717\n",
      "Epoch 46/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0518 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0812\n",
      "Epoch 47/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0464 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0727\n",
      "Epoch 48/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0431 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0713\n",
      "Epoch 49/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0450 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0777\n",
      "Epoch 50/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0464 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0810\n",
      "Epoch 51/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0457 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0770\n",
      "Epoch 52/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0417 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0801\n",
      "Epoch 53/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0460 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0855\n",
      "Epoch 54/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0535 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0783\n",
      "Epoch 55/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0521 - val_loss: 0.0088 - val_mse: 0.0088 - val_mae: 0.0751\n",
      "Epoch 56/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0491 - val_loss: 0.0163 - val_mse: 0.0163 - val_mae: 0.1050\n",
      "Epoch 57/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0625 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0776\n",
      "Epoch 58/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0686 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.1166\n",
      "Epoch 59/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0638 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0806\n",
      "Epoch 60/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0534 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0855\n",
      "Epoch 61/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0607 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0762\n",
      "Epoch 62/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0555 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0824\n",
      "Epoch 63/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0580 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0836\n",
      "Epoch 64/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0490 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.1130\n",
      "Epoch 65/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0540 - val_loss: 0.0143 - val_mse: 0.0143 - val_mae: 0.0929\n",
      "Epoch 66/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0555 - val_loss: 0.0135 - val_mse: 0.0135 - val_mae: 0.0948\n",
      "Epoch 67/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0504 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0814\n",
      "Epoch 68/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0425 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0713\n",
      "Epoch 69/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0433 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0822\n",
      "Epoch 70/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0460 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0770\n",
      "Epoch 71/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0490 - val_loss: 0.0162 - val_mse: 0.0162 - val_mae: 0.0988\n",
      "Epoch 72/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0511 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0881\n",
      "Epoch 73/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0458 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0784\n",
      "Epoch 74/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0419 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0797\n",
      "Epoch 75/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0432 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0774\n",
      "Epoch 76/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0372 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0771\n",
      "Epoch 77/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0435 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0801\n",
      "Epoch 78/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0430 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0806\n",
      "Epoch 79/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0511 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0835\n",
      "Epoch 80/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0513 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0849\n",
      "Epoch 81/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0424 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0747\n",
      "Epoch 82/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0417 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0703\n",
      "Epoch 83/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0421 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0884\n",
      "Epoch 84/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0417 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0719\n",
      "Epoch 85/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0447 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0770\n",
      "Epoch 86/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0513 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0731\n",
      "Epoch 87/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0402 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0774\n",
      "Epoch 88/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0399 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0816\n",
      "Epoch 89/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0408 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0804\n",
      "Epoch 90/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0378 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0770\n",
      "Epoch 91/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0386 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0750\n",
      "Epoch 92/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0419 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0857\n",
      "Epoch 93/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0407 - val_loss: 0.0143 - val_mse: 0.0143 - val_mae: 0.0942\n",
      "Epoch 94/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0423 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0741\n",
      "Epoch 95/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0520 - val_loss: 0.0160 - val_mse: 0.0160 - val_mae: 0.1061\n",
      "Epoch 96/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0524 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0728\n",
      "Epoch 97/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0515 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0838\n",
      "Epoch 98/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0451 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0722\n",
      "Epoch 99/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0406 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0838\n",
      "Epoch 100/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0517 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0784\n",
      "Epoch 101/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0530 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0818\n",
      "Epoch 102/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0402 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0846\n",
      "Epoch 103/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0397 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0826\n",
      "Epoch 104/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0383 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0838\n",
      "Epoch 105/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0400 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0792\n",
      "Epoch 106/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0359 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0773\n",
      "Epoch 107/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0397 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0718\n",
      "Epoch 108/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0433 - val_loss: 0.0138 - val_mse: 0.0138 - val_mae: 0.0923\n",
      "Epoch 109/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0438 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0765\n",
      "Epoch 110/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0364 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0757\n",
      "Epoch 111/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0366 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0828\n",
      "Epoch 112/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0368 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0764\n",
      "Epoch 113/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - mae: 0.1089 - val_loss: 0.0230 - val_mse: 0.0230 - val_mae: 0.1222\n",
      "Epoch 114/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0155 - mae: 0.0981 - val_loss: 0.0167 - val_mse: 0.0167 - val_mae: 0.1046\n",
      "Epoch 115/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - mae: 0.1131 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0873\n",
      "Epoch 116/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0801 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.1236\n",
      "Epoch 117/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0807 - val_loss: 0.0151 - val_mse: 0.0151 - val_mae: 0.1006\n",
      "Epoch 118/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0619 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0900\n",
      "Epoch 119/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0568 - val_loss: 0.0154 - val_mse: 0.0154 - val_mae: 0.0998\n",
      "Epoch 120/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0500 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0844\n",
      "Epoch 121/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0480 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0881\n",
      "Epoch 122/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0429 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0900\n",
      "Epoch 123/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0433 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0824\n",
      "Epoch 124/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0437 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0824\n",
      "Epoch 125/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0396 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0880\n",
      "Epoch 126/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0433 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0797\n",
      "Epoch 127/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0413 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0776\n",
      "Epoch 128/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0440 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0801\n",
      "Epoch 129/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0432 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0807\n",
      "Epoch 130/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0399 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0787\n",
      "Epoch 131/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0405 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0823\n",
      "Epoch 132/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0421 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0760\n",
      "Epoch 133/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0487 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0929\n",
      "Epoch 134/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0468 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0806\n",
      "Epoch 135/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0444 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0800\n",
      "Epoch 136/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0372 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0737\n",
      "Epoch 137/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0412 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0820\n",
      "Epoch 138/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0391 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0731\n",
      "Epoch 139/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0386 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0747\n",
      "Epoch 140/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0353 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0780\n",
      "Epoch 141/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0339 - val_loss: 0.0132 - val_mse: 0.0132 - val_mae: 0.0910\n",
      "Epoch 142/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0371 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0728\n",
      "Epoch 143/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0398 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0749\n",
      "Epoch 144/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0360 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0813\n",
      "Epoch 145/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0408 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0736\n",
      "Epoch 146/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0361 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0821\n",
      "Epoch 147/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0366 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0728\n",
      "Epoch 148/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0370 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0715\n",
      "Epoch 149/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0424 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0764\n",
      "Epoch 150/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0398 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0334 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0704\n",
      "Epoch 152/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0412 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0721\n",
      "Epoch 153/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0339 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0755\n",
      "Epoch 154/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0392 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0719\n",
      "Epoch 155/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0385 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0734\n",
      "Epoch 156/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0364 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0764\n",
      "Epoch 157/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0335 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0784\n",
      "Epoch 158/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0367 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0767\n",
      "Epoch 159/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0333 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0781\n",
      "Epoch 160/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0404 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0787\n",
      "Epoch 161/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0357 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0738\n",
      "Epoch 162/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0377 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0861\n",
      "Epoch 163/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0391 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0788\n",
      "Epoch 164/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0378 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0734\n",
      "Epoch 165/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0365 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0775\n",
      "Epoch 166/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0344 - val_loss: 0.0088 - val_mse: 0.0088 - val_mae: 0.0724\n",
      "Epoch 167/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0342 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0811\n",
      "Epoch 168/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0309 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0849\n",
      "Epoch 169/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0377 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0741\n",
      "Epoch 170/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0464 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0783\n",
      "Epoch 171/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0489 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0875\n",
      "Epoch 172/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0446 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0760\n",
      "Epoch 173/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0357 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0759\n",
      "Epoch 174/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0383 - val_loss: 0.0135 - val_mse: 0.0135 - val_mae: 0.0888\n",
      "Epoch 175/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0398 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0776\n",
      "Epoch 176/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0362 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0814\n",
      "Epoch 177/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0342 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0747\n",
      "Epoch 178/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0338 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0765\n",
      "Epoch 179/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0330 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0771\n",
      "Epoch 180/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0361 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0809\n",
      "Epoch 181/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0367 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0757\n",
      "Epoch 182/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0401 - val_loss: 0.0161 - val_mse: 0.0161 - val_mae: 0.0983\n",
      "Epoch 183/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0415 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0721\n",
      "Epoch 184/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0361 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0800\n",
      "Epoch 185/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0363 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0742\n",
      "Epoch 186/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0352 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0863\n",
      "Epoch 187/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0357 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0766\n",
      "Epoch 188/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0357 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0753\n",
      "Epoch 189/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0441 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0809\n",
      "Epoch 190/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0406 - val_loss: 0.0153 - val_mse: 0.0153 - val_mae: 0.0973\n",
      "Epoch 191/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0506 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0777\n",
      "Epoch 192/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0412 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0770\n",
      "Epoch 193/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0396 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0871\n",
      "Epoch 194/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0462 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0826\n",
      "Epoch 195/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0416 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0770\n",
      "Epoch 196/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0353 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0803\n",
      "Epoch 197/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0380 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0711\n",
      "Epoch 198/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0490 - val_loss: 0.0141 - val_mse: 0.0141 - val_mae: 0.0910\n",
      "Epoch 199/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0577 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0766\n",
      "Epoch 200/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0452 - val_loss: 0.0160 - val_mse: 0.0160 - val_mae: 0.0971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0426 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0851\n",
      "Epoch 202/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0486 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0846\n",
      "Epoch 203/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0390 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0776\n",
      "Epoch 204/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0414 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0762\n",
      "Epoch 205/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0371 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0788\n",
      "Epoch 206/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0394 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0824\n",
      "Epoch 207/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0419 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0806\n",
      "Epoch 208/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0461 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0790\n",
      "Epoch 209/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0416 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0781\n",
      "Epoch 210/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0423 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0810\n",
      "Epoch 211/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0392 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0893\n",
      "Epoch 212/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0403 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0795\n",
      "Epoch 213/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0371 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0762\n",
      "Epoch 214/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0398 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0766\n",
      "Epoch 215/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0385 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0736\n",
      "Epoch 216/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0375 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0752\n",
      "Epoch 217/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0354 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0769\n",
      "Epoch 218/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0348 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0859\n",
      "Epoch 219/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0345 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0743\n",
      "Epoch 220/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0308 - val_loss: 0.0146 - val_mse: 0.0146 - val_mae: 0.0944\n",
      "Epoch 221/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0484 - val_loss: 0.0148 - val_mse: 0.0148 - val_mae: 0.1006\n",
      "Epoch 222/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0520 - val_loss: 0.0119 - val_mse: 0.0119 - val_mae: 0.0899\n",
      "Epoch 223/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0603 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0864\n",
      "Epoch 224/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0401 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0788\n",
      "Epoch 225/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0406 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0740\n",
      "Epoch 226/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0391 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0731\n",
      "Epoch 227/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0493 - val_loss: 0.0180 - val_mse: 0.0180 - val_mae: 0.1067\n",
      "Epoch 228/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0527 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0810\n",
      "Epoch 229/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0454 - val_loss: 0.0230 - val_mse: 0.0230 - val_mae: 0.1246\n",
      "Epoch 230/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0513 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0811\n",
      "Epoch 231/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0447 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0869\n",
      "Epoch 232/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0381 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0767\n",
      "Epoch 233/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0409 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0793\n",
      "Epoch 234/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0400 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0821\n",
      "Epoch 235/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0402 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0797\n",
      "Epoch 236/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0334 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0853\n",
      "Epoch 237/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0334 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0779\n",
      "Epoch 238/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0337 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0826\n",
      "Epoch 239/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0314 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0764\n",
      "Epoch 240/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0325 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0799\n",
      "Epoch 241/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0300 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0835\n",
      "Epoch 242/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0406 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0832\n",
      "Epoch 243/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0341 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0943\n",
      "Epoch 244/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0330 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0917\n",
      "Epoch 245/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0446 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0823\n",
      "Epoch 246/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0382 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0836\n",
      "Epoch 247/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0420 - val_loss: 0.0138 - val_mse: 0.0138 - val_mae: 0.0884\n",
      "Epoch 248/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0449 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0793\n",
      "Epoch 249/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0483 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0808\n",
      "Epoch 250/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0389 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0364 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0819\n",
      "Epoch 252/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0331 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0973\n",
      "Epoch 253/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0393 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0839\n",
      "Epoch 254/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0422 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0785\n",
      "Epoch 255/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0422 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0752\n",
      "Epoch 256/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0457 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0894\n",
      "Epoch 257/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0505 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0802\n",
      "Epoch 258/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0421 - val_loss: 0.0137 - val_mse: 0.0137 - val_mae: 0.0937\n",
      "Epoch 259/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0380 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0813\n",
      "Epoch 260/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0318 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0793\n",
      "Epoch 261/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0352 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0818\n",
      "Epoch 262/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0480 - val_loss: 0.0119 - val_mse: 0.0119 - val_mae: 0.0844\n",
      "Epoch 263/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0426 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0822\n",
      "Epoch 264/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0424 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0881\n",
      "Epoch 265/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0430 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0841\n",
      "Epoch 266/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0404 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0809\n",
      "Epoch 267/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0434 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0855\n",
      "Epoch 268/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0412 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0880\n",
      "Epoch 269/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0379 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0890\n",
      "Epoch 270/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0365 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0820\n",
      "Epoch 271/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0323 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0877\n",
      "Epoch 272/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0310 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0812\n",
      "Epoch 273/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0313 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0816\n",
      "Epoch 274/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0346 - val_loss: 0.0144 - val_mse: 0.0144 - val_mae: 0.0959\n",
      "Epoch 275/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0350 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0771\n",
      "Epoch 276/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0326 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0834\n",
      "Epoch 277/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0332 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0897\n",
      "Epoch 278/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0309 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0841\n",
      "Epoch 279/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0435 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0841\n",
      "Epoch 280/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0426 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0763\n",
      "Epoch 281/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0537 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0790\n",
      "Epoch 282/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0385 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0913\n",
      "Epoch 283/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0332 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0841\n",
      "Epoch 284/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0345 - val_loss: 0.0119 - val_mse: 0.0119 - val_mae: 0.0872\n",
      "Epoch 285/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0402 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0804\n",
      "Epoch 286/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0424 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0777\n",
      "Epoch 287/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0466 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0833\n",
      "Epoch 288/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0517 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0778\n",
      "Epoch 289/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0425 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0813\n",
      "Epoch 290/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0391 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0689\n",
      "Epoch 291/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0391 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0867\n",
      "Epoch 292/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0397 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0813\n",
      "Epoch 293/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0377 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0849\n",
      "Epoch 294/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0405 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0846\n",
      "Epoch 295/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0428 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0715\n",
      "Epoch 296/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0429 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0732\n",
      "Epoch 297/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0501 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0743\n",
      "Epoch 298/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0542 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0782\n",
      "Epoch 299/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0394 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0763\n",
      "Epoch 300/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0398 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0401 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0882\n",
      "Epoch 302/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0381 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0903\n",
      "Epoch 303/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0549 - val_loss: 0.0146 - val_mse: 0.0146 - val_mae: 0.0953\n",
      "Epoch 304/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0414 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0705\n",
      "Epoch 305/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0389 - val_loss: 0.0134 - val_mse: 0.0134 - val_mae: 0.0850\n",
      "Epoch 306/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0381 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0955\n",
      "Epoch 307/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0423 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0774\n",
      "Epoch 308/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0391 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0855\n",
      "Epoch 309/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0464 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0851\n",
      "Epoch 310/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0397 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0776\n",
      "Epoch 311/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0395 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0866\n",
      "Epoch 312/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0346 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0864\n",
      "Epoch 313/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0313 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0809\n",
      "Epoch 314/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0356 - val_loss: 0.0153 - val_mse: 0.0153 - val_mae: 0.0970\n",
      "Epoch 315/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0393 - val_loss: 0.0135 - val_mse: 0.0135 - val_mae: 0.0990\n",
      "Epoch 316/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0470 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0892\n",
      "Epoch 317/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0421 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0763\n",
      "Epoch 318/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0485 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0909\n",
      "Epoch 319/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0438 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0826\n",
      "Epoch 320/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0335 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0794\n",
      "Epoch 321/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0366 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0854\n",
      "Epoch 322/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0360 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0893\n",
      "Epoch 323/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0419 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0736\n",
      "Epoch 324/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0397 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0890\n",
      "Epoch 325/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0341 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0784\n",
      "Epoch 326/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0377 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0885\n",
      "Epoch 327/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0301 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0822\n",
      "Epoch 328/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0332 - val_loss: 0.0135 - val_mse: 0.0135 - val_mae: 0.0913\n",
      "Epoch 329/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0328 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0823\n",
      "Epoch 330/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0327 - val_loss: 0.0162 - val_mse: 0.0162 - val_mae: 0.0990\n",
      "Epoch 331/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0393 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0859\n",
      "Epoch 332/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0409 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0824\n",
      "Epoch 333/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0405 - val_loss: 0.0170 - val_mse: 0.0170 - val_mae: 0.1019\n",
      "Epoch 334/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0431 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0786\n",
      "Epoch 335/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0320 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0849\n",
      "Epoch 336/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0332 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0759\n",
      "Epoch 337/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0346 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0828\n",
      "Epoch 338/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0346 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0756\n",
      "Epoch 339/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0362 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0986\n",
      "Epoch 340/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0452 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0879\n",
      "Epoch 341/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0439 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0873\n",
      "Epoch 342/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0420 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0887\n",
      "Epoch 343/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0401 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0850\n",
      "Epoch 344/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0400 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0840\n",
      "Epoch 345/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0501 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0804\n",
      "Epoch 346/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0396 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0757\n",
      "Epoch 347/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0336 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0753\n",
      "Epoch 348/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0338 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0740\n",
      "Epoch 349/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0316 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0751\n",
      "Epoch 350/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0385 - val_loss: 0.0137 - val_mse: 0.0137 - val_mae: 0.0962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0405 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0832\n",
      "Epoch 352/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0336 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0748\n",
      "Epoch 353/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0436 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0840\n",
      "Epoch 354/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0476 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0872\n",
      "Epoch 355/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0523 - val_loss: 0.0177 - val_mse: 0.0177 - val_mae: 0.1030\n",
      "Epoch 356/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0487 - val_loss: 0.0138 - val_mse: 0.0138 - val_mae: 0.0918\n",
      "Epoch 357/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0408 - val_loss: 0.0137 - val_mse: 0.0137 - val_mae: 0.0903\n",
      "Epoch 358/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0398 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0772\n",
      "Epoch 359/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0335 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0759\n",
      "Epoch 360/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0302 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0775\n",
      "Epoch 361/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0291 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0785\n",
      "Epoch 362/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0288 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0759\n",
      "Epoch 363/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0354 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0735\n",
      "Epoch 364/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0374 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0875\n",
      "Epoch 365/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0406 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0779\n",
      "Epoch 366/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0402 - val_loss: 0.0167 - val_mse: 0.0167 - val_mae: 0.0989\n",
      "Epoch 367/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0419 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0877\n",
      "Epoch 368/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0403 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0831\n",
      "Epoch 369/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0359 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0788\n",
      "Epoch 370/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0550 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0766\n",
      "Epoch 371/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0581 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0878\n",
      "Epoch 372/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0569 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0796\n",
      "Epoch 373/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0523 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0749\n",
      "Epoch 374/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0432 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0767\n",
      "Epoch 375/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0402 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0681\n",
      "Epoch 376/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0374 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0872\n",
      "Epoch 377/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0368 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0826\n",
      "Epoch 378/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0312 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0807\n",
      "Epoch 379/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0378 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0749\n",
      "Epoch 380/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0378 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0761\n",
      "Epoch 381/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0358 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0822\n",
      "Epoch 382/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0323 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0795\n",
      "Epoch 383/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0358 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0819\n",
      "Epoch 384/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0339 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0814\n",
      "Epoch 385/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0294 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0725\n",
      "Epoch 386/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0322 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0882\n",
      "Epoch 387/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0407 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0884\n",
      "Epoch 388/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0411 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.1125\n",
      "Epoch 389/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0464 - val_loss: 0.0088 - val_mse: 0.0088 - val_mae: 0.0723\n",
      "Epoch 390/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0365 - val_loss: 0.0151 - val_mse: 0.0151 - val_mae: 0.0962\n",
      "Epoch 391/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0392 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0833\n",
      "Epoch 392/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0369 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0781\n",
      "Epoch 393/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0360 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0817\n",
      "Epoch 394/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0362 - val_loss: 0.0119 - val_mse: 0.0119 - val_mae: 0.0870\n",
      "Epoch 395/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0376 - val_loss: 0.0119 - val_mse: 0.0119 - val_mae: 0.0833\n",
      "Epoch 396/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0348 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0763\n",
      "Epoch 397/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0403 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0882\n",
      "Epoch 398/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0484 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0798\n",
      "Epoch 399/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0395 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0803\n",
      "Epoch 400/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0522 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.1154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0685 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.1020\n",
      "Epoch 402/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0623 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.1115\n",
      "Epoch 403/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0459 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0770\n",
      "Epoch 404/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0457 - val_loss: 0.0167 - val_mse: 0.0167 - val_mae: 0.0986\n",
      "Epoch 405/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0509 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0905\n",
      "Epoch 406/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0524 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0762\n",
      "Epoch 407/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0472 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0736\n",
      "Epoch 408/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0413 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0697\n",
      "Epoch 409/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0431 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0755\n",
      "Epoch 410/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0451 - val_loss: 0.0151 - val_mse: 0.0151 - val_mae: 0.0984\n",
      "Epoch 411/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0433 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0758\n",
      "Epoch 412/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0411 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0810\n",
      "Epoch 413/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0356 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0851\n",
      "Epoch 414/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0384 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0846\n",
      "Epoch 415/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0358 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0915\n",
      "Epoch 416/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0433 - val_loss: 0.0163 - val_mse: 0.0163 - val_mae: 0.1030\n",
      "Epoch 417/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0432 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0813\n",
      "Epoch 418/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0346 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0812\n",
      "Epoch 419/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0373 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0863\n",
      "Epoch 420/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0404 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0724\n",
      "Epoch 421/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0383 - val_loss: 0.0144 - val_mse: 0.0144 - val_mae: 0.0962\n",
      "Epoch 422/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0401 - val_loss: 0.0140 - val_mse: 0.0140 - val_mae: 0.0949\n",
      "Epoch 423/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0404 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0816\n",
      "Epoch 424/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0354 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0758\n",
      "Epoch 425/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0328 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0795\n",
      "Epoch 426/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0402 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0890\n",
      "Epoch 427/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0373 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0777\n",
      "Epoch 428/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0429 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0810\n",
      "Epoch 429/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0383 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0814\n",
      "Epoch 430/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0410 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0784\n",
      "Epoch 431/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0483 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0773\n",
      "Epoch 432/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0528 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0985\n",
      "Epoch 433/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0579 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0796\n",
      "Epoch 434/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0520 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0715\n",
      "Epoch 435/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0491 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0859\n",
      "Epoch 436/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0385 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0821\n",
      "Epoch 437/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0480 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0852\n",
      "Epoch 438/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0404 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.1120\n",
      "Epoch 439/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0477 - val_loss: 0.0088 - val_mse: 0.0088 - val_mae: 0.0715\n",
      "Epoch 440/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0493 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0808\n",
      "Epoch 441/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0392 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0737\n",
      "Epoch 442/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0373 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0712\n",
      "Epoch 443/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0335 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0763\n",
      "Epoch 444/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0327 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0773\n",
      "Epoch 445/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0355 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0787\n",
      "Epoch 446/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0371 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0760\n",
      "Epoch 447/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0324 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0767\n",
      "Epoch 448/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0311 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0829\n",
      "Epoch 449/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0287 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0775\n",
      "Epoch 450/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0335 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0902\n",
      "Epoch 451/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0342 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0722\n",
      "Epoch 452/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0346 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0869\n",
      "Epoch 453/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0356 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0763\n",
      "Epoch 454/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0404 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0784\n",
      "Epoch 455/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0391 - val_loss: 0.0148 - val_mse: 0.0148 - val_mae: 0.0980\n",
      "Epoch 456/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0497 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0755\n",
      "Epoch 457/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0451 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0865\n",
      "Epoch 458/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0465 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0851\n",
      "Epoch 459/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0411 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0739\n",
      "Epoch 460/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0335 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0742\n",
      "Epoch 461/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0386 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0768\n",
      "Epoch 462/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0403 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0885\n",
      "Epoch 463/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0431 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0748\n",
      "Epoch 464/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0390 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0754\n",
      "Epoch 465/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0387 - val_loss: 0.0141 - val_mse: 0.0141 - val_mae: 0.0936\n",
      "Epoch 466/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0344 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0749\n",
      "Epoch 467/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0408 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0778\n",
      "Epoch 468/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0344 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0777\n",
      "Epoch 469/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0330 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0779\n",
      "Epoch 470/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0297 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0851\n",
      "Epoch 471/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0349 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.0999\n",
      "Epoch 472/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0373 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0794\n",
      "Epoch 473/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0343 - val_loss: 0.0143 - val_mse: 0.0143 - val_mae: 0.0965\n",
      "Epoch 474/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0393 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0839\n",
      "Epoch 475/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0405 - val_loss: 0.0138 - val_mse: 0.0138 - val_mae: 0.0942\n",
      "Epoch 476/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0375 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0797\n",
      "Epoch 477/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0314 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0781\n",
      "Epoch 478/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0336 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0787\n",
      "Epoch 479/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0372 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0725\n",
      "Epoch 480/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0352 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.1034\n",
      "Epoch 481/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0385 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0789\n",
      "Epoch 482/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0405 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0791\n",
      "Epoch 483/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0352 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0907\n",
      "Epoch 484/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0328 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0745\n",
      "Epoch 485/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0358 - val_loss: 0.0152 - val_mse: 0.0152 - val_mae: 0.0974\n",
      "Epoch 486/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0335 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0817\n",
      "Epoch 487/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0340 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0762\n",
      "Epoch 488/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0321 - val_loss: 0.0144 - val_mse: 0.0144 - val_mae: 0.0934\n",
      "Epoch 489/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0329 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0762\n",
      "Epoch 490/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0462 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0829\n",
      "Epoch 491/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0424 - val_loss: 0.0132 - val_mse: 0.0132 - val_mae: 0.0899\n",
      "Epoch 492/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0439 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0784\n",
      "Epoch 493/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0350 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.1006\n",
      "Epoch 494/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0478 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0863\n",
      "Epoch 495/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0429 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0820\n",
      "Epoch 496/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0462 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0791\n",
      "Epoch 497/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0419 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0734\n",
      "Epoch 498/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0443 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0882\n",
      "Epoch 499/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0406 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0434 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0752\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_test_scaled, \n",
    "    y_test_scaled, \n",
    "    epochs= 500, \n",
    "    batch_size= 12,  \n",
    "    \n",
    "    #epochs=best_noOfEpochs, \n",
    "    #batch_size= best_BatchSize,  \n",
    "    \n",
    "    verbose=1, \n",
    "    validation_split=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "offshore-community",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(history.history.keys())\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "meaningful-bruce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2836 - mse: 0.2836 - mae: 0.4939\n",
      "Mean Squared Error : 0.28365\n",
      "Mean Absolute Error : 0.49393\n"
     ]
    }
   ],
   "source": [
    "loss, mean_sq_e, mean_abs_e = model.evaluate(X_test_scaled, y_test_scaled)\n",
    "print(\"Mean Squared Error : {:.5f}\".format(mean_sq_e))\n",
    "print(\"Mean Absolute Error : {:.5f}\".format(mean_abs_e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-conspiracy",
   "metadata": {},
   "source": [
    "# 6. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "twenty-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_scaled)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "predictions = np.round(predictions, 2)\n",
    "# print(\"Predictions : \\n\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-joseph",
   "metadata": {},
   "source": [
    "Inference on 14th Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eleven-sampling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Values : 16.0\n",
      "Predicted G3's score is 14.94\n",
      "Difference : 1.060\n"
     ]
    }
   ],
   "source": [
    "student_index = 14\n",
    "g_truth = float(y_test_np[student_index])\n",
    "p = float(predictions[student_index])\n",
    "print(\"Real Values :\", g_truth)\n",
    "print(\"Predicted G3's score is {:.2f}\".format(p))\n",
    "diff = np.abs(p-g_truth)\n",
    "print(\"Difference : {:.3f}\".format(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-kernel",
   "metadata": {},
   "source": [
    "#### On Test Set/Unseen Data, manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "statewide-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_list = []\n",
    "\n",
    "for i in range(0,len(y_test)):\n",
    "    \n",
    "    g_truth = float(y_test_np[i])\n",
    "    p = float(predictions[i])\n",
    "    diff = np.abs(p-g_truth)\n",
    "    diff_list.append(diff)\n",
    "#     print(i)  \n",
    "#     print(\"Real Values :\", g_truth)\n",
    "#     print(\"Predicted G3's score is {:.2f}\".format(p))\n",
    "#     print(\"Difference : {:.3f}\".format(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-edwards",
   "metadata": {},
   "source": [
    "### Mean Absolute Error after applying genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "formal-colleague",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error : 0.68742\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mean_abs_e_on_test_set = sum(diff_list) / len(y_test)\n",
    "mean_abs_e_on_test_set1 = mean_absolute_error(y_test_np, predictions)\n",
    "print(\"Mean Absolute Error : {:.5f}\".format(mean_abs_e_on_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-southwest",
   "metadata": {},
   "source": [
    "Thanks for reading!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
