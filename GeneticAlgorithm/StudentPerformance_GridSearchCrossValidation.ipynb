{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solved-diary",
   "metadata": {},
   "source": [
    "# StudentPerformance_GridSearchCrossValidation\n",
    "This is a duplicate notebook from StudentPerformance_with_NN. In this notebook I will use Grid Search Cross Validation to search for optimum hyperparameter instead of doing it empirically in the previous notebook.\n",
    "\n",
    "Hyperparameters Grid Search 101: \n",
    "\n",
    "https://elutins.medium.com/grid-searching-in-machine-learning-quick-explanation-and-python-implementation-550552200596\n",
    "\n",
    "References: \n",
    "\n",
    "https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-trinity",
   "metadata": {},
   "source": [
    "### Index\n",
    "\n",
    "1. Dataset\n",
    "2. Packages Needed\n",
    "3. Data Preprocessing\n",
    "4. Grid Search Cross Validation\n",
    "5. Inference\n",
    "6. Some findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-manufacturer",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "Source: https://archive.ics.uci.edu/ml/datasets/Student+Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-provider",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. \n",
    "\n",
    "Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). \n",
    "\n",
    "### Note: In this notebook, I used the Dataset with Portuguese Language\n",
    "\n",
    "In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks. \n",
    "\n",
    "Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. \n",
    "\n",
    "This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd-period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-small",
   "metadata": {},
   "source": [
    "### Attribute Information:\n",
    "\n",
    "### Attributes for both student-mat.csv (Math course) and student-por.csv (Portuguese language course) datasets:\n",
    "\n",
    "* 1 school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)* \n",
    "* 2 sex - student's sex (binary: 'F' - female or 'M' - male)\n",
    "* 3 age - student's age (numeric: from 15 to 22)\n",
    "* 4 address - student's home address type (binary: 'U' - urban or 'R' - rural)\n",
    "* 5 famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)\n",
    "* 6 Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)\n",
    "* 7 Medu - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education)\n",
    "* 8 Fedu - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education)\n",
    "* 9 Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "* 10 Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "* 11 reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\n",
    "* 12 guardian - student's guardian (nominal: 'mother', 'father' or 'other')\n",
    "* 13 traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    "* 14 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    "* 15 failures - number of past class failures (numeric: n if 1<=n<3, else 4)\n",
    "* 16 schoolsup - extra educational support (binary: yes or no)\n",
    "* 17 famsup - family educational support (binary: yes or no)\n",
    "* 18 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    "* 19 activities - extra-curricular activities (binary: yes or no)\n",
    "* 20 nursery - attended nursery school (binary: yes or no)\n",
    "* 21 higher - wants to take higher education (binary: yes or no)\n",
    "* 22 internet - Internet access at home (binary: yes or no)\n",
    "* 23 romantic - with a romantic relationship (binary: yes or no)\n",
    "* 24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "* 25 freetime - free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "* 26 goout - going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "* 27 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "* 28 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "* 29 health - current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "* 30 absences - number of school absences (numeric: from 0 to 93)\n",
    "\n",
    "#### these grades are related with the course subject, Math or Portuguese:\n",
    "* 31 G1 - first period grade (numeric: from 0 to 20)\n",
    "* 31 G2 - second period grade (numeric: from 0 to 20)\n",
    "* 32 G3 - final grade (numeric: from 0 to 20, output target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-staff",
   "metadata": {},
   "source": [
    "## 2. Packages Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "integrated-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-roulette",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing\n",
    "\n",
    "Here, I will find for empty data, encode categorical data, plot some graph to understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "continued-opposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>home</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>home</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>R</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>teacher</td>\n",
       "      <td>services</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>R</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
       "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
       "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
       "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
       "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
       "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
       "644     MS   F   19       R     GT3       T     2     3  services     other   \n",
       "645     MS   F   18       U     LE3       T     3     1   teacher  services   \n",
       "646     MS   F   18       U     GT3       T     1     1     other     other   \n",
       "647     MS   M   17       U     LE3       T     3     1  services  services   \n",
       "648     MS   M   18       R     LE3       T     3     2  services     other   \n",
       "\n",
       "     reason guardian  traveltime  studytime  failures schoolsup famsup paid  \\\n",
       "0    course   mother           2          2         0       yes     no   no   \n",
       "1    course   father           1          2         0        no    yes   no   \n",
       "2     other   mother           1          2         0       yes     no   no   \n",
       "3      home   mother           1          3         0        no    yes   no   \n",
       "4      home   father           1          2         0        no    yes   no   \n",
       "..      ...      ...         ...        ...       ...       ...    ...  ...   \n",
       "644  course   mother           1          3         1        no     no   no   \n",
       "645  course   mother           1          2         0        no    yes   no   \n",
       "646  course   mother           2          2         0        no     no   no   \n",
       "647  course   mother           2          1         0        no     no   no   \n",
       "648  course   mother           3          1         0        no     no   no   \n",
       "\n",
       "    activities nursery higher internet romantic  famrel  freetime  goout  \\\n",
       "0           no     yes    yes       no       no       4         3      4   \n",
       "1           no      no    yes      yes       no       5         3      3   \n",
       "2           no     yes    yes      yes       no       4         3      2   \n",
       "3          yes     yes    yes      yes      yes       3         2      2   \n",
       "4           no     yes    yes       no       no       4         3      2   \n",
       "..         ...     ...    ...      ...      ...     ...       ...    ...   \n",
       "644        yes      no    yes      yes       no       5         4      2   \n",
       "645         no     yes    yes      yes       no       4         3      4   \n",
       "646        yes     yes    yes       no       no       1         1      1   \n",
       "647         no      no    yes      yes       no       2         4      5   \n",
       "648         no      no    yes      yes       no       4         4      1   \n",
       "\n",
       "     Dalc  Walc  health  absences  G1  G2  G3  \n",
       "0       1     1       3         4   0  11  11  \n",
       "1       1     1       3         2   9  11  11  \n",
       "2       2     3       3         6  12  13  12  \n",
       "3       1     1       5         0  14  14  14  \n",
       "4       1     2       5         0  11  13  13  \n",
       "..    ...   ...     ...       ...  ..  ..  ..  \n",
       "644     1     2       5         4  10  11  10  \n",
       "645     1     1       1         4  15  15  16  \n",
       "646     1     1       5         6  11  12   9  \n",
       "647     3     4       2         6  10  10  10  \n",
       "648     3     4       5         4  10  11  11  \n",
       "\n",
       "[649 rows x 33 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"student-por.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "military-sending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.744222</td>\n",
       "      <td>2.514638</td>\n",
       "      <td>2.306626</td>\n",
       "      <td>1.568567</td>\n",
       "      <td>1.930663</td>\n",
       "      <td>0.221880</td>\n",
       "      <td>3.930663</td>\n",
       "      <td>3.180277</td>\n",
       "      <td>3.184900</td>\n",
       "      <td>1.502311</td>\n",
       "      <td>2.280431</td>\n",
       "      <td>3.536210</td>\n",
       "      <td>3.659476</td>\n",
       "      <td>11.399076</td>\n",
       "      <td>11.570108</td>\n",
       "      <td>11.906009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.218138</td>\n",
       "      <td>1.134552</td>\n",
       "      <td>1.099931</td>\n",
       "      <td>0.748660</td>\n",
       "      <td>0.829510</td>\n",
       "      <td>0.593235</td>\n",
       "      <td>0.955717</td>\n",
       "      <td>1.051093</td>\n",
       "      <td>1.175766</td>\n",
       "      <td>0.924834</td>\n",
       "      <td>1.284380</td>\n",
       "      <td>1.446259</td>\n",
       "      <td>4.640759</td>\n",
       "      <td>2.745265</td>\n",
       "      <td>2.913639</td>\n",
       "      <td>3.230656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age        Medu        Fedu  traveltime   studytime    failures  \\\n",
       "count  649.000000  649.000000  649.000000  649.000000  649.000000  649.000000   \n",
       "mean    16.744222    2.514638    2.306626    1.568567    1.930663    0.221880   \n",
       "std      1.218138    1.134552    1.099931    0.748660    0.829510    0.593235   \n",
       "min     15.000000    0.000000    0.000000    1.000000    1.000000    0.000000   \n",
       "25%     16.000000    2.000000    1.000000    1.000000    1.000000    0.000000   \n",
       "50%     17.000000    2.000000    2.000000    1.000000    2.000000    0.000000   \n",
       "75%     18.000000    4.000000    3.000000    2.000000    2.000000    0.000000   \n",
       "max     22.000000    4.000000    4.000000    4.000000    4.000000    3.000000   \n",
       "\n",
       "           famrel    freetime       goout        Dalc        Walc      health  \\\n",
       "count  649.000000  649.000000  649.000000  649.000000  649.000000  649.000000   \n",
       "mean     3.930663    3.180277    3.184900    1.502311    2.280431    3.536210   \n",
       "std      0.955717    1.051093    1.175766    0.924834    1.284380    1.446259   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      4.000000    3.000000    2.000000    1.000000    1.000000    2.000000   \n",
       "50%      4.000000    3.000000    3.000000    1.000000    2.000000    4.000000   \n",
       "75%      5.000000    4.000000    4.000000    2.000000    3.000000    5.000000   \n",
       "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
       "\n",
       "         absences          G1          G2          G3  \n",
       "count  649.000000  649.000000  649.000000  649.000000  \n",
       "mean     3.659476   11.399076   11.570108   11.906009  \n",
       "std      4.640759    2.745265    2.913639    3.230656  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000   10.000000   10.000000   10.000000  \n",
       "50%      2.000000   11.000000   11.000000   12.000000  \n",
       "75%      6.000000   13.000000   13.000000   14.000000  \n",
       "max     32.000000   19.000000   19.000000   19.000000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "gentle-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "infectious-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isnull().sum() \n",
    "# Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "entitled-security",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2']\n",
      "\n",
      "Number of Features: 32\n"
     ]
    }
   ],
   "source": [
    "features_list = list(df.columns)[:-1]\n",
    "print(\"Features: {x}\".format(x = features_list))\n",
    "print(\"\\nNumber of Features: {x}\".format(x = len(features_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "brutal-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()\n",
    "# # Check datatype of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "brilliant-english",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>home</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>home</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>R</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>teacher</td>\n",
       "      <td>services</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>R</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
       "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
       "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
       "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
       "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
       "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
       "644     MS   F   19       R     GT3       T     2     3  services     other   \n",
       "645     MS   F   18       U     LE3       T     3     1   teacher  services   \n",
       "646     MS   F   18       U     GT3       T     1     1     other     other   \n",
       "647     MS   M   17       U     LE3       T     3     1  services  services   \n",
       "648     MS   M   18       R     LE3       T     3     2  services     other   \n",
       "\n",
       "     reason guardian  traveltime  studytime  failures schoolsup famsup paid  \\\n",
       "0    course   mother           2          2         0       yes     no   no   \n",
       "1    course   father           1          2         0        no    yes   no   \n",
       "2     other   mother           1          2         0       yes     no   no   \n",
       "3      home   mother           1          3         0        no    yes   no   \n",
       "4      home   father           1          2         0        no    yes   no   \n",
       "..      ...      ...         ...        ...       ...       ...    ...  ...   \n",
       "644  course   mother           1          3         1        no     no   no   \n",
       "645  course   mother           1          2         0        no    yes   no   \n",
       "646  course   mother           2          2         0        no     no   no   \n",
       "647  course   mother           2          1         0        no     no   no   \n",
       "648  course   mother           3          1         0        no     no   no   \n",
       "\n",
       "    activities nursery higher internet romantic  famrel  freetime  goout  \\\n",
       "0           no     yes    yes       no       no       4         3      4   \n",
       "1           no      no    yes      yes       no       5         3      3   \n",
       "2           no     yes    yes      yes       no       4         3      2   \n",
       "3          yes     yes    yes      yes      yes       3         2      2   \n",
       "4           no     yes    yes       no       no       4         3      2   \n",
       "..         ...     ...    ...      ...      ...     ...       ...    ...   \n",
       "644        yes      no    yes      yes       no       5         4      2   \n",
       "645         no     yes    yes      yes       no       4         3      4   \n",
       "646        yes     yes    yes       no       no       1         1      1   \n",
       "647         no      no    yes      yes       no       2         4      5   \n",
       "648         no      no    yes      yes       no       4         4      1   \n",
       "\n",
       "     Dalc  Walc  health  absences  G1  G2  \n",
       "0       1     1       3         4   0  11  \n",
       "1       1     1       3         2   9  11  \n",
       "2       2     3       3         6  12  13  \n",
       "3       1     1       5         0  14  14  \n",
       "4       1     2       5         0  11  13  \n",
       "..    ...   ...     ...       ...  ..  ..  \n",
       "644     1     2       5         4  10  11  \n",
       "645     1     1       1         4  15  15  \n",
       "646     1     1       5         6  11  12  \n",
       "647     3     4       2         6  10  10  \n",
       "648     3     4       5         4  10  11  \n",
       "\n",
       "[649 rows x 32 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.drop([\"G3\"], axis = 1)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "small-vienna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     G3\n",
       "0    11\n",
       "1    11\n",
       "2    12\n",
       "3    14\n",
       "4    13\n",
       "..   ..\n",
       "644  10\n",
       "645  16\n",
       "646   9\n",
       "647  10\n",
       "648  11\n",
       "\n",
       "[649 rows x 1 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df.drop(features_list, axis = 1)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "opponent-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_school = {'GP' : 0, 'MS' : 1}\n",
    "mapping_sex = {'F' : 0, 'M' : 1}\n",
    "mapping_address = {'U' : 0, 'R' : 1}\n",
    "mapping_famsize = {'GT3' : 0, 'LE3' : 1}\n",
    "mapping_pstatus = {'A' : 0, 'T' : 1}\n",
    "mapping_mjob = {'at_home' : 0, 'health' : 1, 'other' : 2, 'services' : 3, 'teacher' : 4}\n",
    "mapping_fjob = {'at_home' : 0, 'health' : 1, 'other' : 2, 'services' : 3, 'teacher' : 4}\n",
    "mapping_reason = {'course' : 0, 'other' : 1, 'home' : 2, 'reputation' : 3}\n",
    "mapping_guardian = {'mother' : 0, 'father' : 1, 'other': 2}\n",
    "mapping_schoolsup = {'no' : 0, 'yes' : 1}\n",
    "mapping_famsup = {'no' : 0, 'yes' : 1}\n",
    "mapping_romantic = {'no' : 0, 'yes' : 1}\n",
    "mapping_paid = {'no' : 0, 'yes' : 1}\n",
    "mapping_activities = {'no' : 0, 'yes' : 1}\n",
    "mapping_nursery = {'no' : 0, 'yes' : 1}\n",
    "mapping_higher = {'no' : 0, 'yes' : 1}\n",
    "mapping_internet = {'no' : 0, 'yes' : 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "strong-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['school'] = features['school'].map(mapping_school)\n",
    "features['sex'] = features['sex'].map(mapping_sex)\n",
    "features['address'] = features['address'].map(mapping_address)\n",
    "features['famsize'] = features['famsize'].map(mapping_famsize)\n",
    "features['Pstatus'] = features['Pstatus'].map(mapping_pstatus)\n",
    "features['Mjob'] = features['Mjob'].map(mapping_mjob)\n",
    "features['Fjob'] = features['Fjob'].map(mapping_fjob)\n",
    "features['reason'] = features['reason'].map(mapping_reason)\n",
    "features['guardian'] = features['guardian'].map(mapping_guardian).astype('Int64')\n",
    "features['famsup'] = features['famsup'].map(mapping_famsup)\n",
    "features['schoolsup'] = features['schoolsup'].map(mapping_schoolsup)\n",
    "features['romantic'] = features['romantic'].map(mapping_romantic)\n",
    "features['paid'] = features['paid'].map(mapping_paid)\n",
    "features['activities'] = features['activities'].map(mapping_activities)\n",
    "features['nursery'] = features['nursery'].map(mapping_nursery)\n",
    "features['higher'] = features['higher'].map(mapping_higher)\n",
    "features['internet'] = features['internet'].map(mapping_internet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "conditional-italic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     school  sex  age  address  famsize  Pstatus  Medu  Fedu  Mjob  Fjob  \\\n",
       "0         0    0   18        0        0        0     4     4     0     4   \n",
       "1         0    0   17        0        0        1     1     1     0     2   \n",
       "2         0    0   15        0        1        1     1     1     0     2   \n",
       "3         0    0   15        0        0        1     4     2     1     3   \n",
       "4         0    0   16        0        0        1     3     3     2     2   \n",
       "..      ...  ...  ...      ...      ...      ...   ...   ...   ...   ...   \n",
       "644       1    0   19        1        0        1     2     3     3     2   \n",
       "645       1    0   18        0        1        1     3     1     4     3   \n",
       "646       1    0   18        0        0        1     1     1     2     2   \n",
       "647       1    1   17        0        1        1     3     1     3     3   \n",
       "648       1    1   18        1        1        1     3     2     3     2   \n",
       "\n",
       "     reason  guardian  traveltime  studytime  failures  schoolsup  famsup  \\\n",
       "0         0         0           2          2         0          1       0   \n",
       "1         0         1           1          2         0          0       1   \n",
       "2         1         0           1          2         0          1       0   \n",
       "3         2         0           1          3         0          0       1   \n",
       "4         2         1           1          2         0          0       1   \n",
       "..      ...       ...         ...        ...       ...        ...     ...   \n",
       "644       0         0           1          3         1          0       0   \n",
       "645       0         0           1          2         0          0       1   \n",
       "646       0         0           2          2         0          0       0   \n",
       "647       0         0           2          1         0          0       0   \n",
       "648       0         0           3          1         0          0       0   \n",
       "\n",
       "     paid  activities  nursery  higher  internet  romantic  famrel  freetime  \\\n",
       "0       0           0        1       1         0         0       4         3   \n",
       "1       0           0        0       1         1         0       5         3   \n",
       "2       0           0        1       1         1         0       4         3   \n",
       "3       0           1        1       1         1         1       3         2   \n",
       "4       0           0        1       1         0         0       4         3   \n",
       "..    ...         ...      ...     ...       ...       ...     ...       ...   \n",
       "644     0           1        0       1         1         0       5         4   \n",
       "645     0           0        1       1         1         0       4         3   \n",
       "646     0           1        1       1         0         0       1         1   \n",
       "647     0           0        0       1         1         0       2         4   \n",
       "648     0           0        0       1         1         0       4         4   \n",
       "\n",
       "     goout  Dalc  Walc  health  absences  G1  G2  \n",
       "0        4     1     1       3         4   0  11  \n",
       "1        3     1     1       3         2   9  11  \n",
       "2        2     2     3       3         6  12  13  \n",
       "3        2     1     1       5         0  14  14  \n",
       "4        2     1     2       5         0  11  13  \n",
       "..     ...   ...   ...     ...       ...  ..  ..  \n",
       "644      2     1     2       5         4  10  11  \n",
       "645      4     1     1       1         4  15  15  \n",
       "646      1     1     1       5         6  11  12  \n",
       "647      5     3     4       2         6  10  10  \n",
       "648      1     3     4       5         4  10  11  \n",
       "\n",
       "[649 rows x 32 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "literary-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "failing-qualification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='school', data=features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "vocational-translator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 36 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features.hist(bins=20, figsize=(20,15));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-victim",
   "metadata": {},
   "source": [
    "## 4. Grid Search Cross Validation\n",
    "\n",
    "Here the real thing begins. We will use Sci-Kit Learn's GridSearchCV to find the optimal hypter parameters for the model for this problem.\n",
    "\n",
    "#### To be tuned:\n",
    "\n",
    "1. Batch Size & Number of Epochs with Training Optimization Algorithm\n",
    "3. Learning Rate & Momentum(if applies) of the optimal Training Optimization Algorithm\n",
    "4. Network Weight Initialization\n",
    "5. Neuron Activation Function\n",
    "6. Dropout Regularization\n",
    "7. Number of Neurons in the Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-letters",
   "metadata": {},
   "source": [
    "#### Search/Tuning Flow:\n",
    "1. Define Model\n",
    "2. Wrap Keras model with KerasRegressor of Sci-Kit Learn\n",
    "3. Define Grid Parameters\n",
    "4. Train model with Grid Parameters defined\n",
    "5. Summarize Results\n",
    "\n",
    "Note: Set verbose = 0, as it's gonna be long list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-jacket",
   "metadata": {},
   "source": [
    "#### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "coral-inspection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler()\n",
      "MinMaxScaler()\n"
     ]
    }
   ],
   "source": [
    "x = features\n",
    "y = target\n",
    "scaler_x = preprocessing.MinMaxScaler()\n",
    "scaler_y = preprocessing.MinMaxScaler()\n",
    "print(scaler_x.fit(x))\n",
    "xscale =scaler_x.transform(x)\n",
    "print(scaler_y.fit(y))\n",
    "yscale =scaler_y.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-postcard",
   "metadata": {},
   "source": [
    "#### Split Training and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "affecting-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "medical-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xscale, yscale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-times",
   "metadata": {},
   "source": [
    "### Here we go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-bandwidth",
   "metadata": {},
   "source": [
    "### Batch Size & Number of Epochs with Training Optimization Algorithm \n",
    "\n",
    "1. ###### Batch Size & Number of Epochs with Training Optimization Algorithm (This section)\n",
    "3. Learning Rate & Momentum(if applies) of the optimal Training Optimization Algorithm \n",
    "4. Network Weight Initialization\n",
    "5. Neuron Activation Function\n",
    "6. Dropout Regularization\n",
    "7. Number of Neurons in the Hidden Layer\n",
    "\n",
    "Based on the best parameter obtained, we can further fine tune it. For instance, the Adam optimizer used with default Learning Rate of 0.001. Here, GridSearchCV is used again to search for best Learning Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "considerable-decimal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_367\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1468 (Dense)           (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_1469 (Dense)           (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_1470 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1471 (Dense)           (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,281\n",
      "Trainable params: 5,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(optimizer='adam'):\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(32, input_dim=32, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='relu')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "    loss='mse', \n",
    "    optimizer=optimizer, \n",
    "    metrics=['mse', 'mae'])\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "timely-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "specialized-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "batch_size = [10, 50]\n",
    "epochs = [10, 50, 100, 200, 500, 700, 100]\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adam']\n",
    "\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=None, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ultimate-comment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.005965 using {'batch_size': 10, 'epochs': 500, 'optimizer': 'Adam'}\n",
      "-0.028463 (0.004721) with: {'batch_size': 10, 'epochs': 10, 'optimizer': 'SGD'}\n",
      "-0.015968 (0.003097) with: {'batch_size': 10, 'epochs': 10, 'optimizer': 'RMSprop'}\n",
      "-0.025240 (0.003616) with: {'batch_size': 10, 'epochs': 10, 'optimizer': 'Adagrad'}\n",
      "-0.015238 (0.002083) with: {'batch_size': 10, 'epochs': 10, 'optimizer': 'Adam'}\n",
      "-0.017206 (0.002360) with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'SGD'}\n",
      "-0.145098 (0.191964) with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'RMSprop'}\n",
      "-0.022524 (0.001170) with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'Adagrad'}\n",
      "-0.146513 (0.190964) with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'Adam'}\n",
      "-0.157444 (0.202528) with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'SGD'}\n",
      "-0.011094 (0.000877) with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'RMSprop'}\n",
      "-0.020580 (0.002711) with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'Adagrad'}\n",
      "-0.010374 (0.000477) with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'Adam'}\n",
      "-0.009310 (0.002759) with: {'batch_size': 10, 'epochs': 200, 'optimizer': 'SGD'}\n",
      "-0.009293 (0.000250) with: {'batch_size': 10, 'epochs': 200, 'optimizer': 'RMSprop'}\n",
      "-0.017017 (0.001379) with: {'batch_size': 10, 'epochs': 200, 'optimizer': 'Adagrad'}\n",
      "-0.146682 (0.196286) with: {'batch_size': 10, 'epochs': 200, 'optimizer': 'Adam'}\n",
      "-0.009240 (0.000665) with: {'batch_size': 10, 'epochs': 500, 'optimizer': 'SGD'}\n",
      "-0.146397 (0.191046) with: {'batch_size': 10, 'epochs': 500, 'optimizer': 'RMSprop'}\n",
      "-0.011593 (0.000583) with: {'batch_size': 10, 'epochs': 500, 'optimizer': 'Adagrad'}\n",
      "-0.005965 (0.000901) with: {'batch_size': 10, 'epochs': 500, 'optimizer': 'Adam'}\n",
      "-0.008600 (0.001274) with: {'batch_size': 10, 'epochs': 700, 'optimizer': 'SGD'}\n",
      "-0.010942 (0.001055) with: {'batch_size': 10, 'epochs': 700, 'optimizer': 'RMSprop'}\n",
      "-0.014289 (0.001645) with: {'batch_size': 10, 'epochs': 700, 'optimizer': 'Adagrad'}\n",
      "-0.288956 (0.200082) with: {'batch_size': 10, 'epochs': 700, 'optimizer': 'Adam'}\n",
      "-0.150279 (0.193825) with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'SGD'}\n",
      "-0.010215 (0.001553) with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'RMSprop'}\n",
      "-0.016976 (0.002632) with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'Adagrad'}\n",
      "-0.009126 (0.001062) with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'Adam'}\n",
      "-0.166019 (0.175163) with: {'batch_size': 50, 'epochs': 10, 'optimizer': 'SGD'}\n",
      "-0.153591 (0.191492) with: {'batch_size': 50, 'epochs': 10, 'optimizer': 'RMSprop'}\n",
      "-0.033854 (0.011117) with: {'batch_size': 50, 'epochs': 10, 'optimizer': 'Adagrad'}\n",
      "-0.160026 (0.200699) with: {'batch_size': 50, 'epochs': 10, 'optimizer': 'Adam'}\n",
      "-0.027034 (0.001804) with: {'batch_size': 50, 'epochs': 50, 'optimizer': 'SGD'}\n",
      "-0.148442 (0.189607) with: {'batch_size': 50, 'epochs': 50, 'optimizer': 'RMSprop'}\n",
      "-0.022836 (0.006468) with: {'batch_size': 50, 'epochs': 50, 'optimizer': 'Adagrad'}\n",
      "-0.014069 (0.003681) with: {'batch_size': 50, 'epochs': 50, 'optimizer': 'Adam'}\n",
      "-0.020749 (0.001314) with: {'batch_size': 50, 'epochs': 100, 'optimizer': 'SGD'}\n",
      "-0.016138 (0.001555) with: {'batch_size': 50, 'epochs': 100, 'optimizer': 'RMSprop'}\n",
      "-0.023641 (0.002033) with: {'batch_size': 50, 'epochs': 100, 'optimizer': 'Adagrad'}\n",
      "-0.147562 (0.195748) with: {'batch_size': 50, 'epochs': 100, 'optimizer': 'Adam'}\n",
      "-0.019128 (0.002629) with: {'batch_size': 50, 'epochs': 200, 'optimizer': 'SGD'}\n",
      "-0.009716 (0.000544) with: {'batch_size': 50, 'epochs': 200, 'optimizer': 'RMSprop'}\n",
      "-0.021260 (0.003085) with: {'batch_size': 50, 'epochs': 200, 'optimizer': 'Adagrad'}\n",
      "-0.009083 (0.001498) with: {'batch_size': 50, 'epochs': 200, 'optimizer': 'Adam'}\n",
      "-0.013320 (0.001870) with: {'batch_size': 50, 'epochs': 500, 'optimizer': 'SGD'}\n",
      "-0.011065 (0.001593) with: {'batch_size': 50, 'epochs': 500, 'optimizer': 'RMSprop'}\n",
      "-0.016537 (0.002512) with: {'batch_size': 50, 'epochs': 500, 'optimizer': 'Adagrad'}\n",
      "-0.009509 (0.001473) with: {'batch_size': 50, 'epochs': 500, 'optimizer': 'Adam'}\n",
      "-0.011761 (0.000520) with: {'batch_size': 50, 'epochs': 700, 'optimizer': 'SGD'}\n",
      "-0.293740 (0.198689) with: {'batch_size': 50, 'epochs': 700, 'optimizer': 'RMSprop'}\n",
      "-0.019242 (0.005587) with: {'batch_size': 50, 'epochs': 700, 'optimizer': 'Adagrad'}\n",
      "-0.010471 (0.001940) with: {'batch_size': 50, 'epochs': 700, 'optimizer': 'Adam'}\n",
      "-0.161215 (0.199862) with: {'batch_size': 50, 'epochs': 100, 'optimizer': 'SGD'}\n",
      "-0.013806 (0.002374) with: {'batch_size': 50, 'epochs': 100, 'optimizer': 'RMSprop'}\n",
      "-0.023127 (0.003016) with: {'batch_size': 50, 'epochs': 100, 'optimizer': 'Adagrad'}\n",
      "-0.289808 (0.198879) with: {'batch_size': 50, 'epochs': 100, 'optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-religion",
   "metadata": {},
   "source": [
    "Some reading on the negative values on scoring : \n",
    "\n",
    "https://stackoverflow.com/questions/21443865/scikit-learn-cross-validation-negative-values-with-mean-squared-error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-excitement",
   "metadata": {},
   "source": [
    "### Learning Rate\n",
    "\n",
    "1. Batch Size & Number of Epochs with Training Optimization Algorithm \n",
    "(Best Params : Batch Size: 10, Epochs = 500, Optimzation Algorithm: Adam)\n",
    "3. ###### Learning Rate & Momentum(if applies) of the optimal Training Optimization Algorithm (This section)\n",
    "4. Network Weight Initialization\n",
    "5. Neuron Activation Function\n",
    "6. Dropout Regularization\n",
    "7. Number of Neurons in the Hidden Layer\n",
    "\n",
    "Based on the best parameter obtained, we can further fine tune it. For instance, the Adam optimizer used with default Learning Rate of 0.001. Here, GridSearchCV is used again to search for best Learning Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "prescribed-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_Adam(learn_rate=0.001):\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(32, input_dim=32, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='relu')\n",
    "    ])\n",
    "    optimizer = Adam(lr = learn_rate)\n",
    "    \n",
    "    model.compile(\n",
    "    loss='mse', \n",
    "    optimizer=optimizer, \n",
    "    metrics=['mse', 'mae'])\n",
    "        \n",
    "    return model\n",
    "\n",
    "model_Adam = KerasRegressor(build_fn=create_model_Adam, epochs=500, batch_size=10,  verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "seeing-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "\n",
    "param_grid = dict(learn_rate=learn_rate)\n",
    "grid = GridSearchCV(estimator=model_Adam, param_grid=param_grid, n_jobs=None, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "equipped-nature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.008608 using {'learn_rate': 0.01}\n",
      "-0.282835 (0.194689) with: {'learn_rate': 0.001}\n",
      "-0.008608 (0.002567) with: {'learn_rate': 0.01}\n",
      "-0.428273 (0.011470) with: {'learn_rate': 0.1}\n",
      "-0.428273 (0.011470) with: {'learn_rate': 0.2}\n",
      "-0.428273 (0.011470) with: {'learn_rate': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-professor",
   "metadata": {},
   "source": [
    "### Network Weight Initialization\n",
    "\n",
    "1. Batch Size & Number of Epochs with Training Optimization Algorithm \n",
    "(Best Params : Batch Size: 10, Epochs = 500, Optimzation Algorithm: Adam)\n",
    "3. Learning Rate & Momentum(if applies) of the optimal Training Optimization Algorithm (Learning Rate = 0.01)\n",
    "4. ###### Network Weight Initialization(This section)\n",
    "5. Neuron Activation Function\n",
    "6. Dropout Regularization\n",
    "7. Number of Neurons in the Hidden Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "mental-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_weight_init(init_mode = 'uniform'):\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(32, input_dim=32, activation='relu', kernel_initializer=init_mode),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='relu')\n",
    "    ])\n",
    "    optimizer = Adam(lr = 0.01)\n",
    "    \n",
    "    model.compile(\n",
    "    loss='mse', \n",
    "    optimizer=optimizer, \n",
    "    metrics=['mse', 'mae'])\n",
    "        \n",
    "    return model\n",
    "\n",
    "model_weight_init = KerasRegressor(build_fn=create_model_weight_init, epochs=500, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "legal-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model_weight_init, param_grid=param_grid, n_jobs=None, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "divided-finish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.006276 using {'init_mode': 'glorot_normal'}\n",
      "-0.007148 (0.001306) with: {'init_mode': 'uniform'}\n",
      "-0.007395 (0.000859) with: {'init_mode': 'lecun_uniform'}\n",
      "-0.007029 (0.002231) with: {'init_mode': 'normal'}\n",
      "-0.428273 (0.011470) with: {'init_mode': 'zero'}\n",
      "-0.006276 (0.001090) with: {'init_mode': 'glorot_normal'}\n",
      "-0.006986 (0.001367) with: {'init_mode': 'glorot_uniform'}\n",
      "-0.006326 (0.000991) with: {'init_mode': 'he_normal'}\n",
      "-0.007320 (0.001293) with: {'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-violence",
   "metadata": {},
   "source": [
    "### Neuron Activation Function\n",
    "\n",
    "1. Batch Size & Number of Epochs with Training Optimization Algorithm \n",
    "(Best Params : Batch Size: 10, Epochs = 500, Optimzation Algorithm: Adam)\n",
    "3. Learning Rate & Momentum(if applies) of the optimal Training Optimization Algorithm (Learning Rate = 0.01)\n",
    "4. Network Weight Initialization(glorot_normal)\n",
    "5. ###### Neuron Activation Function (This section)\n",
    "6. Dropout Regularization\n",
    "7. Number of Neurons in the Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "distant-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_act_func(activation='relu', output_activation = 'sigmoid'):\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(32, input_dim=32, activation='relu', kernel_initializer='glorot_normal'),\n",
    "        Dense(64, activation=activation),\n",
    "        Dense(32, activation=activation),\n",
    "        Dense(1, activation=output_activation)\n",
    "    ])\n",
    "    optimizer = Adam(lr = 0.01)\n",
    "    \n",
    "    model.compile(\n",
    "    loss='mse', \n",
    "    optimizer=optimizer, \n",
    "    metrics=['mse', 'mae'])\n",
    "        \n",
    "    return model\n",
    "\n",
    "model_act_func = KerasRegressor(build_fn=create_model_act_func, epochs=500, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "charming-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "output_activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation, output_activation=output_activation)\n",
    "grid = GridSearchCV(estimator=model_act_func, param_grid=param_grid, n_jobs=None, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "rubber-former",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.005240 using {'activation': 'tanh', 'output_activation': 'softplus'}\n",
      "-0.163698 (0.006265) with: {'activation': 'softmax', 'output_activation': 'softmax'}\n",
      "-0.007385 (0.000300) with: {'activation': 'softmax', 'output_activation': 'softplus'}\n",
      "-0.007461 (0.001923) with: {'activation': 'softmax', 'output_activation': 'softsign'}\n",
      "-0.428273 (0.011470) with: {'activation': 'softmax', 'output_activation': 'relu'}\n",
      "-0.012566 (0.007980) with: {'activation': 'softmax', 'output_activation': 'tanh'}\n",
      "-0.008226 (0.000539) with: {'activation': 'softmax', 'output_activation': 'hard_sigmoid'}\n",
      "-0.015137 (0.012034) with: {'activation': 'softmax', 'output_activation': 'linear'}\n",
      "-0.163698 (0.006265) with: {'activation': 'softplus', 'output_activation': 'softmax'}\n",
      "-0.006287 (0.000951) with: {'activation': 'softplus', 'output_activation': 'softplus'}\n",
      "-0.006516 (0.000858) with: {'activation': 'softplus', 'output_activation': 'softsign'}\n",
      "-0.428273 (0.011470) with: {'activation': 'softplus', 'output_activation': 'relu'}\n",
      "-0.056475 (0.070589) with: {'activation': 'softplus', 'output_activation': 'tanh'}\n",
      "-0.006456 (0.000210) with: {'activation': 'softplus', 'output_activation': 'hard_sigmoid'}\n",
      "-0.006241 (0.001225) with: {'activation': 'softplus', 'output_activation': 'linear'}\n",
      "-0.163698 (0.006265) with: {'activation': 'softsign', 'output_activation': 'softmax'}\n",
      "-0.005645 (0.000984) with: {'activation': 'softsign', 'output_activation': 'softplus'}\n",
      "-0.007501 (0.000745) with: {'activation': 'softsign', 'output_activation': 'softsign'}\n",
      "-0.007688 (0.002387) with: {'activation': 'softsign', 'output_activation': 'relu'}\n",
      "-0.007554 (0.001550) with: {'activation': 'softsign', 'output_activation': 'tanh'}\n",
      "-0.007614 (0.000529) with: {'activation': 'softsign', 'output_activation': 'hard_sigmoid'}\n",
      "-0.006586 (0.001407) with: {'activation': 'softsign', 'output_activation': 'linear'}\n",
      "-0.163698 (0.006265) with: {'activation': 'tanh', 'output_activation': 'softmax'}\n",
      "-0.005240 (0.002096) with: {'activation': 'tanh', 'output_activation': 'softplus'}\n",
      "-0.008419 (0.000604) with: {'activation': 'tanh', 'output_activation': 'softsign'}\n",
      "-0.282485 (0.195184) with: {'activation': 'tanh', 'output_activation': 'relu'}\n",
      "-0.014544 (0.008586) with: {'activation': 'tanh', 'output_activation': 'tanh'}\n",
      "-0.007384 (0.000880) with: {'activation': 'tanh', 'output_activation': 'hard_sigmoid'}\n",
      "-0.007753 (0.002090) with: {'activation': 'tanh', 'output_activation': 'linear'}\n",
      "-0.163698 (0.006265) with: {'activation': 'sigmoid', 'output_activation': 'softmax'}\n",
      "-0.006808 (0.000508) with: {'activation': 'sigmoid', 'output_activation': 'softplus'}\n",
      "-0.008362 (0.001018) with: {'activation': 'sigmoid', 'output_activation': 'softsign'}\n",
      "-0.006664 (0.000509) with: {'activation': 'sigmoid', 'output_activation': 'relu'}\n",
      "-0.007290 (0.000399) with: {'activation': 'sigmoid', 'output_activation': 'tanh'}\n",
      "-0.008176 (0.000130) with: {'activation': 'sigmoid', 'output_activation': 'hard_sigmoid'}\n",
      "-0.006958 (0.000760) with: {'activation': 'sigmoid', 'output_activation': 'linear'}\n",
      "-0.163698 (0.006265) with: {'activation': 'hard_sigmoid', 'output_activation': 'softmax'}\n",
      "-0.005850 (0.001183) with: {'activation': 'hard_sigmoid', 'output_activation': 'softplus'}\n",
      "-0.007024 (0.001326) with: {'activation': 'hard_sigmoid', 'output_activation': 'softsign'}\n",
      "-0.006228 (0.001002) with: {'activation': 'hard_sigmoid', 'output_activation': 'relu'}\n",
      "-0.005977 (0.001243) with: {'activation': 'hard_sigmoid', 'output_activation': 'tanh'}\n",
      "-0.007457 (0.002490) with: {'activation': 'hard_sigmoid', 'output_activation': 'hard_sigmoid'}\n",
      "-0.006458 (0.000733) with: {'activation': 'hard_sigmoid', 'output_activation': 'linear'}\n",
      "-0.163698 (0.006265) with: {'activation': 'linear', 'output_activation': 'softmax'}\n",
      "-0.030347 (0.035337) with: {'activation': 'linear', 'output_activation': 'softplus'}\n",
      "-0.014863 (0.008106) with: {'activation': 'linear', 'output_activation': 'softsign'}\n",
      "-0.428273 (0.011470) with: {'activation': 'linear', 'output_activation': 'relu'}\n",
      "-0.950006 (1.218025) with: {'activation': 'linear', 'output_activation': 'tanh'}\n",
      "-0.008761 (0.001055) with: {'activation': 'linear', 'output_activation': 'hard_sigmoid'}\n",
      "-0.006560 (0.001270) with: {'activation': 'linear', 'output_activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-strengthening",
   "metadata": {},
   "source": [
    "### Dropout Regularization\n",
    "\n",
    "1. Batch Size & Number of Epochs with Training Optimization Algorithm \n",
    "(Best Params : Batch Size: 10, Epochs = 500, Optimzation Algorithm: Adam)\n",
    "3. Learning Rate & Momentum(if applies) of the optimal Training Optimization Algorithm (Learning Rate = 0.01)\n",
    "4. Network Weight Initialization(glorot_normal)\n",
    "5. Neuron Activation Function (activation=tanH, output_activation = SoftPlus)\n",
    "6. ###### Dropout Regularization (This section)\n",
    "7. Number of Neurons in the Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-niger",
   "metadata": {},
   "source": [
    "### Check if the model is overfitting. \n",
    "If overfit --> add Dropout layer to regularize it, else skip having dropout layer(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "technical-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_current(activation= 'tanh', output_activation = 'softplus'):\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(32, input_dim=32, activation='relu', kernel_initializer='glorot_normal'),\n",
    "        Dense(64, activation=activation),\n",
    "        Dense(32, activation=activation),\n",
    "        Dense(1, activation=output_activation)\n",
    "    ])\n",
    "    optimizer = Adam(lr = 0.01)\n",
    "    \n",
    "    model.compile(\n",
    "    loss='mse', \n",
    "    optimizer=optimizer, \n",
    "    metrics=['mse', 'mae'])\n",
    "        \n",
    "    return model\n",
    "\n",
    "model_current = create_model_current()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "boxed-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=500, batch_size=10,  verbose=0, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "delayed-benchmark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(history.history.keys())\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "liked-system",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.01027\n",
      "Mean Absolute Error: 0.06792\n"
     ]
    }
   ],
   "source": [
    "mean_squared_e = mean_squared_error(y_test, model.predict(X_test))\n",
    "mean_absolute_e = mean_absolute_error(y_test, model.predict(X_test))\n",
    "\n",
    "print(\"Mean Squared Error: {:.5f}\".format(mean_squared_e))\n",
    "print(\"Mean Absolute Error: {:.5f}\".format(mean_absolute_e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-gates",
   "metadata": {},
   "source": [
    "Based on the graph, it's overfitting, hence, will use Dropout to regularize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "comparative-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_dropout(dropout_rate=0.0, weight_constraint=0):\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(32, \n",
    "              input_dim=32, \n",
    "              activation='tanh', \n",
    "              kernel_initializer='glorot_normal',\n",
    "              kernel_constraint=MaxNorm(weight_constraint),\n",
    "             ),\n",
    "        Dense(64, activation='tanh'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(32, activation='tanh'),\n",
    "        Dense(1, activation='softplus')\n",
    "    ])\n",
    "    optimizer = Adam(lr = 0.01)\n",
    "    \n",
    "    model.compile(\n",
    "    loss='mse', \n",
    "    optimizer=optimizer, \n",
    "    metrics=['mse', 'mae'])\n",
    "        \n",
    "    return model\n",
    "\n",
    "model_dropout = KerasRegressor(build_fn=create_model_dropout, epochs=500, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "elegant-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "weight_constraint = [1, 2, 3, 4, 5]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
    "grid = GridSearchCV(estimator=model_dropout, param_grid=param_grid, n_jobs=None, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ranging-twenty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.005827 using {'dropout_rate': 0.0, 'weight_constraint': 5}\n",
      "-0.008765 (0.002131) with: {'dropout_rate': 0.0, 'weight_constraint': 1}\n",
      "-0.006575 (0.002795) with: {'dropout_rate': 0.0, 'weight_constraint': 2}\n",
      "-0.006673 (0.002291) with: {'dropout_rate': 0.0, 'weight_constraint': 3}\n",
      "-0.006450 (0.000443) with: {'dropout_rate': 0.0, 'weight_constraint': 4}\n",
      "-0.005827 (0.001479) with: {'dropout_rate': 0.0, 'weight_constraint': 5}\n",
      "-0.013988 (0.007143) with: {'dropout_rate': 0.1, 'weight_constraint': 1}\n",
      "-0.007855 (0.001035) with: {'dropout_rate': 0.1, 'weight_constraint': 2}\n",
      "-0.009630 (0.006036) with: {'dropout_rate': 0.1, 'weight_constraint': 3}\n",
      "-0.008967 (0.001543) with: {'dropout_rate': 0.1, 'weight_constraint': 4}\n",
      "-0.007916 (0.003304) with: {'dropout_rate': 0.1, 'weight_constraint': 5}\n",
      "-0.019527 (0.009681) with: {'dropout_rate': 0.2, 'weight_constraint': 1}\n",
      "-0.008429 (0.001298) with: {'dropout_rate': 0.2, 'weight_constraint': 2}\n",
      "-0.009075 (0.000833) with: {'dropout_rate': 0.2, 'weight_constraint': 3}\n",
      "-0.006793 (0.000545) with: {'dropout_rate': 0.2, 'weight_constraint': 4}\n",
      "-0.006739 (0.000751) with: {'dropout_rate': 0.2, 'weight_constraint': 5}\n",
      "-0.013708 (0.004926) with: {'dropout_rate': 0.3, 'weight_constraint': 1}\n",
      "-0.011813 (0.003191) with: {'dropout_rate': 0.3, 'weight_constraint': 2}\n",
      "-0.008855 (0.001806) with: {'dropout_rate': 0.3, 'weight_constraint': 3}\n",
      "-0.006968 (0.001091) with: {'dropout_rate': 0.3, 'weight_constraint': 4}\n",
      "-0.009324 (0.004486) with: {'dropout_rate': 0.3, 'weight_constraint': 5}\n",
      "-0.010334 (0.003062) with: {'dropout_rate': 0.4, 'weight_constraint': 1}\n",
      "-0.009656 (0.005014) with: {'dropout_rate': 0.4, 'weight_constraint': 2}\n",
      "-0.006355 (0.000391) with: {'dropout_rate': 0.4, 'weight_constraint': 3}\n",
      "-0.006925 (0.001233) with: {'dropout_rate': 0.4, 'weight_constraint': 4}\n",
      "-0.011089 (0.001564) with: {'dropout_rate': 0.4, 'weight_constraint': 5}\n",
      "-0.010122 (0.001114) with: {'dropout_rate': 0.5, 'weight_constraint': 1}\n",
      "-0.009317 (0.002456) with: {'dropout_rate': 0.5, 'weight_constraint': 2}\n",
      "-0.007415 (0.001370) with: {'dropout_rate': 0.5, 'weight_constraint': 3}\n",
      "-0.007537 (0.000723) with: {'dropout_rate': 0.5, 'weight_constraint': 4}\n",
      "-0.006466 (0.001177) with: {'dropout_rate': 0.5, 'weight_constraint': 5}\n",
      "-0.010014 (0.001142) with: {'dropout_rate': 0.6, 'weight_constraint': 1}\n",
      "-0.009007 (0.004027) with: {'dropout_rate': 0.6, 'weight_constraint': 2}\n",
      "-0.007114 (0.000283) with: {'dropout_rate': 0.6, 'weight_constraint': 3}\n",
      "-0.007894 (0.001372) with: {'dropout_rate': 0.6, 'weight_constraint': 4}\n",
      "-0.006598 (0.000390) with: {'dropout_rate': 0.6, 'weight_constraint': 5}\n",
      "-0.011148 (0.001172) with: {'dropout_rate': 0.7, 'weight_constraint': 1}\n",
      "-0.008827 (0.002068) with: {'dropout_rate': 0.7, 'weight_constraint': 2}\n",
      "-0.007030 (0.000353) with: {'dropout_rate': 0.7, 'weight_constraint': 3}\n",
      "-0.007573 (0.000667) with: {'dropout_rate': 0.7, 'weight_constraint': 4}\n",
      "-0.008285 (0.001155) with: {'dropout_rate': 0.7, 'weight_constraint': 5}\n",
      "-0.014133 (0.004180) with: {'dropout_rate': 0.8, 'weight_constraint': 1}\n",
      "-0.012693 (0.002982) with: {'dropout_rate': 0.8, 'weight_constraint': 2}\n",
      "-0.010169 (0.002252) with: {'dropout_rate': 0.8, 'weight_constraint': 3}\n",
      "-0.007328 (0.000291) with: {'dropout_rate': 0.8, 'weight_constraint': 4}\n",
      "-0.010010 (0.003715) with: {'dropout_rate': 0.8, 'weight_constraint': 5}\n",
      "-0.030002 (0.003454) with: {'dropout_rate': 0.9, 'weight_constraint': 1}\n",
      "-0.022153 (0.005183) with: {'dropout_rate': 0.9, 'weight_constraint': 2}\n",
      "-0.017274 (0.005280) with: {'dropout_rate': 0.9, 'weight_constraint': 3}\n",
      "-0.014791 (0.003530) with: {'dropout_rate': 0.9, 'weight_constraint': 4}\n",
      "-0.014723 (0.002444) with: {'dropout_rate': 0.9, 'weight_constraint': 5}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-privilege",
   "metadata": {},
   "source": [
    "### Neuron Activation Function\n",
    "\n",
    "1. Batch Size & Number of Epochs with Training Optimization Algorithm \n",
    "(Best Params : Batch Size: 10, Epochs = 500, Optimzation Algorithm: Adam)\n",
    "3. Learning Rate & Momentum(if applies) of the optimal Training Optimization Algorithm (Learning Rate = 0.01)\n",
    "4. Network Weight Initialization(glorot_normal)\n",
    "5. Neuron Activation Function (activation=tanH, output_activation = SoftPlus)\n",
    "6. Dropout Regularization\n",
    "7. Number of Neurons in the Hidden Layer(This section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "auburn-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_neurons_hidden_layer(neurons_h_layer_1 = 1, neurons_h_layer_2 = 1):\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(32, \n",
    "              input_dim=32, \n",
    "              activation='tanh', \n",
    "              kernel_initializer='glorot_normal',\n",
    "              kernel_constraint=MaxNorm(5),\n",
    "             ),\n",
    "        Dense(neurons_h_layer_1, activation='tanh'),\n",
    "        Dense(neurons_h_layer_2, activation='tanh'),\n",
    "        Dense(1, activation='softplus')\n",
    "    ])\n",
    "    optimizer = Adam(lr = 0.01)\n",
    "    \n",
    "    model.compile(\n",
    "    loss='mse', \n",
    "    optimizer=optimizer, \n",
    "    metrics=['mse', 'mae'])\n",
    "        \n",
    "    return model\n",
    "\n",
    "model_neurons_hidden_layer = KerasRegressor(build_fn=create_model_neurons_hidden_layer, epochs=500, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "incorporated-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "neurons_h_layer_1 = [8, 16, 32, 64, 128]\n",
    "neurons_h_layer_2 = [16, 32, 64, 128]\n",
    "param_grid = dict(neurons_h_layer_1=neurons_h_layer_1, neurons_h_layer_2=neurons_h_layer_2)\n",
    "grid = GridSearchCV(estimator=model_neurons_hidden_layer, param_grid=param_grid, n_jobs=None, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "hispanic-trinidad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.005979 using {'neurons_h_layer_1': 8, 'neurons_h_layer_2': 32}\n",
      "-0.006768 (0.001340) with: {'neurons_h_layer_1': 8, 'neurons_h_layer_2': 16}\n",
      "-0.005979 (0.001061) with: {'neurons_h_layer_1': 8, 'neurons_h_layer_2': 32}\n",
      "-0.008095 (0.002254) with: {'neurons_h_layer_1': 8, 'neurons_h_layer_2': 64}\n",
      "-0.006723 (0.001068) with: {'neurons_h_layer_1': 8, 'neurons_h_layer_2': 128}\n",
      "-0.007194 (0.001230) with: {'neurons_h_layer_1': 16, 'neurons_h_layer_2': 16}\n",
      "-0.006844 (0.001333) with: {'neurons_h_layer_1': 16, 'neurons_h_layer_2': 32}\n",
      "-0.007062 (0.000690) with: {'neurons_h_layer_1': 16, 'neurons_h_layer_2': 64}\n",
      "-0.152289 (0.206175) with: {'neurons_h_layer_1': 16, 'neurons_h_layer_2': 128}\n",
      "-0.010299 (0.003803) with: {'neurons_h_layer_1': 32, 'neurons_h_layer_2': 16}\n",
      "-0.007090 (0.000883) with: {'neurons_h_layer_1': 32, 'neurons_h_layer_2': 32}\n",
      "-0.008150 (0.002697) with: {'neurons_h_layer_1': 32, 'neurons_h_layer_2': 64}\n",
      "-0.143353 (0.193198) with: {'neurons_h_layer_1': 32, 'neurons_h_layer_2': 128}\n",
      "-0.006842 (0.001533) with: {'neurons_h_layer_1': 64, 'neurons_h_layer_2': 16}\n",
      "-0.006771 (0.000534) with: {'neurons_h_layer_1': 64, 'neurons_h_layer_2': 32}\n",
      "-0.006896 (0.000306) with: {'neurons_h_layer_1': 64, 'neurons_h_layer_2': 64}\n",
      "-0.290035 (0.198558) with: {'neurons_h_layer_1': 64, 'neurons_h_layer_2': 128}\n",
      "-0.018203 (0.009804) with: {'neurons_h_layer_1': 128, 'neurons_h_layer_2': 16}\n",
      "-0.009424 (0.001389) with: {'neurons_h_layer_1': 128, 'neurons_h_layer_2': 32}\n",
      "-0.007640 (0.000955) with: {'neurons_h_layer_1': 128, 'neurons_h_layer_2': 64}\n",
      "-0.016053 (0.004649) with: {'neurons_h_layer_1': 128, 'neurons_h_layer_2': 128}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-mechanism",
   "metadata": {},
   "source": [
    "### Optimal Parameters\n",
    "\n",
    "1. Batch Size & Number of Epochs with Training Optimization Algorithm \n",
    "(Best Params : Batch Size: 10, Epochs = 500, Optimzation Algorithm: Adam)\n",
    "3. Learning Rate & Momentum(if applies) of the optimal Training Optimization Algorithm (Learning Rate = 0.01)\n",
    "4. Network Weight Initialization(glorot_normal)\n",
    "5. Neuron Activation Function (activation=tanH, output_activation = SoftPlus)\n",
    "6. Dropout Regularization (dropout_rate: 0.0, weight_constraint: 5)\n",
    "7. Number of Neurons in the Hidden Layer(First Hidden layer = 8, Second Hidden layer = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-sending",
   "metadata": {},
   "source": [
    "#### Grid Searched CV's model\n",
    "\n",
    "With the best parameter GridSearchCV could find based on given set of parameters grid. Now we instantiate a model and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "experimental-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mmodel_gridsearched():\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(32, \n",
    "              input_dim=32, \n",
    "              activation='tanh', \n",
    "              kernel_initializer='glorot_normal',\n",
    "              kernel_constraint=MaxNorm(5),\n",
    "             ),\n",
    "        Dense(8, activation='tanh'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='tanh'),\n",
    "        Dense(1, activation='softplus')\n",
    "    ])\n",
    "    optimizer = Adam(lr = 0.01)\n",
    "    \n",
    "    model.compile(\n",
    "    loss='mse', \n",
    "    optimizer=optimizer, \n",
    "    metrics=['mse', 'mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_gridsearched = create_mmodel_gridsearched()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "current-sacrifice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0315 - mse: 0.0315 - mae: 0.1357 - val_loss: 0.0170 - val_mse: 0.0170 - val_mae: 0.1037\n",
      "Epoch 2/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0234 - mse: 0.0234 - mae: 0.1151 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.1179\n",
      "Epoch 3/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0213 - mse: 0.0213 - mae: 0.1098 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0844\n",
      "Epoch 4/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0182 - mae: 0.1035 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0909\n",
      "Epoch 5/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0172 - mse: 0.0172 - mae: 0.0990 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0855\n",
      "Epoch 6/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0894 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0676\n",
      "Epoch 7/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0774 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0804\n",
      "Epoch 8/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0124 - mae: 0.0833 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0620\n",
      "Epoch 9/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0749 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0657\n",
      "Epoch 10/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0783 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0961\n",
      "Epoch 11/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 0.0130 - mae: 0.0865 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0651\n",
      "Epoch 12/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0699 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0485\n",
      "Epoch 13/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0669 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0649\n",
      "Epoch 14/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0846 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0519\n",
      "Epoch 15/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0720 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0490\n",
      "Epoch 16/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0663 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0614\n",
      "Epoch 17/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0749 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0529\n",
      "Epoch 18/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0082 - mse: 0.0082 - mae: 0.0669 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0492\n",
      "Epoch 19/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0634 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0469\n",
      "Epoch 20/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0672 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0454\n",
      "Epoch 21/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0649 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0523\n",
      "Epoch 22/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0639 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0676\n",
      "Epoch 23/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0645 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0536\n",
      "Epoch 24/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0622 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0486\n",
      "Epoch 25/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0590 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0496\n",
      "Epoch 26/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0572 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0539\n",
      "Epoch 27/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0608 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0503\n",
      "Epoch 28/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0717 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0613\n",
      "Epoch 29/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0672 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0460\n",
      "Epoch 30/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0619 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0440\n",
      "Epoch 31/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0559 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0451\n",
      "Epoch 32/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0685 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0650\n",
      "Epoch 33/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0646 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0526\n",
      "Epoch 34/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0598 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0585\n",
      "Epoch 35/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0593 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0433\n",
      "Epoch 36/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0620 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0463\n",
      "Epoch 37/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0569 - val_loss: 0.0077 - val_mse: 0.0077 - val_mae: 0.0599\n",
      "Epoch 38/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0579 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0463\n",
      "Epoch 39/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0587 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0474\n",
      "Epoch 40/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0596 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0526\n",
      "Epoch 41/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0564 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0465\n",
      "Epoch 42/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0603 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0468\n",
      "Epoch 43/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0545 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0437\n",
      "Epoch 44/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0565 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0476\n",
      "Epoch 45/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0544 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0698\n",
      "Epoch 46/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0551 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0402\n",
      "Epoch 47/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0512 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0542\n",
      "Epoch 48/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0537 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0656\n",
      "Epoch 49/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0615 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0466\n",
      "Epoch 50/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0536 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0434\n",
      "Epoch 51/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0512 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0434\n",
      "Epoch 52/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0489 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0527\n",
      "Epoch 53/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0553 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0473\n",
      "Epoch 54/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0583 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0489\n",
      "Epoch 55/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0756 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0576\n",
      "Epoch 56/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0618 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0464\n",
      "Epoch 57/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0613 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0565\n",
      "Epoch 58/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0580 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0459\n",
      "Epoch 59/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0508 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0498\n",
      "Epoch 60/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0519 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0696\n",
      "Epoch 61/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0516 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0455\n",
      "Epoch 62/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0541 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0473\n",
      "Epoch 63/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0519 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0563\n",
      "Epoch 64/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0556 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0495\n",
      "Epoch 65/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0531 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0577\n",
      "Epoch 66/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0514 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0463\n",
      "Epoch 67/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0500 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0436\n",
      "Epoch 68/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0496 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0466\n",
      "Epoch 69/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0498 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0508\n",
      "Epoch 70/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0526 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0696\n",
      "Epoch 71/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0530 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0536\n",
      "Epoch 72/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0455 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0502\n",
      "Epoch 73/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0460 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0459\n",
      "Epoch 74/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0450 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0449\n",
      "Epoch 75/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0468 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0405\n",
      "Epoch 76/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0462 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0457\n",
      "Epoch 77/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0503 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0459\n",
      "Epoch 78/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0465 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0434\n",
      "Epoch 79/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0441 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0654\n",
      "Epoch 80/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0526 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0480\n",
      "Epoch 81/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0494 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0467\n",
      "Epoch 82/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0481 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0482\n",
      "Epoch 83/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0456 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0598\n",
      "Epoch 84/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0455 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0421\n",
      "Epoch 85/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0456 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0443\n",
      "Epoch 86/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0472 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0451\n",
      "Epoch 87/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0425 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0550\n",
      "Epoch 88/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0425 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0421\n",
      "Epoch 89/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0448 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0467\n",
      "Epoch 90/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0462 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0421\n",
      "Epoch 91/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0450 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0570\n",
      "Epoch 92/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0430 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0495\n",
      "Epoch 93/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0485 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0447\n",
      "Epoch 94/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0486 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0573\n",
      "Epoch 95/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0504 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0486\n",
      "Epoch 96/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0474 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0486\n",
      "Epoch 97/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0451 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0464\n",
      "Epoch 98/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0457 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0427\n",
      "Epoch 99/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0522 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0544\n",
      "Epoch 100/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0455 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0441\n",
      "Epoch 101/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0420 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0510\n",
      "Epoch 102/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0441 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0499\n",
      "Epoch 103/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0439 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0521\n",
      "Epoch 104/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0467 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0442\n",
      "Epoch 105/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0471 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0489\n",
      "Epoch 106/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0461 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0571\n",
      "Epoch 107/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0479 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0781\n",
      "Epoch 108/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0585 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0549\n",
      "Epoch 109/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0591 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0480\n",
      "Epoch 110/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0512 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0548\n",
      "Epoch 111/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0465 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0507\n",
      "Epoch 112/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0477 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0620\n",
      "Epoch 113/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0542 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0541\n",
      "Epoch 114/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0464 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0512\n",
      "Epoch 115/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0491 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0735\n",
      "Epoch 116/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0470 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0493\n",
      "Epoch 117/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0451 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0453\n",
      "Epoch 118/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0444 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0474\n",
      "Epoch 119/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0413 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0430\n",
      "Epoch 120/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0383 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0469\n",
      "Epoch 121/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0536 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0575\n",
      "Epoch 122/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0569 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0583\n",
      "Epoch 123/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0547 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0514\n",
      "Epoch 124/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0549 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0634\n",
      "Epoch 125/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0556 - val_loss: 0.0077 - val_mse: 0.0077 - val_mae: 0.0617\n",
      "Epoch 126/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0523 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0518\n",
      "Epoch 127/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0482 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0654\n",
      "Epoch 128/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0464 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0506\n",
      "Epoch 129/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0508 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0569\n",
      "Epoch 130/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0484 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0451\n",
      "Epoch 131/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0542 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0678\n",
      "Epoch 132/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0479 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0553\n",
      "Epoch 133/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0543 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0455\n",
      "Epoch 134/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0463 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0533\n",
      "Epoch 135/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0476 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0727\n",
      "Epoch 136/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0542 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0504\n",
      "Epoch 137/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0415 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0516\n",
      "Epoch 138/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0450 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0454\n",
      "Epoch 139/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0443 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0441\n",
      "Epoch 140/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0427 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0563\n",
      "Epoch 141/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0437 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0768\n",
      "Epoch 142/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0426 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0518\n",
      "Epoch 143/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0411 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0476\n",
      "Epoch 144/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0434 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0498\n",
      "Epoch 145/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0402 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0470\n",
      "Epoch 146/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0408 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0461\n",
      "Epoch 147/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0388 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0494\n",
      "Epoch 148/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0432 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0772\n",
      "Epoch 149/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0456 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0554\n",
      "Epoch 150/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0499 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0507 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0544\n",
      "Epoch 152/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0570 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0697\n",
      "Epoch 153/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0468 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0475\n",
      "Epoch 154/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0424 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0493\n",
      "Epoch 155/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0496 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0560\n",
      "Epoch 156/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0506 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0500\n",
      "Epoch 157/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0510 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0667\n",
      "Epoch 158/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0458 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0471\n",
      "Epoch 159/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0418 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0499\n",
      "Epoch 160/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0460 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0539\n",
      "Epoch 161/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0396 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0497\n",
      "Epoch 162/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0402 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0476\n",
      "Epoch 163/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0422 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0477\n",
      "Epoch 164/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0416 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0550\n",
      "Epoch 165/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0398 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0527\n",
      "Epoch 166/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0423 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0449\n",
      "Epoch 167/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0436 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0529\n",
      "Epoch 168/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0470 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0565\n",
      "Epoch 169/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0442 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0463\n",
      "Epoch 170/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0409 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0522\n",
      "Epoch 171/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0512 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0553\n",
      "Epoch 172/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0509 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0541\n",
      "Epoch 173/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0472 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0449\n",
      "Epoch 174/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0429 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0489\n",
      "Epoch 175/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0450 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0505\n",
      "Epoch 176/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0447 - val_loss: 0.0088 - val_mse: 0.0088 - val_mae: 0.0572\n",
      "Epoch 177/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0603 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0535\n",
      "Epoch 178/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0515 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0656\n",
      "Epoch 179/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0467 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0596\n",
      "Epoch 180/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0459 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0489\n",
      "Epoch 181/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0442 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0500\n",
      "Epoch 182/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0437 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0455\n",
      "Epoch 183/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0474 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0531\n",
      "Epoch 184/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0418 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0456\n",
      "Epoch 185/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0429 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0548\n",
      "Epoch 186/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0402 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0457\n",
      "Epoch 187/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0450 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0498\n",
      "Epoch 188/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0407 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0474\n",
      "Epoch 189/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0415 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0478\n",
      "Epoch 190/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0398 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0495\n",
      "Epoch 191/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0499 - val_loss: 0.0361 - val_mse: 0.0361 - val_mae: 0.1224\n",
      "Epoch 192/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 0.0138 - mae: 0.0864 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0754\n",
      "Epoch 193/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0781 - val_loss: 0.0166 - val_mse: 0.0166 - val_mae: 0.1001\n",
      "Epoch 194/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0601 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0497\n",
      "Epoch 195/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0443 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0532\n",
      "Epoch 196/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0507 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0508\n",
      "Epoch 197/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0559 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0537\n",
      "Epoch 198/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0525 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0552\n",
      "Epoch 199/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0500 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0546\n",
      "Epoch 200/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0457 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0450 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0493\n",
      "Epoch 202/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0470 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0514\n",
      "Epoch 203/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0430 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0520\n",
      "Epoch 204/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0450 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0535\n",
      "Epoch 205/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0409 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0557\n",
      "Epoch 206/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0441 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0552\n",
      "Epoch 207/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0459 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0544\n",
      "Epoch 208/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0417 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0654\n",
      "Epoch 209/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0402 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0543\n",
      "Epoch 210/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0424 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0523\n",
      "Epoch 211/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0429 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0543\n",
      "Epoch 212/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0389 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0512\n",
      "Epoch 213/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0392 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0479\n",
      "Epoch 214/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0403 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0466\n",
      "Epoch 215/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0377 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0470\n",
      "Epoch 216/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0433 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0486\n",
      "Epoch 217/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0379 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0466\n",
      "Epoch 218/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0386 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0462\n",
      "Epoch 219/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0398 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0513\n",
      "Epoch 220/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0397 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0486\n",
      "Epoch 221/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0402 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0517\n",
      "Epoch 222/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0409 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0498\n",
      "Epoch 223/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0437 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0495\n",
      "Epoch 224/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0409 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0519\n",
      "Epoch 225/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0344 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0539\n",
      "Epoch 226/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0369 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0451\n",
      "Epoch 227/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0371 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0526\n",
      "Epoch 228/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0399 - val_loss: 0.0076 - val_mse: 0.0076 - val_mae: 0.0585\n",
      "Epoch 229/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0369 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0506\n",
      "Epoch 230/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0366 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0548\n",
      "Epoch 231/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0376 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0631\n",
      "Epoch 232/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0447 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0490\n",
      "Epoch 233/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0417 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0504\n",
      "Epoch 234/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0440 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0508\n",
      "Epoch 235/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0370 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0512\n",
      "Epoch 236/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0390 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0531\n",
      "Epoch 237/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0452 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0586\n",
      "Epoch 238/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0416 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0566\n",
      "Epoch 239/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0426 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0556\n",
      "Epoch 240/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0407 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0542\n",
      "Epoch 241/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0591 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0613\n",
      "Epoch 242/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0651 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0717\n",
      "Epoch 243/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0659 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0681\n",
      "Epoch 244/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0681 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0614\n",
      "Epoch 245/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0605 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0520\n",
      "Epoch 246/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0504 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0533\n",
      "Epoch 247/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0598 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0625\n",
      "Epoch 248/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0651 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0553\n",
      "Epoch 249/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0585 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0511\n",
      "Epoch 250/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0484 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0494 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0617\n",
      "Epoch 252/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0624 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0587\n",
      "Epoch 253/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0595 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0523\n",
      "Epoch 254/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0590 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0560\n",
      "Epoch 255/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0708 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0819\n",
      "Epoch 256/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0601 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0522\n",
      "Epoch 257/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0476 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0477\n",
      "Epoch 258/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0492 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0499\n",
      "Epoch 259/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0449 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0517\n",
      "Epoch 260/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0431 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0523\n",
      "Epoch 261/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0481 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0467\n",
      "Epoch 262/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0467 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0492\n",
      "Epoch 263/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0405 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0462\n",
      "Epoch 264/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0440 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0507\n",
      "Epoch 265/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0445 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0488\n",
      "Epoch 266/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0386 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0482\n",
      "Epoch 267/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0379 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0482\n",
      "Epoch 268/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0395 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0484\n",
      "Epoch 269/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0408 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0499\n",
      "Epoch 270/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0399 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0508\n",
      "Epoch 271/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0420 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0466\n",
      "Epoch 272/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0389 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0482\n",
      "Epoch 273/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0362 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0539\n",
      "Epoch 274/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0421 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0470\n",
      "Epoch 275/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0372 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0483\n",
      "Epoch 276/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0391 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0498\n",
      "Epoch 277/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0426 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0553\n",
      "Epoch 278/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0398 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0474\n",
      "Epoch 279/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0404 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0496\n",
      "Epoch 280/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0387 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0498\n",
      "Epoch 281/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0408 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0479\n",
      "Epoch 282/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0389 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0479\n",
      "Epoch 283/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0390 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0475\n",
      "Epoch 284/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0421 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0488\n",
      "Epoch 285/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0371 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0463\n",
      "Epoch 286/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0377 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0443\n",
      "Epoch 287/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0381 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0504\n",
      "Epoch 288/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0386 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0530\n",
      "Epoch 289/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0399 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0525\n",
      "Epoch 290/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0413 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0472\n",
      "Epoch 291/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0372 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0503\n",
      "Epoch 292/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0393 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0501\n",
      "Epoch 293/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0376 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0520\n",
      "Epoch 294/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0393 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0487\n",
      "Epoch 295/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0391 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0466\n",
      "Epoch 296/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0403 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0504\n",
      "Epoch 297/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0389 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0524\n",
      "Epoch 298/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0386 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0502\n",
      "Epoch 299/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0354 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0511\n",
      "Epoch 300/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0494 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0512 - val_loss: 0.0077 - val_mse: 0.0077 - val_mae: 0.0580\n",
      "Epoch 302/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0463 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0543\n",
      "Epoch 303/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0586 - val_loss: 0.0178 - val_mse: 0.0178 - val_mae: 0.0849\n",
      "Epoch 304/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0668 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0546\n",
      "Epoch 305/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0590 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0701\n",
      "Epoch 306/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0502 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0572\n",
      "Epoch 307/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0399 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0570\n",
      "Epoch 308/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0407 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0594\n",
      "Epoch 309/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0466 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0565\n",
      "Epoch 310/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0424 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0532\n",
      "Epoch 311/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0439 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0526\n",
      "Epoch 312/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0386 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0520\n",
      "Epoch 313/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0409 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0498\n",
      "Epoch 314/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0517 - val_loss: 0.0151 - val_mse: 0.0151 - val_mae: 0.0759\n",
      "Epoch 315/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0794 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0659\n",
      "Epoch 316/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0633 - val_loss: 0.0077 - val_mse: 0.0077 - val_mae: 0.0603\n",
      "Epoch 317/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0460 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0454\n",
      "Epoch 318/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0456 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0456\n",
      "Epoch 319/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0435 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0499\n",
      "Epoch 320/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0437 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0483\n",
      "Epoch 321/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0424 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0591\n",
      "Epoch 322/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0439 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0507\n",
      "Epoch 323/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0414 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0552\n",
      "Epoch 324/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0436 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0610\n",
      "Epoch 325/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0428 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0524\n",
      "Epoch 326/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0427 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0630\n",
      "Epoch 327/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0371 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0509\n",
      "Epoch 328/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0385 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0554\n",
      "Epoch 329/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0551 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0564\n",
      "Epoch 330/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0587 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0523\n",
      "Epoch 331/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0539 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0518\n",
      "Epoch 332/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0500 - val_loss: 0.0076 - val_mse: 0.0076 - val_mae: 0.0535\n",
      "Epoch 333/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0404 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0477\n",
      "Epoch 334/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0465 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0515\n",
      "Epoch 335/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0419 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0484\n",
      "Epoch 336/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0404 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0513\n",
      "Epoch 337/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0382 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0550\n",
      "Epoch 338/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0375 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0497\n",
      "Epoch 339/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0374 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0474\n",
      "Epoch 340/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0394 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0512\n",
      "Epoch 341/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0393 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0481\n",
      "Epoch 342/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0423 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0477\n",
      "Epoch 343/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0374 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0495\n",
      "Epoch 344/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0414 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0558\n",
      "Epoch 345/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0398 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0526\n",
      "Epoch 346/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0403 - val_loss: 0.0077 - val_mse: 0.0077 - val_mae: 0.0584\n",
      "Epoch 347/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0608 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0630\n",
      "Epoch 348/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0569 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0512\n",
      "Epoch 349/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0549 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0589\n",
      "Epoch 350/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0477 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0434 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0559\n",
      "Epoch 352/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0423 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0543\n",
      "Epoch 353/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0420 - val_loss: 0.0076 - val_mse: 0.0076 - val_mae: 0.0575\n",
      "Epoch 354/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0412 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0548\n",
      "Epoch 355/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0391 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0546\n",
      "Epoch 356/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0369 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0529\n",
      "Epoch 357/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0372 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0559\n",
      "Epoch 358/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0435 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0558\n",
      "Epoch 359/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0393 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0532\n",
      "Epoch 360/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0344 - val_loss: 0.0076 - val_mse: 0.0076 - val_mae: 0.0576\n",
      "Epoch 361/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0377 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0537\n",
      "Epoch 362/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0393 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0533\n",
      "Epoch 363/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0357 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0549\n",
      "Epoch 364/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0395 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0553\n",
      "Epoch 365/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0373 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0538\n",
      "Epoch 366/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0377 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0562\n",
      "Epoch 367/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0411 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0651\n",
      "Epoch 368/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0451 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0546\n",
      "Epoch 369/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0350 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0585\n",
      "Epoch 370/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0393 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0539\n",
      "Epoch 371/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0344 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0550\n",
      "Epoch 372/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0376 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0498\n",
      "Epoch 373/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0378 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0534\n",
      "Epoch 374/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0376 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0553\n",
      "Epoch 375/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0414 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0560\n",
      "Epoch 376/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0376 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0602\n",
      "Epoch 377/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0397 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0536\n",
      "Epoch 378/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0365 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0508\n",
      "Epoch 379/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0391 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0533\n",
      "Epoch 380/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0411 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0522\n",
      "Epoch 381/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0405 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0565\n",
      "Epoch 382/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0502 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0547\n",
      "Epoch 383/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0449 - val_loss: 0.0134 - val_mse: 0.0134 - val_mae: 0.0851\n",
      "Epoch 384/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0544 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0608\n",
      "Epoch 385/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0470 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0570\n",
      "Epoch 386/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0438 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0556\n",
      "Epoch 387/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0412 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0540\n",
      "Epoch 388/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0369 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0536\n",
      "Epoch 389/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0376 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0550\n",
      "Epoch 390/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0348 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0489\n",
      "Epoch 391/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0356 - val_loss: 0.0076 - val_mse: 0.0076 - val_mae: 0.0566\n",
      "Epoch 392/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0412 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0542\n",
      "Epoch 393/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0356 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0524\n",
      "Epoch 394/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0381 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0529\n",
      "Epoch 395/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0432 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0540\n",
      "Epoch 396/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0438 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0502\n",
      "Epoch 397/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0397 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0534\n",
      "Epoch 398/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0395 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0555\n",
      "Epoch 399/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0401 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0581\n",
      "Epoch 400/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0391 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0379 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0551\n",
      "Epoch 402/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0359 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0524\n",
      "Epoch 403/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0393 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0501\n",
      "Epoch 404/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0381 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0520\n",
      "Epoch 405/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0421 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0569\n",
      "Epoch 406/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0423 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0585\n",
      "Epoch 407/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0382 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0600\n",
      "Epoch 408/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0406 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0540\n",
      "Epoch 409/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0432 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0642\n",
      "Epoch 410/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0428 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0505\n",
      "Epoch 411/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0475 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0664\n",
      "Epoch 412/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0601 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0549\n",
      "Epoch 413/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0522 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0780\n",
      "Epoch 414/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0471 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0619\n",
      "Epoch 415/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0481 - val_loss: 0.0076 - val_mse: 0.0076 - val_mae: 0.0554\n",
      "Epoch 416/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0439 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0560\n",
      "Epoch 417/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0423 - val_loss: 0.0076 - val_mse: 0.0076 - val_mae: 0.0601\n",
      "Epoch 418/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0419 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0567\n",
      "Epoch 419/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0431 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0534\n",
      "Epoch 420/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0445 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0532\n",
      "Epoch 421/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0386 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0585\n",
      "Epoch 422/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0467 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0531\n",
      "Epoch 423/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0408 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0554\n",
      "Epoch 424/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0438 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0593\n",
      "Epoch 425/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0446 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0492\n",
      "Epoch 426/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0393 - val_loss: 0.0077 - val_mse: 0.0077 - val_mae: 0.0567\n",
      "Epoch 427/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0490 - val_loss: 0.0171 - val_mse: 0.0171 - val_mae: 0.0922\n",
      "Epoch 428/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0628 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0752\n",
      "Epoch 429/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0612 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0666\n",
      "Epoch 430/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0534 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0638\n",
      "Epoch 431/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0546 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0572\n",
      "Epoch 432/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0471 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0549\n",
      "Epoch 433/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0511 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0548\n",
      "Epoch 434/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0443 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0624\n",
      "Epoch 435/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0405 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0555\n",
      "Epoch 436/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0389 - val_loss: 0.0077 - val_mse: 0.0077 - val_mae: 0.0586\n",
      "Epoch 437/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0397 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0570\n",
      "Epoch 438/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0364 - val_loss: 0.0076 - val_mse: 0.0076 - val_mae: 0.0554\n",
      "Epoch 439/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0376 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0566\n",
      "Epoch 440/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0385 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0592\n",
      "Epoch 441/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0362 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0609\n",
      "Epoch 442/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0379 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0601\n",
      "Epoch 443/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0397 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0561\n",
      "Epoch 444/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0343 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0608\n",
      "Epoch 445/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0350 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0552\n",
      "Epoch 446/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0393 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0606\n",
      "Epoch 447/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0430 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0610\n",
      "Epoch 448/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0441 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0545\n",
      "Epoch 449/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0392 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0635\n",
      "Epoch 450/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0403 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0432 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0684\n",
      "Epoch 452/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0413 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0687\n",
      "Epoch 453/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0426 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0634\n",
      "Epoch 454/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0391 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0571\n",
      "Epoch 455/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0379 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0567\n",
      "Epoch 456/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0331 - val_loss: 0.0076 - val_mse: 0.0076 - val_mae: 0.0574\n",
      "Epoch 457/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0368 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0558\n",
      "Epoch 458/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0411 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0596\n",
      "Epoch 459/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0369 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0604\n",
      "Epoch 460/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0384 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0563\n",
      "Epoch 461/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0436 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0605\n",
      "Epoch 462/500\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0452 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0575\n",
      "Epoch 463/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0376 - val_loss: 0.0076 - val_mse: 0.0076 - val_mae: 0.0567\n",
      "Epoch 464/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0366 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0564\n",
      "Epoch 465/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0446 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0560\n",
      "Epoch 466/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0401 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0610\n",
      "Epoch 467/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0380 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0584\n",
      "Epoch 468/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0400 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0582\n",
      "Epoch 469/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0377 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0638\n",
      "Epoch 470/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0346 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0556\n",
      "Epoch 471/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0356 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0613\n",
      "Epoch 472/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0377 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0642\n",
      "Epoch 473/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0383 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0655\n",
      "Epoch 474/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0364 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0619\n",
      "Epoch 475/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0371 - val_loss: 0.0088 - val_mse: 0.0088 - val_mae: 0.0583\n",
      "Epoch 476/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0374 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0626\n",
      "Epoch 477/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0380 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0666\n",
      "Epoch 478/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0414 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0686\n",
      "Epoch 479/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0406 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0658\n",
      "Epoch 480/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0436 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0689\n",
      "Epoch 481/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0528 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0564\n",
      "Epoch 482/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0560 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0594\n",
      "Epoch 483/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0483 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0541\n",
      "Epoch 484/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0426 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0522\n",
      "Epoch 485/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0388 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0561\n",
      "Epoch 486/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0388 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0524\n",
      "Epoch 487/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0409 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0651\n",
      "Epoch 488/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0386 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0637\n",
      "Epoch 489/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0410 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0562\n",
      "Epoch 490/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0358 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0549\n",
      "Epoch 491/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0361 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0529\n",
      "Epoch 492/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0398 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0563\n",
      "Epoch 493/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0367 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0575\n",
      "Epoch 494/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0366 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0534\n",
      "Epoch 495/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0449 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0627\n",
      "Epoch 496/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0506 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0723\n",
      "Epoch 497/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0444 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0606\n",
      "Epoch 498/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0382 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0540\n",
      "Epoch 499/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0415 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0548\n",
      "Epoch 500/500\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0360 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0525\n"
     ]
    }
   ],
   "source": [
    "history_model_gridsearched = model_gridsearched.fit(X_train, y_train, epochs=500, batch_size=10,  verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "offshore-community",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(history.history.keys())\n",
    "plt.plot(history_model_gridsearched.history['loss'])\n",
    "plt.plot(history_model_gridsearched.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-sympathy",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "eleven-sampling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted G3's score is 9.82\n"
     ]
    }
   ],
   "source": [
    "df2 = features.iloc[644] # Test with the 14th Student \n",
    "Xnew = np.array([df2])\n",
    "Xnew.reshape(-1, 1)\n",
    "\n",
    "Xnew= scaler_x.transform(Xnew)\n",
    "ynew= model_gridsearched.predict(Xnew)\n",
    "\n",
    "# #invert normalize\n",
    "ynew = scaler_y.inverse_transform(ynew) \n",
    "Xnew = scaler_x.inverse_transform(Xnew)\n",
    "\n",
    "#print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))\n",
    "print(\"Predicted G3's score is {:.2f}\".format(float(ynew)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "coordinate-passion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error : 0.00918\n",
      "Mean Absolute Error : 0.05933\n"
     ]
    }
   ],
   "source": [
    "loss, mean_sq_e, mean_abs_e = model_gridsearched.evaluate(X_test, y_test, batch_size=10,verbose=0)\n",
    "print(\"Mean Squared Error : {:.5f}\".format(mean_sq_e))\n",
    "print(\"Mean Absolute Error : {:.5f}\".format(mean_abs_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "passing-memphis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.62\n",
      "Difference : 1.382\n",
      "1\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.30\n",
      "Difference : 0.300\n",
      "2\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.21\n",
      "Difference : 0.209\n",
      "3\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.90\n",
      "Difference : 0.903\n",
      "4\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.74\n",
      "Difference : 0.260\n",
      "5\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.33\n",
      "Difference : 0.667\n",
      "6\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.46\n",
      "Difference : 0.542\n",
      "7\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.20\n",
      "Difference : 0.800\n",
      "8\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.71\n",
      "Difference : 1.289\n",
      "9\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.85\n",
      "Difference : 0.147\n",
      "10\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.97\n",
      "Difference : 0.971\n",
      "11\n",
      "Real Values : 13\n",
      "Predicted G3's score is 11.75\n",
      "Difference : 1.254\n",
      "12\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.29\n",
      "Difference : 0.290\n",
      "13\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.22\n",
      "Difference : 0.775\n",
      "14\n",
      "Real Values : 15\n",
      "Predicted G3's score is 14.37\n",
      "Difference : 0.630\n",
      "15\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.88\n",
      "Difference : 1.120\n",
      "16\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.07\n",
      "Difference : 0.068\n",
      "17\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.16\n",
      "Difference : 0.160\n",
      "18\n",
      "Real Values : 7\n",
      "Predicted G3's score is 7.53\n",
      "Difference : 0.529\n",
      "19\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.95\n",
      "Difference : 0.047\n",
      "20\n",
      "Real Values : 14\n",
      "Predicted G3's score is 13.95\n",
      "Difference : 0.050\n",
      "21\n",
      "Real Values : 12\n",
      "Predicted G3's score is 10.50\n",
      "Difference : 1.504\n",
      "22\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.25\n",
      "Difference : 0.254\n",
      "23\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.03\n",
      "Difference : 0.030\n",
      "24\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.69\n",
      "Difference : 0.307\n",
      "25\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.59\n",
      "Difference : 0.410\n",
      "26\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.76\n",
      "Difference : 0.236\n",
      "27\n",
      "Real Values : 11\n",
      "Predicted G3's score is 12.01\n",
      "Difference : 1.014\n",
      "28\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.70\n",
      "Difference : 0.303\n",
      "29\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.95\n",
      "Difference : 0.051\n",
      "30\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.01\n",
      "Difference : 0.015\n",
      "31\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.42\n",
      "Difference : 0.417\n",
      "32\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.20\n",
      "Difference : 0.202\n",
      "33\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.00\n",
      "Difference : 0.002\n",
      "34\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.06\n",
      "Difference : 0.060\n",
      "35\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.13\n",
      "Difference : 0.869\n",
      "36\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.81\n",
      "Difference : 0.805\n",
      "37\n",
      "Real Values : 13\n",
      "Predicted G3's score is 14.95\n",
      "Difference : 1.954\n",
      "38\n",
      "Real Values : 12\n",
      "Predicted G3's score is 10.01\n",
      "Difference : 1.990\n",
      "39\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.81\n",
      "Difference : 0.188\n",
      "40\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.77\n",
      "Difference : 0.772\n",
      "41\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.98\n",
      "Difference : 0.023\n",
      "42\n",
      "Real Values : 15\n",
      "Predicted G3's score is 14.97\n",
      "Difference : 0.032\n",
      "43\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.83\n",
      "Difference : 0.835\n",
      "44\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.76\n",
      "Difference : 1.241\n",
      "45\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.63\n",
      "Difference : 0.366\n",
      "46\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.69\n",
      "Difference : 0.305\n",
      "47\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.83\n",
      "Difference : 1.171\n",
      "48\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.34\n",
      "Difference : 0.660\n",
      "49\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.87\n",
      "Difference : 0.127\n",
      "50\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.43\n",
      "Difference : 0.435\n",
      "51\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.45\n",
      "Difference : 0.554\n",
      "52\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.60\n",
      "Difference : 0.596\n",
      "53\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.14\n",
      "Difference : 0.142\n",
      "54\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.48\n",
      "Difference : 0.522\n",
      "55\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.18\n",
      "Difference : 0.176\n",
      "56\n",
      "Real Values : 15\n",
      "Predicted G3's score is 14.79\n",
      "Difference : 0.210\n",
      "57\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.04\n",
      "Difference : 0.959\n",
      "58\n",
      "Real Values : 14\n",
      "Predicted G3's score is 13.28\n",
      "Difference : 0.720\n",
      "59\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.68\n",
      "Difference : 0.319\n",
      "60\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.70\n",
      "Difference : 0.299\n",
      "61\n",
      "Real Values : 16\n",
      "Predicted G3's score is 11.99\n",
      "Difference : 4.012\n",
      "62\n",
      "Real Values : 10\n",
      "Predicted G3's score is 13.51\n",
      "Difference : 3.513\n",
      "63\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.80\n",
      "Difference : 0.196\n",
      "64\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.25\n",
      "Difference : 0.754\n",
      "65\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.66\n",
      "Difference : 0.342\n",
      "66\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.63\n",
      "Difference : 0.370\n",
      "67\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.78\n",
      "Difference : 0.224\n",
      "68\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.12\n",
      "Difference : 0.879\n",
      "69\n",
      "Real Values : 15\n",
      "Predicted G3's score is 14.88\n",
      "Difference : 0.120\n",
      "70\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.27\n",
      "Difference : 0.267\n",
      "71\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.70\n",
      "Difference : 0.300\n",
      "72\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.53\n",
      "Difference : 0.470\n",
      "73\n",
      "Real Values : 14\n",
      "Predicted G3's score is 13.59\n",
      "Difference : 0.405\n",
      "74\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.08\n",
      "Difference : 0.082\n",
      "75\n",
      "Real Values : 11\n",
      "Predicted G3's score is 12.07\n",
      "Difference : 1.071\n",
      "76\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.17\n",
      "Difference : 0.172\n",
      "77\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.48\n",
      "Difference : 0.520\n",
      "78\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.71\n",
      "Difference : 0.290\n",
      "79\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.08\n",
      "Difference : 0.083\n",
      "80\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.73\n",
      "Difference : 0.274\n",
      "81\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.64\n",
      "Difference : 0.640\n",
      "82\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.31\n",
      "Difference : 0.686\n",
      "83\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.01\n",
      "Difference : 0.989\n",
      "84\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.29\n",
      "Difference : 0.293\n",
      "85\n",
      "Real Values : 12\n",
      "Predicted G3's score is 10.04\n",
      "Difference : 1.962\n",
      "86\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.15\n",
      "Difference : 0.150\n",
      "87\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.52\n",
      "Difference : 0.521\n",
      "88\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.15\n",
      "Difference : 0.155\n",
      "89\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.70\n",
      "Difference : 0.302\n",
      "90\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.87\n",
      "Difference : 0.128\n",
      "91\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.85\n",
      "Difference : 0.851\n",
      "92\n",
      "Real Values : 12\n",
      "Predicted G3's score is 10.97\n",
      "Difference : 1.029\n",
      "93\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.62\n",
      "Difference : 0.619\n",
      "94\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.06\n",
      "Difference : 0.060\n",
      "95\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.89\n",
      "Difference : 0.112\n",
      "96\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.91\n",
      "Difference : 0.086\n",
      "97\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.57\n",
      "Difference : 0.427\n",
      "98\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.91\n",
      "Difference : 0.085\n",
      "99\n",
      "Real Values : 13\n",
      "Predicted G3's score is 11.92\n",
      "Difference : 1.077\n",
      "100\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.57\n",
      "Difference : 1.567\n",
      "101\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.81\n",
      "Difference : 0.195\n",
      "102\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.06\n",
      "Difference : 0.064\n",
      "103\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.67\n",
      "Difference : 0.665\n",
      "104\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.78\n",
      "Difference : 0.218\n",
      "105\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.66\n",
      "Difference : 0.344\n",
      "106\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.68\n",
      "Difference : 0.315\n",
      "107\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.35\n",
      "Difference : 0.355\n",
      "108\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.93\n",
      "Difference : 0.071\n",
      "109\n",
      "Real Values : 14\n",
      "Predicted G3's score is 13.88\n",
      "Difference : 0.117\n",
      "110\n",
      "Real Values : 14\n",
      "Predicted G3's score is 15.08\n",
      "Difference : 1.079\n",
      "111\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.70\n",
      "Difference : 1.301\n",
      "112\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.56\n",
      "Difference : 0.440\n",
      "113\n",
      "Real Values : 18\n",
      "Predicted G3's score is 15.90\n",
      "Difference : 2.104\n",
      "114\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.65\n",
      "Difference : 0.348\n",
      "115\n",
      "Real Values : 14\n",
      "Predicted G3's score is 15.03\n",
      "Difference : 1.030\n",
      "116\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.72\n",
      "Difference : 0.279\n",
      "117\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.36\n",
      "Difference : 0.362\n",
      "118\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.79\n",
      "Difference : 0.208\n",
      "119\n",
      "Real Values : 14\n",
      "Predicted G3's score is 13.57\n",
      "Difference : 0.426\n",
      "120\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.42\n",
      "Difference : 0.417\n",
      "121\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.88\n",
      "Difference : 0.116\n",
      "122\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.52\n",
      "Difference : 0.522\n",
      "123\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.35\n",
      "Difference : 0.350\n",
      "124\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.61\n",
      "Difference : 0.390\n",
      "125\n",
      "Real Values : 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted G3's score is 10.05\n",
      "Difference : 1.050\n",
      "126\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.53\n",
      "Difference : 0.532\n",
      "127\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.27\n",
      "Difference : 0.729\n",
      "128\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.56\n",
      "Difference : 0.561\n",
      "129\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.57\n",
      "Difference : 0.431\n",
      "130\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.51\n",
      "Difference : 0.493\n",
      "131\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.57\n",
      "Difference : 1.566\n",
      "132\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.83\n",
      "Difference : 0.165\n",
      "133\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.02\n",
      "Difference : 0.023\n",
      "134\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.73\n",
      "Difference : 0.269\n",
      "135\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.25\n",
      "Difference : 0.245\n",
      "136\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.60\n",
      "Difference : 1.395\n",
      "137\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.46\n",
      "Difference : 0.461\n",
      "138\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.38\n",
      "Difference : 0.381\n",
      "139\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.18\n",
      "Difference : 0.181\n",
      "140\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.99\n",
      "Difference : 0.990\n",
      "141\n",
      "Real Values : 13\n",
      "Predicted G3's score is 14.63\n",
      "Difference : 1.625\n",
      "142\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.08\n",
      "Difference : 0.076\n",
      "143\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.65\n",
      "Difference : 0.649\n",
      "144\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.41\n",
      "Difference : 0.412\n",
      "145\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.67\n",
      "Difference : 0.327\n",
      "146\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.59\n",
      "Difference : 0.406\n",
      "147\n",
      "Real Values : 14\n",
      "Predicted G3's score is 15.59\n",
      "Difference : 1.587\n",
      "148\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.56\n",
      "Difference : 0.562\n",
      "149\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.87\n",
      "Difference : 1.133\n",
      "150\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.56\n",
      "Difference : 0.559\n",
      "151\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.36\n",
      "Difference : 0.357\n",
      "152\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.43\n",
      "Difference : 0.427\n",
      "153\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.81\n",
      "Difference : 0.814\n",
      "154\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.84\n",
      "Difference : 0.158\n",
      "155\n",
      "Real Values : 6\n",
      "Predicted G3's score is 9.50\n",
      "Difference : 3.502\n",
      "156\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.15\n",
      "Difference : 0.148\n",
      "157\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.72\n",
      "Difference : 0.283\n",
      "158\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.01\n",
      "Difference : 0.993\n",
      "159\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.10\n",
      "Difference : 0.903\n",
      "160\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.75\n",
      "Difference : 0.750\n",
      "161\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.57\n",
      "Difference : 1.568\n",
      "162\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.86\n",
      "Difference : 0.137\n",
      "163\n",
      "Real Values : 0\n",
      "Predicted G3's score is 10.01\n",
      "Difference : 10.005\n",
      "164\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.74\n",
      "Difference : 0.259\n",
      "165\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.13\n",
      "Difference : 0.866\n",
      "166\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.60\n",
      "Difference : 0.402\n",
      "167\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.57\n",
      "Difference : 0.433\n",
      "168\n",
      "Real Values : 8\n",
      "Predicted G3's score is 7.50\n",
      "Difference : 0.496\n",
      "169\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.39\n",
      "Difference : 0.610\n",
      "170\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.96\n",
      "Difference : 0.043\n",
      "171\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.04\n",
      "Difference : 0.963\n",
      "172\n",
      "Real Values : 1\n",
      "Predicted G3's score is 9.97\n",
      "Difference : 8.973\n",
      "173\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.63\n",
      "Difference : 0.373\n",
      "174\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.55\n",
      "Difference : 0.548\n",
      "175\n",
      "Real Values : 8\n",
      "Predicted G3's score is 8.42\n",
      "Difference : 0.418\n",
      "176\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.62\n",
      "Difference : 0.379\n",
      "177\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.48\n",
      "Difference : 1.485\n",
      "178\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.61\n",
      "Difference : 1.611\n",
      "179\n",
      "Real Values : 8\n",
      "Predicted G3's score is 7.75\n",
      "Difference : 0.254\n",
      "180\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.78\n",
      "Difference : 1.216\n",
      "181\n",
      "Real Values : 18\n",
      "Predicted G3's score is 15.87\n",
      "Difference : 2.127\n",
      "182\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.55\n",
      "Difference : 0.447\n",
      "183\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.70\n",
      "Difference : 1.298\n",
      "184\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.66\n",
      "Difference : 0.342\n",
      "185\n",
      "Real Values : 18\n",
      "Predicted G3's score is 15.88\n",
      "Difference : 2.121\n",
      "186\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.93\n",
      "Difference : 0.071\n",
      "187\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.90\n",
      "Difference : 0.101\n",
      "188\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.03\n",
      "Difference : 0.032\n",
      "189\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.26\n",
      "Difference : 0.257\n",
      "190\n",
      "Real Values : 14\n",
      "Predicted G3's score is 15.01\n",
      "Difference : 1.008\n",
      "191\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.38\n",
      "Difference : 0.380\n",
      "192\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.83\n",
      "Difference : 1.171\n",
      "193\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.26\n",
      "Difference : 0.741\n",
      "194\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.54\n",
      "Difference : 0.539\n",
      "195\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.76\n",
      "Difference : 0.759\n",
      "196\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.84\n",
      "Difference : 1.163\n",
      "197\n",
      "Real Values : 14\n",
      "Predicted G3's score is 11.25\n",
      "Difference : 2.747\n",
      "198\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.55\n",
      "Difference : 0.445\n",
      "199\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.98\n",
      "Difference : 0.977\n",
      "200\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.05\n",
      "Difference : 0.952\n",
      "201\n",
      "Real Values : 16\n",
      "Predicted G3's score is 13.72\n",
      "Difference : 2.285\n",
      "202\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.17\n",
      "Difference : 0.169\n",
      "203\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.66\n",
      "Difference : 0.336\n",
      "204\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.61\n",
      "Difference : 0.613\n",
      "205\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.43\n",
      "Difference : 0.429\n",
      "206\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.25\n",
      "Difference : 0.754\n",
      "207\n",
      "Real Values : 10\n",
      "Predicted G3's score is 12.00\n",
      "Difference : 1.997\n",
      "208\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.42\n",
      "Difference : 0.419\n",
      "209\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.75\n",
      "Difference : 0.254\n",
      "210\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.90\n",
      "Difference : 0.902\n",
      "211\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.86\n",
      "Difference : 0.144\n",
      "212\n",
      "Real Values : 16\n",
      "Predicted G3's score is 14.88\n",
      "Difference : 1.124\n",
      "213\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.94\n",
      "Difference : 1.061\n",
      "214\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.61\n",
      "Difference : 0.615\n",
      "215\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.91\n",
      "Difference : 0.089\n",
      "216\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.38\n",
      "Difference : 0.381\n",
      "217\n",
      "Real Values : 13\n",
      "Predicted G3's score is 14.25\n",
      "Difference : 1.246\n",
      "218\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.47\n",
      "Difference : 0.526\n",
      "219\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.56\n",
      "Difference : 1.558\n",
      "220\n",
      "Real Values : 12\n",
      "Predicted G3's score is 13.20\n",
      "Difference : 1.200\n",
      "221\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.21\n",
      "Difference : 0.209\n",
      "222\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.29\n",
      "Difference : 0.706\n",
      "223\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.37\n",
      "Difference : 0.369\n",
      "224\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.30\n",
      "Difference : 0.696\n",
      "225\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.65\n",
      "Difference : 0.354\n",
      "226\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.87\n",
      "Difference : 0.126\n",
      "227\n",
      "Real Values : 11\n",
      "Predicted G3's score is 12.55\n",
      "Difference : 1.554\n",
      "228\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.61\n",
      "Difference : 0.391\n",
      "229\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.59\n",
      "Difference : 0.591\n",
      "230\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.68\n",
      "Difference : 0.321\n",
      "231\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.41\n",
      "Difference : 0.405\n",
      "232\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.73\n",
      "Difference : 0.269\n",
      "233\n",
      "Real Values : 13\n",
      "Predicted G3's score is 15.08\n",
      "Difference : 2.076\n",
      "234\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.46\n",
      "Difference : 0.458\n",
      "235\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.58\n",
      "Difference : 0.422\n",
      "236\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.84\n",
      "Difference : 0.842\n",
      "237\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.71\n",
      "Difference : 0.292\n",
      "238\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.25\n",
      "Difference : 0.747\n",
      "239\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.56\n",
      "Difference : 1.560\n",
      "240\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.86\n",
      "Difference : 1.137\n",
      "241\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.44\n",
      "Difference : 0.565\n",
      "242\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.26\n",
      "Difference : 0.738\n",
      "243\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.58\n",
      "Difference : 0.417\n",
      "244\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.15\n",
      "Difference : 0.154\n",
      "245\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.51\n",
      "Difference : 0.507\n",
      "246\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.57\n",
      "Difference : 0.429\n",
      "247\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.31\n",
      "Difference : 0.314\n",
      "248\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.63\n",
      "Difference : 0.632\n",
      "249\n",
      "Real Values : 12\n",
      "Predicted G3's score is 13.06\n",
      "Difference : 1.064\n",
      "250\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.47\n",
      "Difference : 0.526\n",
      "251\n",
      "Real Values : 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted G3's score is 9.91\n",
      "Difference : 0.086\n",
      "252\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.74\n",
      "Difference : 0.259\n",
      "253\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.84\n",
      "Difference : 0.163\n",
      "254\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.58\n",
      "Difference : 0.415\n",
      "255\n",
      "Real Values : 7\n",
      "Predicted G3's score is 7.99\n",
      "Difference : 0.992\n",
      "256\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.57\n",
      "Difference : 1.567\n",
      "257\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.63\n",
      "Difference : 0.626\n",
      "258\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.55\n",
      "Difference : 0.549\n",
      "259\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.77\n",
      "Difference : 0.231\n",
      "260\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.79\n",
      "Difference : 0.213\n",
      "261\n",
      "Real Values : 13\n",
      "Predicted G3's score is 11.99\n",
      "Difference : 1.014\n",
      "262\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.45\n",
      "Difference : 1.451\n",
      "263\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.55\n",
      "Difference : 1.550\n",
      "264\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.21\n",
      "Difference : 0.208\n",
      "265\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.24\n",
      "Difference : 0.235\n",
      "266\n",
      "Real Values : 14\n",
      "Predicted G3's score is 15.62\n",
      "Difference : 1.621\n",
      "267\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.26\n",
      "Difference : 0.264\n",
      "268\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.16\n",
      "Difference : 0.157\n",
      "269\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.11\n",
      "Difference : 0.111\n",
      "270\n",
      "Real Values : 15\n",
      "Predicted G3's score is 13.71\n",
      "Difference : 1.289\n",
      "271\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.06\n",
      "Difference : 0.059\n",
      "272\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.08\n",
      "Difference : 0.084\n",
      "273\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.08\n",
      "Difference : 0.082\n",
      "274\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.60\n",
      "Difference : 0.397\n",
      "275\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.92\n",
      "Difference : 0.916\n",
      "276\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.71\n",
      "Difference : 0.291\n",
      "277\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.57\n",
      "Difference : 0.431\n",
      "278\n",
      "Real Values : 13\n",
      "Predicted G3's score is 11.41\n",
      "Difference : 1.594\n",
      "279\n",
      "Real Values : 5\n",
      "Predicted G3's score is 7.50\n",
      "Difference : 2.500\n",
      "280\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.23\n",
      "Difference : 0.226\n",
      "281\n",
      "Real Values : 11\n",
      "Predicted G3's score is 12.17\n",
      "Difference : 1.168\n",
      "282\n",
      "Real Values : 7\n",
      "Predicted G3's score is 9.55\n",
      "Difference : 2.554\n",
      "283\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.79\n",
      "Difference : 0.208\n",
      "284\n",
      "Real Values : 6\n",
      "Predicted G3's score is 9.55\n",
      "Difference : 3.546\n",
      "285\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.25\n",
      "Difference : 0.254\n",
      "286\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.96\n",
      "Difference : 0.040\n",
      "287\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.68\n",
      "Difference : 0.319\n",
      "288\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.66\n",
      "Difference : 0.337\n",
      "289\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.17\n",
      "Difference : 1.827\n",
      "290\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.01\n",
      "Difference : 0.010\n",
      "291\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.88\n",
      "Difference : 1.117\n",
      "292\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.26\n",
      "Difference : 0.257\n",
      "293\n",
      "Real Values : 14\n",
      "Predicted G3's score is 11.79\n",
      "Difference : 2.210\n",
      "294\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.53\n",
      "Difference : 0.468\n",
      "295\n",
      "Real Values : 14\n",
      "Predicted G3's score is 13.48\n",
      "Difference : 0.522\n",
      "296\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.85\n",
      "Difference : 0.148\n",
      "297\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.68\n",
      "Difference : 0.315\n",
      "298\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.13\n",
      "Difference : 0.869\n",
      "299\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.32\n",
      "Difference : 0.318\n",
      "300\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.36\n",
      "Difference : 0.356\n",
      "301\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.04\n",
      "Difference : 0.963\n",
      "302\n",
      "Real Values : 12\n",
      "Predicted G3's score is 10.10\n",
      "Difference : 1.903\n",
      "303\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.48\n",
      "Difference : 0.518\n",
      "304\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.46\n",
      "Difference : 0.458\n",
      "305\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.57\n",
      "Difference : 0.574\n",
      "306\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.71\n",
      "Difference : 0.287\n",
      "307\n",
      "Real Values : 14\n",
      "Predicted G3's score is 13.17\n",
      "Difference : 0.827\n",
      "308\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.86\n",
      "Difference : 0.137\n",
      "309\n",
      "Real Values : 14\n",
      "Predicted G3's score is 12.13\n",
      "Difference : 1.870\n",
      "310\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.79\n",
      "Difference : 0.212\n",
      "311\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.59\n",
      "Difference : 0.414\n",
      "312\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.33\n",
      "Difference : 0.668\n",
      "313\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.51\n",
      "Difference : 0.507\n",
      "314\n",
      "Real Values : 18\n",
      "Predicted G3's score is 15.60\n",
      "Difference : 2.401\n",
      "315\n",
      "Real Values : 15\n",
      "Predicted G3's score is 14.83\n",
      "Difference : 0.167\n",
      "316\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.71\n",
      "Difference : 0.288\n",
      "317\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.61\n",
      "Difference : 0.390\n",
      "318\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.65\n",
      "Difference : 0.350\n",
      "319\n",
      "Real Values : 12\n",
      "Predicted G3's score is 13.26\n",
      "Difference : 1.259\n",
      "320\n",
      "Real Values : 13\n",
      "Predicted G3's score is 11.31\n",
      "Difference : 1.694\n",
      "321\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.18\n",
      "Difference : 0.179\n",
      "322\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.63\n",
      "Difference : 0.367\n",
      "323\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.99\n",
      "Difference : 0.007\n",
      "324\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.17\n",
      "Difference : 0.832\n",
      "325\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.90\n",
      "Difference : 0.100\n",
      "326\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.72\n",
      "Difference : 0.722\n",
      "327\n",
      "Real Values : 18\n",
      "Predicted G3's score is 15.76\n",
      "Difference : 2.242\n",
      "328\n",
      "Real Values : 13\n",
      "Predicted G3's score is 14.43\n",
      "Difference : 1.429\n",
      "329\n",
      "Real Values : 14\n",
      "Predicted G3's score is 13.99\n",
      "Difference : 0.009\n",
      "330\n",
      "Real Values : 14\n",
      "Predicted G3's score is 12.71\n",
      "Difference : 1.293\n",
      "331\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.93\n",
      "Difference : 0.065\n",
      "332\n",
      "Real Values : 18\n",
      "Predicted G3's score is 15.92\n",
      "Difference : 2.084\n",
      "333\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.71\n",
      "Difference : 0.712\n",
      "334\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.74\n",
      "Difference : 0.741\n",
      "335\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.74\n",
      "Difference : 1.259\n",
      "336\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.69\n",
      "Difference : 0.308\n",
      "337\n",
      "Real Values : 18\n",
      "Predicted G3's score is 15.91\n",
      "Difference : 2.095\n",
      "338\n",
      "Real Values : 19\n",
      "Predicted G3's score is 15.82\n",
      "Difference : 3.180\n",
      "339\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.37\n",
      "Difference : 0.370\n",
      "340\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.25\n",
      "Difference : 0.248\n",
      "341\n",
      "Real Values : 13\n",
      "Predicted G3's score is 14.29\n",
      "Difference : 1.292\n",
      "342\n",
      "Real Values : 14\n",
      "Predicted G3's score is 12.74\n",
      "Difference : 1.257\n",
      "343\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.84\n",
      "Difference : 1.162\n",
      "344\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.85\n",
      "Difference : 1.155\n",
      "345\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.47\n",
      "Difference : 0.472\n",
      "346\n",
      "Real Values : 13\n",
      "Predicted G3's score is 11.50\n",
      "Difference : 1.503\n",
      "347\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.58\n",
      "Difference : 1.581\n",
      "348\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.85\n",
      "Difference : 0.148\n",
      "349\n",
      "Real Values : 18\n",
      "Predicted G3's score is 15.82\n",
      "Difference : 2.180\n",
      "350\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.08\n",
      "Difference : 0.920\n",
      "351\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.27\n",
      "Difference : 0.266\n",
      "352\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.84\n",
      "Difference : 0.164\n",
      "353\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.02\n",
      "Difference : 0.983\n",
      "354\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.21\n",
      "Difference : 0.214\n",
      "355\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.81\n",
      "Difference : 0.807\n",
      "356\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.85\n",
      "Difference : 1.153\n",
      "357\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.74\n",
      "Difference : 1.255\n",
      "358\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.23\n",
      "Difference : 0.228\n",
      "359\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.72\n",
      "Difference : 1.284\n",
      "360\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.67\n",
      "Difference : 0.675\n",
      "361\n",
      "Real Values : 10\n",
      "Predicted G3's score is 12.09\n",
      "Difference : 2.092\n",
      "362\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.27\n",
      "Difference : 0.728\n",
      "363\n",
      "Real Values : 14\n",
      "Predicted G3's score is 12.16\n",
      "Difference : 1.835\n",
      "364\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.84\n",
      "Difference : 1.164\n",
      "365\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.75\n",
      "Difference : 1.252\n",
      "366\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.43\n",
      "Difference : 0.569\n",
      "367\n",
      "Real Values : 14\n",
      "Predicted G3's score is 13.68\n",
      "Difference : 0.318\n",
      "368\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.77\n",
      "Difference : 1.226\n",
      "369\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.07\n",
      "Difference : 0.073\n",
      "370\n",
      "Real Values : 9\n",
      "Predicted G3's score is 10.04\n",
      "Difference : 1.045\n",
      "371\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.70\n",
      "Difference : 0.700\n",
      "372\n",
      "Real Values : 13\n",
      "Predicted G3's score is 14.72\n",
      "Difference : 1.716\n",
      "373\n",
      "Real Values : 10\n",
      "Predicted G3's score is 12.27\n",
      "Difference : 2.270\n",
      "374\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.86\n",
      "Difference : 1.143\n",
      "375\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.33\n",
      "Difference : 0.329\n",
      "376\n",
      "Real Values : 14\n",
      "Predicted G3's score is 15.54\n",
      "Difference : 1.535\n",
      "377\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.68\n",
      "Difference : 0.683\n",
      "378\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.83\n",
      "Difference : 1.167\n",
      "379\n",
      "Real Values : 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted G3's score is 11.92\n",
      "Difference : 1.921\n",
      "380\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.77\n",
      "Difference : 0.769\n",
      "381\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.34\n",
      "Difference : 0.341\n",
      "382\n",
      "Real Values : 11\n",
      "Predicted G3's score is 12.72\n",
      "Difference : 1.719\n",
      "383\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.55\n",
      "Difference : 0.449\n",
      "384\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.32\n",
      "Difference : 0.319\n",
      "385\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.36\n",
      "Difference : 0.355\n",
      "386\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.74\n",
      "Difference : 0.739\n",
      "387\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.45\n",
      "Difference : 0.455\n",
      "388\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.77\n",
      "Difference : 0.226\n",
      "389\n",
      "Real Values : 12\n",
      "Predicted G3's score is 10.92\n",
      "Difference : 1.082\n",
      "390\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.51\n",
      "Difference : 0.510\n",
      "391\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.35\n",
      "Difference : 0.348\n",
      "392\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.01\n",
      "Difference : 0.007\n",
      "393\n",
      "Real Values : 15\n",
      "Predicted G3's score is 14.45\n",
      "Difference : 0.548\n",
      "394\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.66\n",
      "Difference : 0.343\n",
      "395\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.76\n",
      "Difference : 0.243\n",
      "396\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.84\n",
      "Difference : 1.160\n",
      "397\n",
      "Real Values : 14\n",
      "Predicted G3's score is 11.06\n",
      "Difference : 2.940\n",
      "398\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.90\n",
      "Difference : 0.905\n",
      "399\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.62\n",
      "Difference : 1.379\n",
      "400\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.72\n",
      "Difference : 1.279\n",
      "401\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.05\n",
      "Difference : 0.047\n",
      "402\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.06\n",
      "Difference : 0.063\n",
      "403\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.51\n",
      "Difference : 0.509\n",
      "404\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.67\n",
      "Difference : 0.334\n",
      "405\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.44\n",
      "Difference : 0.563\n",
      "406\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.43\n",
      "Difference : 0.568\n",
      "407\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.50\n",
      "Difference : 0.498\n",
      "408\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.28\n",
      "Difference : 0.280\n",
      "409\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.30\n",
      "Difference : 0.301\n",
      "410\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.87\n",
      "Difference : 1.128\n",
      "411\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.50\n",
      "Difference : 0.500\n",
      "412\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.87\n",
      "Difference : 1.129\n",
      "413\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.65\n",
      "Difference : 0.354\n",
      "414\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.06\n",
      "Difference : 0.060\n",
      "415\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.88\n",
      "Difference : 1.115\n",
      "416\n",
      "Real Values : 18\n",
      "Predicted G3's score is 15.85\n",
      "Difference : 2.153\n",
      "417\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.67\n",
      "Difference : 1.326\n",
      "418\n",
      "Real Values : 14\n",
      "Predicted G3's score is 13.96\n",
      "Difference : 0.037\n",
      "419\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.82\n",
      "Difference : 0.185\n",
      "420\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.83\n",
      "Difference : 1.166\n",
      "421\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.57\n",
      "Difference : 0.431\n",
      "422\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.83\n",
      "Difference : 0.170\n",
      "423\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.05\n",
      "Difference : 0.953\n",
      "424\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.73\n",
      "Difference : 0.728\n",
      "425\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.57\n",
      "Difference : 0.433\n",
      "426\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.19\n",
      "Difference : 0.807\n",
      "427\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.41\n",
      "Difference : 1.590\n",
      "428\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.53\n",
      "Difference : 0.535\n",
      "429\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.22\n",
      "Difference : 0.784\n",
      "430\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.88\n",
      "Difference : 0.877\n",
      "431\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.69\n",
      "Difference : 0.306\n",
      "432\n",
      "Real Values : 7\n",
      "Predicted G3's score is 7.52\n",
      "Difference : 0.516\n",
      "433\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.53\n",
      "Difference : 0.528\n",
      "434\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.93\n",
      "Difference : 1.071\n",
      "435\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.72\n",
      "Difference : 0.281\n",
      "436\n",
      "Real Values : 8\n",
      "Predicted G3's score is 7.50\n",
      "Difference : 0.500\n",
      "437\n",
      "Real Values : 12\n",
      "Predicted G3's score is 10.78\n",
      "Difference : 1.224\n",
      "438\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.45\n",
      "Difference : 0.447\n",
      "439\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.66\n",
      "Difference : 0.337\n",
      "440\n",
      "Real Values : 0\n",
      "Predicted G3's score is 0.61\n",
      "Difference : 0.611\n",
      "441\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.63\n",
      "Difference : 0.634\n",
      "442\n",
      "Real Values : 14\n",
      "Predicted G3's score is 13.98\n",
      "Difference : 0.021\n",
      "443\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.58\n",
      "Difference : 1.580\n",
      "444\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.17\n",
      "Difference : 0.169\n",
      "445\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.67\n",
      "Difference : 0.673\n",
      "446\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.61\n",
      "Difference : 0.611\n",
      "447\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.79\n",
      "Difference : 0.786\n",
      "448\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.73\n",
      "Difference : 1.267\n",
      "449\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.04\n",
      "Difference : 0.044\n",
      "450\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.75\n",
      "Difference : 0.746\n",
      "451\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.16\n",
      "Difference : 0.157\n",
      "452\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.35\n",
      "Difference : 0.653\n",
      "453\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.07\n",
      "Difference : 1.065\n",
      "454\n",
      "Real Values : 8\n",
      "Predicted G3's score is 7.54\n",
      "Difference : 0.464\n",
      "455\n",
      "Real Values : 9\n",
      "Predicted G3's score is 10.79\n",
      "Difference : 1.793\n",
      "456\n",
      "Real Values : 15\n",
      "Predicted G3's score is 14.33\n",
      "Difference : 0.665\n",
      "457\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.98\n",
      "Difference : 0.015\n",
      "458\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.12\n",
      "Difference : 0.876\n",
      "459\n",
      "Real Values : 10\n",
      "Predicted G3's score is 11.39\n",
      "Difference : 1.387\n",
      "460\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.89\n",
      "Difference : 1.108\n",
      "461\n",
      "Real Values : 14\n",
      "Predicted G3's score is 12.26\n",
      "Difference : 1.741\n",
      "462\n",
      "Real Values : 14\n",
      "Predicted G3's score is 13.64\n",
      "Difference : 0.364\n",
      "463\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.61\n",
      "Difference : 0.388\n",
      "464\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.84\n",
      "Difference : 1.165\n",
      "465\n",
      "Real Values : 8\n",
      "Predicted G3's score is 8.46\n",
      "Difference : 0.459\n",
      "466\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.17\n",
      "Difference : 0.832\n",
      "467\n",
      "Real Values : 14\n",
      "Predicted G3's score is 15.08\n",
      "Difference : 1.083\n",
      "468\n",
      "Real Values : 13\n",
      "Predicted G3's score is 11.87\n",
      "Difference : 1.125\n",
      "469\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.39\n",
      "Difference : 0.615\n",
      "470\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.04\n",
      "Difference : 0.040\n",
      "471\n",
      "Real Values : 12\n",
      "Predicted G3's score is 10.70\n",
      "Difference : 1.299\n",
      "472\n",
      "Real Values : 16\n",
      "Predicted G3's score is 12.19\n",
      "Difference : 3.812\n",
      "473\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.57\n",
      "Difference : 0.430\n",
      "474\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.35\n",
      "Difference : 0.353\n",
      "475\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.80\n",
      "Difference : 0.799\n",
      "476\n",
      "Real Values : 8\n",
      "Predicted G3's score is 8.66\n",
      "Difference : 0.663\n",
      "477\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.54\n",
      "Difference : 0.536\n",
      "478\n",
      "Real Values : 8\n",
      "Predicted G3's score is 7.51\n",
      "Difference : 0.492\n",
      "479\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.66\n",
      "Difference : 0.343\n",
      "480\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.65\n",
      "Difference : 0.352\n",
      "481\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.75\n",
      "Difference : 1.250\n",
      "482\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.61\n",
      "Difference : 0.613\n",
      "483\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.41\n",
      "Difference : 0.588\n",
      "484\n",
      "Real Values : 8\n",
      "Predicted G3's score is 8.42\n",
      "Difference : 0.422\n",
      "485\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.93\n",
      "Difference : 0.932\n",
      "486\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.83\n",
      "Difference : 0.174\n",
      "487\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.55\n",
      "Difference : 0.454\n",
      "488\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.48\n",
      "Difference : 0.478\n",
      "489\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.57\n",
      "Difference : 0.429\n",
      "490\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.86\n",
      "Difference : 0.143\n",
      "491\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.59\n",
      "Difference : 0.585\n",
      "492\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.59\n",
      "Difference : 0.413\n",
      "493\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.34\n",
      "Difference : 0.345\n",
      "494\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.56\n",
      "Difference : 0.564\n",
      "495\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.64\n",
      "Difference : 0.356\n",
      "496\n",
      "Real Values : 14\n",
      "Predicted G3's score is 11.80\n",
      "Difference : 2.198\n",
      "497\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.87\n",
      "Difference : 0.127\n",
      "498\n",
      "Real Values : 14\n",
      "Predicted G3's score is 15.24\n",
      "Difference : 1.243\n",
      "499\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.51\n",
      "Difference : 0.487\n",
      "500\n",
      "Real Values : 7\n",
      "Predicted G3's score is 7.51\n",
      "Difference : 0.509\n",
      "501\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.13\n",
      "Difference : 0.133\n",
      "502\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.95\n",
      "Difference : 0.951\n",
      "503\n",
      "Real Values : 14\n",
      "Predicted G3's score is 13.99\n",
      "Difference : 0.014\n",
      "504\n",
      "Real Values : 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted G3's score is 12.21\n",
      "Difference : 0.787\n",
      "505\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.93\n",
      "Difference : 1.067\n",
      "506\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.57\n",
      "Difference : 0.435\n",
      "507\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.02\n",
      "Difference : 0.024\n",
      "508\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.61\n",
      "Difference : 0.606\n",
      "509\n",
      "Real Values : 18\n",
      "Predicted G3's score is 15.68\n",
      "Difference : 2.318\n",
      "510\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.72\n",
      "Difference : 1.278\n",
      "511\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.13\n",
      "Difference : 0.132\n",
      "512\n",
      "Real Values : 7\n",
      "Predicted G3's score is 7.50\n",
      "Difference : 0.503\n",
      "513\n",
      "Real Values : 8\n",
      "Predicted G3's score is 7.50\n",
      "Difference : 0.500\n",
      "514\n",
      "Real Values : 7\n",
      "Predicted G3's score is 7.51\n",
      "Difference : 0.507\n",
      "515\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.71\n",
      "Difference : 0.293\n",
      "516\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.68\n",
      "Difference : 0.319\n",
      "517\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.25\n",
      "Difference : 0.255\n",
      "518\n",
      "Real Values : 8\n",
      "Predicted G3's score is 7.51\n",
      "Difference : 0.494\n",
      "519\n",
      "Real Values : 0\n",
      "Predicted G3's score is 8.57\n",
      "Difference : 8.574\n",
      "520\n",
      "Real Values : 8\n",
      "Predicted G3's score is 8.47\n",
      "Difference : 0.470\n",
      "521\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.78\n",
      "Difference : 0.221\n",
      "522\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.56\n",
      "Difference : 1.563\n",
      "523\n",
      "Real Values : 6\n",
      "Predicted G3's score is 7.50\n",
      "Difference : 1.502\n",
      "524\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.56\n",
      "Difference : 1.557\n",
      "525\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.15\n",
      "Difference : 0.846\n",
      "526\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.78\n",
      "Difference : 0.783\n",
      "527\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.11\n",
      "Difference : 0.114\n",
      "528\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.74\n",
      "Difference : 0.739\n",
      "529\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.51\n",
      "Difference : 0.487\n",
      "530\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.69\n",
      "Difference : 0.685\n",
      "531\n",
      "Real Values : 10\n",
      "Predicted G3's score is 11.17\n",
      "Difference : 1.170\n",
      "532\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.56\n",
      "Difference : 1.558\n",
      "533\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.57\n",
      "Difference : 0.434\n",
      "534\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.17\n",
      "Difference : 0.171\n",
      "535\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.01\n",
      "Difference : 0.006\n",
      "536\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.85\n",
      "Difference : 0.849\n",
      "537\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.48\n",
      "Difference : 0.483\n",
      "538\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.44\n",
      "Difference : 0.557\n",
      "539\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.83\n",
      "Difference : 0.171\n",
      "540\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.05\n",
      "Difference : 0.946\n",
      "541\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.22\n",
      "Difference : 0.219\n",
      "542\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.77\n",
      "Difference : 0.233\n",
      "543\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.55\n",
      "Difference : 1.551\n",
      "544\n",
      "Real Values : 12\n",
      "Predicted G3's score is 10.68\n",
      "Difference : 1.315\n",
      "545\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.58\n",
      "Difference : 1.583\n",
      "546\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.66\n",
      "Difference : 0.342\n",
      "547\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.88\n",
      "Difference : 0.882\n",
      "548\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.01\n",
      "Difference : 0.995\n",
      "549\n",
      "Real Values : 18\n",
      "Predicted G3's score is 15.80\n",
      "Difference : 2.199\n",
      "550\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.78\n",
      "Difference : 0.223\n",
      "551\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.99\n",
      "Difference : 0.008\n",
      "552\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.58\n",
      "Difference : 0.419\n",
      "553\n",
      "Real Values : 12\n",
      "Predicted G3's score is 9.75\n",
      "Difference : 2.253\n",
      "554\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.87\n",
      "Difference : 0.129\n",
      "555\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.13\n",
      "Difference : 0.866\n",
      "556\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.76\n",
      "Difference : 1.241\n",
      "557\n",
      "Real Values : 10\n",
      "Predicted G3's score is 7.51\n",
      "Difference : 2.495\n",
      "558\n",
      "Real Values : 10\n",
      "Predicted G3's score is 11.85\n",
      "Difference : 1.853\n",
      "559\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.57\n",
      "Difference : 0.567\n",
      "560\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.10\n",
      "Difference : 0.100\n",
      "561\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.94\n",
      "Difference : 0.063\n",
      "562\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.12\n",
      "Difference : 0.122\n",
      "563\n",
      "Real Values : 0\n",
      "Predicted G3's score is 0.61\n",
      "Difference : 0.611\n",
      "564\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.11\n",
      "Difference : 0.113\n",
      "565\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.72\n",
      "Difference : 0.722\n",
      "566\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.58\n",
      "Difference : 0.581\n",
      "567\n",
      "Real Values : 0\n",
      "Predicted G3's score is 0.61\n",
      "Difference : 0.611\n",
      "568\n",
      "Real Values : 9\n",
      "Predicted G3's score is 7.74\n",
      "Difference : 1.257\n",
      "569\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.00\n",
      "Difference : 0.999\n",
      "570\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.59\n",
      "Difference : 1.593\n",
      "571\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.61\n",
      "Difference : 0.605\n",
      "572\n",
      "Real Values : 7\n",
      "Predicted G3's score is 7.50\n",
      "Difference : 0.499\n",
      "573\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.57\n",
      "Difference : 0.433\n",
      "574\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.94\n",
      "Difference : 0.058\n",
      "575\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.14\n",
      "Difference : 0.144\n",
      "576\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.43\n",
      "Difference : 0.569\n",
      "577\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.10\n",
      "Difference : 0.899\n",
      "578\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.61\n",
      "Difference : 0.392\n",
      "579\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.67\n",
      "Difference : 0.668\n",
      "580\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.65\n",
      "Difference : 0.348\n",
      "581\n",
      "Real Values : 8\n",
      "Predicted G3's score is 7.53\n",
      "Difference : 0.465\n",
      "582\n",
      "Real Values : 7\n",
      "Predicted G3's score is 9.56\n",
      "Difference : 2.564\n",
      "583\n",
      "Real Values : 0\n",
      "Predicted G3's score is 7.50\n",
      "Difference : 7.499\n",
      "584\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.59\n",
      "Difference : 0.406\n",
      "585\n",
      "Real Values : 8\n",
      "Predicted G3's score is 9.52\n",
      "Difference : 1.516\n",
      "586\n",
      "Real Values : 0\n",
      "Predicted G3's score is 9.61\n",
      "Difference : 9.614\n",
      "587\n",
      "Real Values : 8\n",
      "Predicted G3's score is 7.50\n",
      "Difference : 0.496\n",
      "588\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.63\n",
      "Difference : 0.625\n",
      "589\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.60\n",
      "Difference : 0.397\n",
      "590\n",
      "Real Values : 7\n",
      "Predicted G3's score is 9.52\n",
      "Difference : 2.518\n",
      "591\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.25\n",
      "Difference : 0.247\n",
      "592\n",
      "Real Values : 13\n",
      "Predicted G3's score is 13.30\n",
      "Difference : 0.305\n",
      "593\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.56\n",
      "Difference : 0.555\n",
      "594\n",
      "Real Values : 18\n",
      "Predicted G3's score is 15.89\n",
      "Difference : 2.106\n",
      "595\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.84\n",
      "Difference : 1.157\n",
      "596\n",
      "Real Values : 18\n",
      "Predicted G3's score is 15.91\n",
      "Difference : 2.086\n",
      "597\n",
      "Real Values : 0\n",
      "Predicted G3's score is 0.61\n",
      "Difference : 0.611\n",
      "598\n",
      "Real Values : 11\n",
      "Predicted G3's score is 11.69\n",
      "Difference : 0.692\n",
      "599\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.85\n",
      "Difference : 0.852\n",
      "600\n",
      "Real Values : 14\n",
      "Predicted G3's score is 12.88\n",
      "Difference : 1.118\n",
      "601\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.60\n",
      "Difference : 0.395\n",
      "602\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.66\n",
      "Difference : 0.341\n",
      "603\n",
      "Real Values : 0\n",
      "Predicted G3's score is 0.61\n",
      "Difference : 0.611\n",
      "604\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.56\n",
      "Difference : 0.445\n",
      "605\n",
      "Real Values : 0\n",
      "Predicted G3's score is 0.61\n",
      "Difference : 0.611\n",
      "606\n",
      "Real Values : 18\n",
      "Predicted G3's score is 15.89\n",
      "Difference : 2.110\n",
      "607\n",
      "Real Values : 12\n",
      "Predicted G3's score is 9.68\n",
      "Difference : 2.322\n",
      "608\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.65\n",
      "Difference : 1.354\n",
      "609\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.28\n",
      "Difference : 0.277\n",
      "610\n",
      "Real Values : 0\n",
      "Predicted G3's score is 0.61\n",
      "Difference : 0.611\n",
      "611\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.48\n",
      "Difference : 0.482\n",
      "612\n",
      "Real Values : 11\n",
      "Predicted G3's score is 10.67\n",
      "Difference : 0.331\n",
      "613\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.71\n",
      "Difference : 0.286\n",
      "614\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.88\n",
      "Difference : 0.116\n",
      "615\n",
      "Real Values : 15\n",
      "Predicted G3's score is 12.09\n",
      "Difference : 2.913\n",
      "616\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.47\n",
      "Difference : 0.473\n",
      "617\n",
      "Real Values : 18\n",
      "Predicted G3's score is 15.89\n",
      "Difference : 2.111\n",
      "618\n",
      "Real Values : 15\n",
      "Predicted G3's score is 13.33\n",
      "Difference : 1.667\n",
      "619\n",
      "Real Values : 13\n",
      "Predicted G3's score is 14.67\n",
      "Difference : 1.670\n",
      "620\n",
      "Real Values : 15\n",
      "Predicted G3's score is 14.98\n",
      "Difference : 0.020\n",
      "621\n",
      "Real Values : 13\n",
      "Predicted G3's score is 12.32\n",
      "Difference : 0.681\n",
      "622\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.63\n",
      "Difference : 0.627\n",
      "623\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.66\n",
      "Difference : 0.338\n",
      "624\n",
      "Real Values : 9\n",
      "Predicted G3's score is 7.58\n",
      "Difference : 1.420\n",
      "625\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.48\n",
      "Difference : 0.477\n",
      "626\n",
      "Real Values : 0\n",
      "Predicted G3's score is 0.61\n",
      "Difference : 0.610\n",
      "627\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.76\n",
      "Difference : 0.241\n",
      "628\n",
      "Real Values : 12\n",
      "Predicted G3's score is 11.64\n",
      "Difference : 0.356\n",
      "629\n",
      "Real Values : 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted G3's score is 9.43\n",
      "Difference : 0.428\n",
      "630\n",
      "Real Values : 17\n",
      "Predicted G3's score is 15.78\n",
      "Difference : 1.224\n",
      "631\n",
      "Real Values : 12\n",
      "Predicted G3's score is 12.17\n",
      "Difference : 0.172\n",
      "632\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.55\n",
      "Difference : 0.546\n",
      "633\n",
      "Real Values : 14\n",
      "Predicted G3's score is 14.69\n",
      "Difference : 0.693\n",
      "634\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.75\n",
      "Difference : 0.246\n",
      "635\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.59\n",
      "Difference : 0.589\n",
      "636\n",
      "Real Values : 19\n",
      "Predicted G3's score is 15.92\n",
      "Difference : 3.083\n",
      "637\n",
      "Real Values : 0\n",
      "Predicted G3's score is 8.53\n",
      "Difference : 8.528\n",
      "638\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.78\n",
      "Difference : 0.223\n",
      "639\n",
      "Real Values : 0\n",
      "Predicted G3's score is 0.61\n",
      "Difference : 0.611\n",
      "640\n",
      "Real Values : 0\n",
      "Predicted G3's score is 0.61\n",
      "Difference : 0.611\n",
      "641\n",
      "Real Values : 15\n",
      "Predicted G3's score is 15.57\n",
      "Difference : 0.566\n",
      "642\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.54\n",
      "Difference : 1.462\n",
      "643\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.55\n",
      "Difference : 0.445\n",
      "644\n",
      "Real Values : 10\n",
      "Predicted G3's score is 9.82\n",
      "Difference : 0.182\n",
      "645\n",
      "Real Values : 16\n",
      "Predicted G3's score is 15.65\n",
      "Difference : 0.347\n",
      "646\n",
      "Real Values : 9\n",
      "Predicted G3's score is 9.62\n",
      "Difference : 0.620\n",
      "647\n",
      "Real Values : 10\n",
      "Predicted G3's score is 10.07\n",
      "Difference : 0.074\n",
      "648\n",
      "Real Values : 11\n",
      "Predicted G3's score is 9.88\n",
      "Difference : 1.122\n",
      "\n",
      "Number of predicted score that exceed Mean Abs Error :  620\n"
     ]
    }
   ],
   "source": [
    "diff_list = []\n",
    "large_diff_count = 0\n",
    "for i in range(0,len(target)):\n",
    "    print(i)\n",
    "    df2 = features.iloc[i] # Test with the 14th Student \n",
    "    target2 = target.iloc[i].values[0]\n",
    "    print(\"Real Values :\", target2)\n",
    "    Xnew = np.array([df2])\n",
    "    Xnew.reshape(1, -1)\n",
    "    Xnew= scaler_x.transform(Xnew)\n",
    "    ynew= model_gridsearched.predict(Xnew)\n",
    "\n",
    "    #invert normalize\n",
    "    ynew = scaler_y.inverse_transform(ynew) \n",
    "    Xnew = scaler_x.inverse_transform(Xnew)\n",
    "    \n",
    "    predicted = float(ynew)\n",
    "    #print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))\n",
    "    print(\"Predicted G3's score is {:.2f}\".format(predicted))\n",
    "    diff = np.abs(predicted-target2)\n",
    "    print(\"Difference : {:.3f}\".format(diff))\n",
    "    diff_list.append(diff)\n",
    "    \n",
    "    if diff > mean_abs_e:\n",
    "        large_diff_count = large_diff_count + 1\n",
    "print(\"\\nNumber of predicted score that exceed Mean Abs Error : \",large_diff_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
